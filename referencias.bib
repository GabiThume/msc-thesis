@article{Abdi2010,
abstract = {Principal component analysis (pca) is a multivariate technique that analyzes a data table in which observations are described by several inter-correlated quantitative dependent variables. Its goal is to extract the important information from the table, to represent it as a set of new orthogonal variables called principal components, and to display the pattern of similarity of the observations and of the variables as points in maps. The quality of the pca model can be evaluated using cross-validation techniques such as the bootstrap and the jackknife. Pca can be generalized as correspondence analysis (ca) in order to handle qualitative variables and as multiple factor analysis (mfa) in order to handle heterogenous sets of variables. Mathematically, pca depends upon the eigen-decomposition of positive semi-definite matrices and upon the singular value decomposition (svd) of rectangular matrices.},
author = {Abdi, Herv{\'{e}} and Williams, Lynne J},
doi = {10.1002/wics.101},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abdi, Williams - 2010 - Principal Component Analysis.pdf:pdf},
isbn = {1939-0068},
issn = {19395108},
journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
keywords = {bilinear decomposition,correspondence analysis,cross validation,eigen decom,factor scores,jackknife,loadings,multicolinearity,multiple factor analy,position,predicted residual sum,press,principal component analysis,resid,sis,squares},
number = {4},
pages = {433--459},
title = {{Principal Component Analysis}},
url = {http://dx.doi.org/10.1002/wics.101},
volume = {2},
year = {2010}
}
@article{Ahonen2004,
author = {Ahonen, Timo and Hadid, Abdenour and Pietik{\"{a}}inen, M},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahonen, Hadid, Pietik{\"{a}}inen - 2004 - Face recognition with local binary patterns.pdf:pdf},
journal = {Computer vision-eccv 2004},
pages = {469--481},
title = {{Face recognition with local binary patterns}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-24670-1{\_}36},
year = {2004}
}
@article{6,
abstract = {This paper presents a novel and efficient facial image representation based on local binary pattern (LBP) texture features. The face image is divided into several regions from which the LBP feature distributions are extracted and concatenated into an enhanced feature vector to be used as a face descriptor. The performance of the proposed method is assessed in the face recognition problem under different challenges. Other applications and several extensions are also discussed.},
author = {Ahonen, Timo and Hadid, Abdenour and Pietik{\"{a}}inen, Matti},
doi = {10.1109/TPAMI.2006.244},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahonen, Hadid, Pietik{\"{a}}inen - 2006 - Face description with local binary patterns application to face recognition.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Biometry,Biometry: methods,Computer-Assisted,Computer-Assisted: methods,Face,Face: anatomy {\&} histology,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Numerical Analysis,Pattern Recognition,Reproducibility of Results,Sensitivity and Specificity,Signal Processing},
month = {dec},
number = {12},
pages = {2037--2041},
pmid = {17108377},
title = {{Face description with local binary patterns: application to face recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17108377},
volume = {28},
year = {2006}
}
@article{Anual2014,
author = {Anual, R I O and Regular, D E Aluno and Ci, E M and Computa, Ncias D E and Icmc-usp, Tica Computacional},
file = {:home/gabi/Documentos/relatorio{\_}anual{\_}gabriela{\_}2016.pdf:pdf},
pages = {1--3},
title = {{Atividades did{\'{a}}ticas}},
year = {2014}
}
@article{Aoki1999,
author = {Aoki, Shinya and Nagao, Tomoharu and Science, Imaging},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aoki, Nagao, Science - 1999 - Automatic Construction of Tree-structural Image Transformation using Genetic Programming.pdf:pdf},
isbn = {0780354672},
pages = {2--6},
title = {{Automatic Construction of Tree-structural Image Transformation using Genetic Programming}},
year = {1999}
}
@article{Aono1984,
abstract = {The authors present botanical trees as models of biological objects, first by defining their developmental rules in a discrete grammatical form, then by defining them in continuous geometric forms. Having analyzed these models from several standpoints, they have developed an interactive synthetic tree manipulation system called the A-system. The A-system incorporates such constructs as leaves, shadows, and shades and can perform three-dimensional transformations of a tree. One of its applications is to assist with landscaping, which includes gardening and the design of street plants.},
author = {Aono, Masaki and Kunii, Tosiyasu},
doi = {10.1109/MCG.1984.276141},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aono, Kunii - 1984 - Botanical Tree Image Generation.pdf:pdf},
issn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
keywords = {A-system,Algae,Biological system modeling,Computer graphics,Formal languages,Fractals,Image generation,Shape,Solid modeling,Testing,Tree graphs,biological objects,botanical trees,computer graphics,continuous geometric forms,developmental rules,discrete grammatical form,gardening,image generation,interactive synthetic tree manipulation system,landscaping,leaves,natural sciences computing,shades,shadows,street plants,three-dimensional transformations,town and country planning},
mendeley-tags = {image generation},
number = {5},
pages = {10--34},
shorttitle = {Computer Graphics and Applications, IEEE},
title = {{Botanical Tree Image Generation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4055766},
volume = {4},
year = {1984}
}
@article{Chornoboy1994,
author = {ApRil, O},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/ApRil - 1994 - Automated storm tracking for terminal air traffic control.pdf:pdf},
journal = {Lincoln Laboratory Journal},
number = {2},
pages = {427--448},
title = {{Automated storm tracking for terminal air traffic control}},
url = {http://www.ll.mit.edu/mission/aviation/publications/publication-files/journal-articles/Chornoboy{\_}1994{\_}JA-7198.pdf},
volume = {7},
year = {1994}
}
@inproceedings{Arandjelovic2013,
abstract = {The objective of this paper is large scale object instance retrieval, given a query image. A starting point of such systems is feature detection and description, for example using SIFT. The focus of this paper, however, is towards very large scale retrieval where, due to storage requirements, very compact image descriptors are required and no information about the original SIFT descriptors can be accessed directly at run time. We start from VLAD, the state-of-the art compact descriptor introduced by Jegou et al. for this purpose, and make three novel contributions: first, we show that a simple change to the normalization method significantly improves retrieval performance, second, we show that vocabulary adaptation can substantially alleviate problems caused when images are added to the dataset after initial vocabulary learning. These two methods set a new state-of-the-art over all benchmarks investigated here for both mid-dimensional (20k-D to 30k-D) and small (128-D) descriptors. Our third contribution is a multiple spatial VLAD representation, MultiVLAD, that allows the retrieval and localization of objects that only extend over a small part of an image (again without requiring use of the original image SIFT descriptors).},
author = {Arandjelovic, Relja and Zisserman, Andrew},
booktitle = {2013 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2013.207},
isbn = {978-0-7695-4989-7},
issn = {1063-6919},
keywords = {Benchmark testing,Buildings,Databases,SIFT descriptor,Standards,Vectors,Visualization,Vocabulary,compact image descriptor,feature description,feature detection,feature extraction,image retrieval,large scale object instance retrieval,multiple spatial VLAD representation,query image,storage requirement},
month = {jun},
pages = {1578--1585},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{All About VLAD}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6619051},
year = {2013}
}
@article{Arici2009,
author = {Arici, Tarik and Dikbas, Salih and Altunbasak, Yucel},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arici, Dikbas, Altunbasak - 2009 - A histogram modification framework and its application for image contrast enhancement.pdf:pdf},
journal = {Image Processing, IEEE {\ldots}},
number = {9},
pages = {1921--1935},
title = {{A histogram modification framework and its application for image contrast enhancement}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4895264},
volume = {18},
year = {2009}
}
@article{Attenberg2013,
author = {Attenberg, Josh},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Attenberg - 2013 - Class imbalance and active learning.pdf:pdf},
number = {iii},
pages = {101--151},
title = {{Class imbalance and active learning}},
year = {2013}
}
@article{AurelienMayoueQuentinBarthelemySebastienOnis2012,
author = {{Aur{\'{e}}lien Mayoue, Quentin Barth{\'{e}}lemy, S{\'{e}}bastien Onis}, Anthony Larue.},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aur{\'{e}}lien Mayoue, Quentin Barth{\'{e}}lemy, S{\'{e}}bastien Onis - 2012 - Preprocessing for classication of sparse data application to trajectory.pdf:pdf},
journal = {IEEE Statistical Signal Processing Workshop},
pages = {37--40},
title = {{Preprocessing for classication of sparse data: application to trajectory recognition.}},
url = {https://hal.archives-ouvertes.fr/hal-00730423/document},
year = {2012}
}
@article{Barua2014,
abstract = {Imbalanced learning problems contain an unequal distribution of data samples among different classes and pose a challenge to any classifier as it becomes hard to learn the minority class samples. Synthetic oversampling methods address this problem by generating the synthetic minority class samples to balance the distribution between the samples of the majority and minority classes. This paper identifies that most of the existing oversampling methods may generate the wrong synthetic minority samples in some scenarios and make learning tasks harder. To this end, a new method, called Majority Weighted Minority Oversampling TEchnique (MWMOTE), is presented for efficiently handling imbalanced learning problems. MWMOTE first identifies the hard-to-learn informative minority class samples and assigns them weights according to their euclidean distance from the nearest majority class samples. It then generates the synthetic samples from the weighted informative minority class samples using a clustering approach. This is done in such a way that all the generated samples lie inside some minority class cluster. MWMOTE has been evaluated extensively on four artificial and 20 real-world data sets. The simulation results show that our method is better than or comparable with some other existing methods in terms of various assessment metrics, such as geometric mean (G-mean) and area under the receiver operating curve (ROC), usually known as area under curve (AUC).},
author = {Barua, Sukarna and Islam, Md. Monirul and Yao, Xin and Murase, Kazuyuki},
doi = {10.1109/TKDE.2012.232},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barua et al. - 2014 - MWMOTE--Majority Weighted Minority Oversampling Technique for Imbalanced Data Set Learning.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {AUC,Abstracts,Boosting,Complexity theory,Euclidean distance,G-mean,Imbalanced learning,Interpolation,MWMOTE-majority weighted minority oversampling tec,Noise measurement,ROC,Sampling methods,Simulation,area under curve,clustering,clustering approach,geometric mean,hard-to-learn informative minority class samples,imbalanced data set learning,imbalanced learning problems,learning (artificial intelligence),majority class,minority class cluster,oversampling,pattern clustering,receiver operating curve,sampling methods,synthetic minority class samples,synthetic oversampling methods,synthetic sample generation,undersampling,weighted informative minority class samples},
month = {feb},
number = {2},
pages = {405--425},
shorttitle = {Knowledge and Data Engineering, IEEE Transactions},
title = {{MWMOTE--Majority Weighted Minority Oversampling Technique for Imbalanced Data Set Learning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6361394},
volume = {26},
year = {2014}
}
@article{Batista2004,
author = {Batista, GE E and Prati, RC C and Monard, MC C},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Batista, Prati, Monard - 2004 - A study of the behavior of several methods for balancing machine learning training data.pdf:pdf},
journal = {ACM Sigkdd Explorations Newsletter},
number = {1},
pages = {20--29},
title = {{A study of the behavior of several methods for balancing machine learning training data}},
url = {http://dl.acm.org/citation.cfm?id=1007735},
volume = {6},
year = {2004}
}
@article{Belhumeur1997,
abstract = {We develop a face recognition algorithm which is insensitive to large variation in lighting direction and facial expression. Taking a pattern classification approach, we consider each pixel in an image as a coordinate in a high-dimensional space. We take advantage of the observation that the images of a particular face, under varying illumination but fixed pose, lie in a 3D linear subspace of the high dimensional image space-if the face is a Lambertian surface without shadowing. However, since faces are not truly Lambertian surfaces and do indeed produce self-shadowing, images will deviate from this linear subspace. Rather than explicitly modeling this deviation, we linearly project the image into a subspace in a manner which discounts those regions of the face with large deviation. Our projection method is based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variation in lighting and facial expressions. The eigenface technique, another method based on linearly projecting the image space to a low dimensional subspace, has similar computational requirements. Yet, extensive experimental results demonstrate that the proposed “Fisherface” method has error rates that are lower than those of the eigenface technique for tests on the Harvard and Yale face databases},
author = {Belhumeur, P.N. N and Hespanha, J.P. P and Kriegman, D.J. J},
doi = {10.1109/34.598228},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belhumeur, Hespanha, Kriegman - 1997 - Eigenfaces vs. Fisherfaces recognition using class specific linear projection.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {3D linear subspace,Error analysis,Face detection,Face recognition,Fisherfaces,Lambertian surface,Light scattering,Light sources,Lighting,Pattern classification,Pixel,Principal component analysis,Shadow mapping,class specific linear projection,computational requirements,eigenfaces,face recognition,facial expression insensitivity,high-dimensional space,lighting direction insensitivity,linear discriminant,linear projection,low-dimensional subspace,pattern classification},
month = {jul},
number = {7},
pages = {711--720},
shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
title = {{Eigenfaces vs. Fisherfaces: recognition using class specific linear projection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=598228},
volume = {19},
year = {1997}
}
@article{Belkin2003,
abstract = {One of the central problems in machine learning and pattern recognition is to develop appropriate representations for complex data. We consider the problem of constructing a representation for data lying on a low-dimensional manifold embedded in a high-dimensional space. Drawing on the correspondence between the graph Laplacian, the Laplace Beltrami operator on the manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for representing the high-dimensional data. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality-preserving properties and a natural connection to clustering. Some potential applications and illustrative examples are discussed.},
author = {Belkin, Mikhail and Niyogi, Partha},
doi = {10.1162/089976603321780317},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belkin, Niyogi - 2003 - Laplacian Eigenmaps for Dimensionality Reduction and Data Representation.pdf:pdf},
isbn = {0899-7667},
issn = {0899-7667},
journal = {Neural Computation},
number = {6},
pages = {1373--1396},
pmid = {12816577},
title = {{Laplacian Eigenmaps for Dimensionality Reduction and Data Representation}},
volume = {15},
year = {2003}
}
@article{bengio2009,
author = {Bengio, Yoshua},
doi = {10.1561/2200000006},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bengio - 2009 - Learning Deep Architectures for AI.pdf:pdf},
issn = {1935-8237},
journal = {Foundations and Trends in Machine Learning},
month = {jan},
number = {1},
pages = {1--127},
publisher = {Now Publishers Inc.},
title = {{Learning Deep Architectures for AI}},
url = {http://dl.acm.org/citation.cfm?id=1658423.1658424},
volume = {2},
year = {2009}
}
@unpublished{Bengio-et-al-2014-Book,
author = {Bengio, Yoshua and Goodfellow, Ian J. and Courville, Aaron},
publisher = {Book in preparation for MIT Press},
title = {{Deep Learning}},
url = {http://www.iro.umontreal.ca/{~}bengioy/dlbook},
year = {2014}
}
@article{Bhattacharyya2011,
author = {Bhattacharyya, Siddhartha},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhattacharyya - 2011 - A brief survey of color image preprocessing and segmentation techniques.pdf:pdf},
journal = {Journal of Pattern Recognition Research},
keywords = {classical approaches,color image enhancement,color image segmentation,non-classical approaches},
pages = {120--129},
title = {{A brief survey of color image preprocessing and segmentation techniques}},
url = {http://jprr.org/index.php/jprr/article/view/191},
volume = {1},
year = {2011}
}
@article{Bielecki2008,
abstract = {In this paper, the first stage of studies concerning the computer analysis of hand X-ray digital images is described. The images are preprocessed and then skeletization of the fingers is carried out. Then, the interphapangeal and metacarpophalangeal joints are detected and contoured. Joint widths are also measured. The obtained results largely concur with those obtained by other authors—see Beier et al. [Segmentation of medical images combining local, regional, global, and hierarchical distances into a bottom-up region merging scheme, Proc. SPIE 5747 (2005) 546–555], Klooster et al. [Automatic quantification of osteoarthritis in hand radiographs: validation of a new method to measure joint space width, Osteoarthritis and Cartilage 16 (1) (2008) 18–25], Ogiela et al. [Image languages in intelligent radiological palm diagnostics, Pattern Recognition 39 (2006) 2157–2165] and Ogiela and Tadeusiewicz [Picture languages in automatic radiological palm interpretation, Int. J. Appl. Math. Comput. Sci. 15 (2) (2005) 305–312].},
author = {Bielecki, Andrzej and Korkosz, Mariusz and Zieliński, Bartosz},
doi = {10.1016/j.patcog.2008.05.032},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bielecki, Korkosz, Zieliński - 2008 - Hand radiographs preprocessing, image representation in the finger regions and joint space width.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Image processing,Joint space width,Medical imaging,Radiology,Rheumatoid arthritis,Thinning,Thresholding,X-ray photo,preprocessing},
mendeley-tags = {preprocessing},
month = {dec},
number = {12},
pages = {3786--3798},
title = {{Hand radiographs preprocessing, image representation in the finger regions and joint space width measurements for image interpretation}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320308002094},
volume = {41},
year = {2008}
}
@article{Boiman2008,
author = {Boiman, Oren and Shechtman, Eli and Irani, Michal},
doi = {10.1109/CVPR.2008.4587598},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boiman, Shechtman, Irani - 2008 - In defense of Nearest-Neighbor based image classification.pdf:pdf},
isbn = {978-1-4244-2242-5},
journal = {IEEE Conference on Computer Vision and Pattern Recognition},
number = {i},
pages = {1--8},
title = {{In defense of Nearest-Neighbor based image classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4587598},
year = {2008}
}
@inproceedings{Borges2013,
abstract = {This paper describes ongoing work on the use of visualization, mining and image analysis techniques to sup- port biologists conducting taxonomic classification of freshwater green microalgae. The classification of such organisms is highly problematic because traditional taxonomy is inconsistent and biologists must carry out complex and meticulous procedures that demand considerable expert knowledge. We are working with biologists to define a visual exploration process characterized by user interaction with visualizations based on similarity trees, that attempt to provide a hierarchical representation of the relationships among green algae families. This requires obtaining representative feature vectors and developing automatic feat ure extractors from green algae images. Preliminary experiments indicate that tree-based visualizations coupled with a visual exploration strategy and an automatic extractor for computing algae morphological features can assist biologists and potentially improve the taxonomic classification process.},
address = {Arequipa, Peru},
author = {Borges, VRP R P and de Oliveira, MCF and Ferreira, TG G and Vieira, AAH A H and de Oliveira, M C F},
booktitle = {XXVI SIBGRAPI - Conference on graphics, patterns and images},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Borges et al. - 2013 - Feature Extraction and Interactive Visualization to Assist Green Algae Taxonomic Classification.pdf:pdf},
keywords = {-visual exploration,classification,feature extraction,green algae,similarity trees},
pages = {4},
title = {{Feature Extraction and Interactive Visualization to Assist Green Algae Taxonomic Classification}},
url = {http://www.ucsp.edu.pe/sibgrapi2013/eproceedings/wip/115151.pdf},
year = {2013}
}
@article{Buades2005,
abstract = {The search for efficient image denoising methods is still a valid challenge at the crossing of functional analysis and statistics. In spite of the sophistication of the recently proposed methods, most algorithms have not yet attained a desirable level of applicability. All show an outstanding performance when the image model corresponds to the algorithm assumptions but fail in general and create artifacts or remove image fine structures. The main focus of this paper is, first, to define a general mathematical and experimental methodology to compare and classify classical image denoising algorithms and, second, to propose a nonlocal means (NL-means) algorithm addressing the preservation of structure in a digital image. The mathematical analysis is based on the analysis of the "method noise," defined as the difference between a digital image and its denoised version. The NL-means algorithm is proven to be asymptotically optimal under a generic statistical image model. The denoising performance of all consid...},
author = {Buades, A. and Coll, B. and Morel, J. M.},
doi = {10.1137/040616024},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buades, Coll, Morel - 2005 - A Review of Image Denoising Algorithms, with a New One.pdf:pdf},
issn = {1540-3459},
journal = {Multiscale Modeling {\&} Simulation},
keywords = {62H35,PDE smoothing filters,adaptive filters,frequency domain filters,image restoration,nonparametric estimation,preprocessing},
language = {en},
mendeley-tags = {preprocessing},
month = {jan},
number = {2},
pages = {490--530},
publisher = {Society for Industrial and Applied Mathematics},
title = {{A Review of Image Denoising Algorithms, with a New One}},
url = {http://epubs.siam.org/doi/abs/10.1137/040616024},
volume = {4},
year = {2005}
}
@article{Burt1981,
abstract = {A highly efficient recursive algorithm is defined for simultaneously convolving an image (or other two-dimensional function) with a set of kernels which differ in width but not in shape. These kernels may closely resemble the Gaussian probability distribution, so that the algorithm generates a set of low-pass or band-pass versions of the image. Image correlation with spot, edge, and bar operators of many sized can be obtained with negligible additional computation},
author = {Burt, Peter J},
doi = {10.1016/0146-664X(81)90092-7},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burt - 1981 - Fast filter transform for image processing.pdf:pdf},
issn = {0146664X},
journal = {Computer Graphics and Image Processing},
month = {may},
number = {1},
pages = {20--51},
title = {{Fast filter transform for image processing}},
url = {http://www.sciencedirect.com/science/article/pii/0146664X81900927},
volume = {16},
year = {1981}
}
@article{Castro2011,
abstract = {Supervised Learning with Imbalanced Data Sets: An Overview Traditional learning algorithms induced by complex and highly imbalanced training sets may have difficulty in dis- tinguishing between examples of the groups. The tendency is to create classification models that are biased toward the overrepresented (majority) class, resulting in a low rate of recognition for the minority group. This paper provides a survey of this problem which has attracted the interest of many researchers in recent years. In the scope of two-class classification tasks, concepts related to the nature of the im- balanced class problem and evaluation metrics are presented, including the foundations of the ROC (Receiver Operating Characteristic) analysis; plus a state of the art of the pro- posed solutions. At the end of the paper a brief discussion on how the subject can be extended to multiclass learning is provided.},
author = {Castro, CL L and Braga, AP P},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Castro, Braga - 2011 - Aprendizado supervisionado com conjuntos de dados desbalanceados.pdf:pdf},
journal = {Sba Controle {\&} Automa{\c{c}}{\~{a}}o},
keywords = {ROC analysis,cost-sensitive approach.,evaluation metrics,imbalanced data sets,resampling methods,supervised learning},
number = {5},
pages = {441 -- 446},
title = {{Aprendizado supervisionado com conjuntos de dados desbalanceados}},
volume = {22},
year = {2011}
}
@article{Chapelle1999a,
abstract = {Traditional classification approaches generalize poorly on image classification tasks, because of the high dimensionality of the feature space. This paper shows that support vector machines (SVM's) can generalize well on difficult image classification problems where the only features are high dimensional histograms. Heavy-tailed RBF kernels of the form K(x, y) = e(-rho)Sigma(i)/xia-yia/b with a < or = 1 and b < or = 2 are evaluated on the classification of images extracted from the Corel stock photo collection and shown to far outperform traditional polynomial or Gaussian radial basis function (RBF) kernels. Moreover, we observed that a simple remapping of the input x(i)-->x(i)(a) improves the performance of linear SVM's to such an extend that it makes them, for this problem, a valid alternative to RBF kernels.},
author = {Chapelle, O and Haffner, P and Vapnik, V N},
doi = {10.1109/72.788646},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chapelle, Haffner, Vapnik - 1999 - Support vector machines for histogram-based image classification.pdf:pdf},
issn = {1045-9227},
journal = {IEEE transactions on neural networks},
keywords = {Classification tree analysis,Corel stock photo collection,Histograms,Image classification,Image databases,Image recognition,Kernel,Polynomials,Support vector machine classification,Support vector machines,Web pages,classification,corel,feature space dimensionality,heavy-tailed RBF kernels,high-dimensional histograms,histogram,histogram-based image classification,image classification,learning (artificial intelligence),linear SVM,radial basis function networks,remapping,support vector machines,svm},
mendeley-tags = {classification,corel,histogram,svm},
month = {jan},
number = {5},
pages = {1055--64},
pmid = {18252608},
shorttitle = {Neural Networks, IEEE Transactions on},
title = {{Support vector machines for histogram-based image classification.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18252608},
volume = {10},
year = {1999}
}
@article{Chatfield2014,
abstract = {The latest generation of Convolutional Neural Networks (CNN) have achieved impressive results in challenging benchmarks on image recognition and object detection, significantly raising the interest of the community in these methods. Nevertheless, it is still unclear how different CNN methods compare with each other and with previous state-of-the-art shallow representations such as the Bag-of-Visual-Words and the Improved Fisher Vector. This paper conducts a rigorous evaluation of these new techniques, exploring different deep architectures and comparing them on a common ground, identifying and disclosing important implementation details. We identify several useful properties of CNN-based representations, including the fact that the dimensionality of the CNN output layer can be reduced significantly without having an adverse effect on performance. We also identify aspects of deep and shallow methods that can be successfully shared. In particular, we show that the data augmentation techniques commonly applied to CNN-based methods can also be applied to shallow methods, and result in an analogous performance boost. Source code and models to reproduce the experiments in the paper is made publicly available.},
annote = {
        From Duplicate 1 ( 
        

        
          

        
        
          Return of the Devil in the Details: Delving Deep into Convolutional Nets
        
        
          

        
        

         - Chatfield, Ken; Simonyan, Karen; Vedaldi, Andrea; Zisserman, Andrew )

          

        
        

        

        

        

        

        

        

      },
archivePrefix = {arXiv},
arxivId = {1405.3531},
author = {Chatfield, Ken and Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
eprint = {1405.3531},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chatfield et al. - 2014 - Return of the Devil in the Details Delving Deep into Convolutional Nets.pdf:pdf},
journal = {British Machine Vision Conference},
month = {may},
title = {{Return of the Devil in the Details: Delving Deep into Convolutional Nets}},
url = {http://arxiv.org/abs/1405.3531},
year = {2014}
}
@article{Chawlaa,
author = {Chawla, Nitesh V and Lazarevic, Aleksandar and Hall, Lawrence O and Bowyer, Kevin},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chawla et al. - Unknown - SMOTEBoost Improving Prediction of the Minority Class in Boosting.pdf:pdf},
title = {{SMOTEBoost: Improving Prediction of the Minority Class in Boosting}}
}
@article{Chawla2004,
author = {Chawla, Nitesh V. and Japkowicz, Nathalie and Kotcz, Aleksander},
doi = {10.1145/1007730.1007733},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chawla, Japkowicz, Kotcz - 2004 - Editorial special issue on learning from imbalanced data sets.pdf:pdf},
issn = {19310145},
journal = {ACM SIGKDD Explorations Newsletter},
month = {jun},
number = {1},
pages = {1},
publisher = {ACM},
title = {{Editorial: special issue on learning from imbalanced data sets}},
url = {http://dl.acm.org/citation.cfm?id=1007730.1007733},
volume = {6},
year = {2004}
}
@article{Chawla,
annote = {
        From Duplicate 1 ( 
        
          Data mining for imbalanced datasets: An overview
        
         - Chawla, NV )

        
        

        

        

      },
author = {Chawla, NV V},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chawla - 2005 - Data mining for imbalanced datasets An overview.pdf:pdf},
journal = {Data mining and knowledge discovery handbook},
pages = {853--867},
title = {{Data mining for imbalanced datasets: An overview}},
url = {http://link.springer.com/chapter/10.1007/0-387-25465-X{\_}40},
year = {2005}
}
@article{Chawla2002,
author = {Chawla, NV V and Hall, LO O and Bowyer, KW W},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chawla, Hall, Bowyer - 2002 - SMOTE Synthetic Minority Over-sampling Technique.pdf:pdf},
journal = {Journal of Artificial Intelligence Research},
pages = {321--357},
title = {{SMOTE: Synthetic Minority Over-sampling Technique}},
url = {http://link.springer.com/chapter/10.1007/3-540-45428-4{\_}5 http://arxiv.org/abs/1106.1813},
volume = {16},
year = {2002}
}
@article{Chellappa2012,
abstract = {In this discussion paper, I present my views on the role on mathematical statistics for solving computer vision problems.},
author = {Chellappa, Rama},
doi = {10.1016/j.imavis.2012.03.008},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chellappa - 2012 - Mathematical statistics and computer vision.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Computer vision,Manifolds,Markov random fields,Mathematical statistics,Particle filters,Simulated annealing,computer vision,mathematical statistics},
mendeley-tags = {computer vision,mathematical statistics},
month = {aug},
number = {8},
pages = {467--468},
title = {{Mathematical statistics and computer vision}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885612000674},
volume = {30},
year = {2012}
}
@article{Chen2015,
archivePrefix = {arXiv},
arxivId = {1412.7062},
author = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
eprint = {1412.7062},
file = {:home/gabi/Downloads/1412.7062v3.pdf:pdf},
journal = {Iclr},
pages = {1--14},
title = {{Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs}},
url = {http://arxiv.org/abs/1412.7062},
year = {2015}
}
@article{Chen2010,
author = {Chen, Qiang and Xu, Xin and Sun, Quansen and Xia, Deshen},
doi = {10.1016/j.sigpro.2009.05.015},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2010 - A solution to the deficiencies of image enhancement.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Contrast loss,Detail loss,Gray-world violation,Image enhancement,Image fusion},
number = {1},
pages = {44--56},
publisher = {Elsevier},
title = {{A solution to the deficiencies of image enhancement}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168409002448},
volume = {90},
year = {2010}
}
@article{Cheng2010,
abstract = {Breast cancer is the second leading cause of death for women all over the world. Since the cause of the disease remains unknown, early detection and diagnosis is the key for breast cancer control, and it can increase the success of treatment, save lives and reduce cost. Ultrasound imaging is one of the most frequently used diagnosis tools to detect and classify abnormalities of the breast. In order to eliminate the operator dependency and improve the diagnostic accuracy, computer-aided diagnosis (CAD) system is a valuable and beneficial means for breast cancer detection and classification. Generally, a CAD system consists of four stages: preprocessing, segmentation, feature extraction and selection, and classification. In this paper, the approaches used in these stages are summarized and their advantages and disadvantages are discussed. The performance evaluation of CAD system is investigated as well.},
author = {Cheng, H.D. D and Shan, Juan and Ju, Wen and Guo, Yanhui and Zhang, Ling},
doi = {10.1016/j.patcog.2009.05.012},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheng et al. - 2010 - Automated breast cancer detection and classification using ultrasound images A survey.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Automated breast cancer detection and classificati,CAD (computer-aided diagnosis),Classifiers,Feature extraction and selection,Ultrasound (US) imaging,preprocessing},
mendeley-tags = {preprocessing},
month = {jan},
number = {1},
pages = {299--317},
title = {{Automated breast cancer detection and classification using ultrasound images: A survey}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320309002027},
volume = {43},
year = {2010}
}
@inproceedings{Cheng2011,
abstract = {Reliable estimation of visual saliency allows appropriate processing of images without prior knowledge of their contents, and thus remains an important step in many computer vision tasks including image segmentation, object recognition, and adaptive compression. We propose a regional contrast based saliency extraction algorithm, which simultaneously evaluates global contrast differences and spatial coherence. The proposed algorithm is simple, efficient, and yields full resolution saliency maps. Our algorithm consistently outperformed existing saliency detection methods, yielding higher precision and better recall rates, when evaluated using one of the largest publicly available data sets. We also demonstrate how the extracted saliency map can be used to create high quality segmentation masks for subsequent image processing.},
author = {Cheng, Ming-Ming and Zhang, Guo-Xin and Mitra, Niloy J. and Huang, Xiaolei and Hu, Shi-Min},
booktitle = {CVPR 2011},
doi = {10.1109/CVPR.2011.5995344},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheng et al. - 2011 - Global contrast based salient region detection.pdf:pdf},
isbn = {978-1-4577-0394-2},
issn = {1063-6919},
keywords = {Histograms,Humans,Image color analysis,Image segmentation,Quantization,Smoothing methods,Visualization,adaptive compression,computer vision,feature extraction,full resolution saliency maps,global contrast based salient region detection,high quality segmentation,image processing,image resolution,image segmentation,object recognition,regional contrast based saliency extraction algori,spatial coherence,visual saliency estimation reliability},
month = {jun},
pages = {409--416},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Global contrast based salient region detection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5995344},
year = {2011}
}
@article{Condat2010,
abstract = {We propose two new types of random patterns with R, G, B colors, which allow to design color filter arrays (CFAs) with good spectral properties. Indeed, the chrominance channels have blue noise characteristics, a property which maximizes the robustness of the acquisition system to aliasing. With these new CFAs, the demosaicking artifacts appear as incoherent noise, which is less visually disturbing than the moir{\'{e}} structures characteristic of CFAs with periodic patterns.},
author = {Condat, Laurent},
doi = {10.1016/j.imavis.2009.12.004},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Condat - 2010 - Color filter array design using random patterns with blue noise chromatic spectra.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Blue noise,Color filter array,Demosaicking,Random pattern},
month = {aug},
number = {8},
pages = {1196--1202},
title = {{Color filter array design using random patterns with blue noise chromatic spectra}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885609002741},
volume = {28},
year = {2010}
}
@article{Cover1967,
abstract = {The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points. This rule is independent of the underlying joint distribution on the sample points and their classifications, and hence the probability of error  of such a rule must be at least as great as the Bayes probability of error  --the minimum probability of error over all decision rules taking underlying probability structure into account. However, in a large sample analysis, we will show in the  -category case that  , where these bounds are the tightest possible, for all suitably smooth underlying distributions. Thus for any number of categories, the probability of error of the nearest neighbor rule is bounded above by twice the Bayes probability of error. In this sense, it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor.},
author = {Cover, T. and Hart, P.},
doi = {10.1109/TIT.1967.1053964},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
keywords = {Pattern classification},
month = {jan},
number = {1},
pages = {21--27},
shorttitle = {Information Theory, IEEE Transactions on},
title = {{Nearest neighbor pattern classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1053964},
volume = {13},
year = {1967}
}
@article{Cover1967a,
abstract = {The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points. This rule is independent of the underlying joint distribution on the sample points and their classifications, and hence the probability of error<tex>R</tex>of such a rule must be at least as great as the Bayes probability of error<tex>R{\^{}}{\{}ast{\}}</tex>--the minimum probability of error over all decision rules taking underlying probability structure into account. However, in a large sample analysis, we will show in the<tex>M</tex>-category case that<tex>R{\^{}}{\{}ast{\}} leq R leq R{\^{}}{\{}ast{\}}(2 --MR{\^{}}{\{}ast{\}}/(M-1))</tex>, where these bounds are the tightest possible, for all suitably smooth underlying distributions. Thus for any number of categories, the probability of error of the nearest neighbor rule is bounded above by twice the Bayes probability of error. In this sense, it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor.},
author = {Cover, T. and Hart, P.},
doi = {10.1109/TIT.1967.1053964},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cover, Hart - 1967 - Nearest neighbor pattern classification.pdf:pdf},
isbn = {0018-9448},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
number = {1},
pages = {21--27},
pmid = {21919855},
title = {{Nearest neighbor pattern classification}},
volume = {13},
year = {1967}
}
@article{Crone2012,
abstract = {To date, best practice in sampling credit applicants has been established based largely on expert opinion, which generally recommends that small samples of 1500 instances each of both goods and bads are sufficient, and that the heavily biased datasets observed should be balanced by undersampling the majority class. Consequently, the topics of sample sizes and sample balance have not been subject to either formal study in credit scoring, or empirical evaluations across different data conditions and algorithms of varying efficiency. This paper describes an empirical study of instance sampling in predicting consumer repayment behaviour, evaluating the relative accuracies of logistic regression, discriminant analysis, decision trees and neural networks on two datasets across 20 samples of increasing size and 29 rebalanced sample distributions created by gradually under- and over-sampling the goods and bads respectively. The paper makes a practical contribution to model building on credit scoring datasets, and provides evidence that using samples larger than those recommended in credit scoring practice provides a significant increase in accuracy across algorithms.},
author = {Crone, Sven F. and Finlay, Steven},
doi = {10.1016/j.ijforecast.2011.07.006},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Crone, Finlay - 2012 - Instance sampling in credit scoring An empirical study of sample size and balancing.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Balancing,Credit scoring,Data pre-processing,Over-sampling,Sample size,Under-sampling},
month = {jan},
number = {1},
pages = {224--238},
title = {{Instance sampling in credit scoring: An empirical study of sample size and balancing}},
url = {http://www.sciencedirect.com/science/article/pii/S0169207011001403},
volume = {28},
year = {2012}
}
@article{D.RandallWilson,
author = {{D. Randall Wilson}, Tony R. Martinez},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/D. Randall Wilson - Unknown - Reduction Techniques for Exemplar-Based Learning Algorithms.pdf:pdf},
title = {{Reduction Techniques for Exemplar-Based Learning Algorithms}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.50.6544}
}
@article{Dai,
author = {Dai, Xiyang},
file = {:home/gabi/Downloads/CVPR2015{\_}CasCNN.pdf:pdf},
isbn = {9781479953134},
journal = {Cs.Nyu.Edu},
title = {{A Convolutional Neural Network Approach for Face Identification}},
url = {http://www.cs.nyu.edu/{~}xd283/face2012.pdf}
}
@inproceedings{Dalal2005,
abstract = {We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
author = {Dalal, N. and Triggs, B.},
booktitle = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
doi = {10.1109/CVPR.2005.177},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dalal, Triggs - 2005 - Histograms of Oriented Gradients for Human Detection.pdf:pdf},
isbn = {0-7695-2372-2},
issn = {1063-6919},
keywords = {High performance computing,Histograms,Humans,Image databases,Image edge detection,Object detection,Object recognition,Robustness,Support vector machines,Testing,coarse spatial binning,contrast normalization,edge based descriptors,feature extraction,fine orientation binning,fine-scale gradients,gradient based descriptors,gradient methods,histograms of oriented gradients,human detection,linear SVM,object detection,object recognition,overlapping descriptor,pedestrian database,robust visual object recognition,support vector machines},
pages = {886--893},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition, 2005. CVP},
title = {{Histograms of Oriented Gradients for Human Detection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1467360},
volume = {1},
year = {2005}
}
@article{mahalanobis2000,
abstract = {The theory of many multivariate chemometrical methods is based on the measurement of distances. The Mahalanobis distance (MD), in the original and principal component (PC) space, will be examined and interpreted in relation with the Euclidean distance (ED). Techniques based on the MD and applied in different fields of chemometrics such as in multivariate calibration, pattern recognition and process control are explained and discussed.},
author = {{De Maesschalck}, R. and Jouan-Rimbaud, D. and Massart, D.L.},
doi = {10.1016/S0169-7439(99)00047-7},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Maesschalck, Jouan-Rimbaud, Massart - 2000 - The Mahalanobis distance.pdf:pdf},
issn = {01697439},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {Euclidean distance,Mahalanobis distance,Principal components},
month = {jan},
number = {1},
pages = {1--18},
title = {{The Mahalanobis distance}},
url = {http://www.sciencedirect.com/science/article/pii/S0169743999000477},
volume = {50},
year = {2000}
}
@article{DeMesquitaSaJunior2014,
abstract = {Color textures are among the most important visual attributes in image analysis. This paper presents a novel method to analyze color textures by modeling a color image as a graph in two different and complementary manners (each color channel separately and the three color channels altogether) and by obtaining statistical moments from the shortest paths between specific vertices of this graph. Such an approach allows to create a set of feature vectors, which were extracted from VisTex, USPTex, and TC00013 color texture databases. The best classification results were 99.07{\%}, 96.85{\%}, and 91.54{\%} (LDA with leave-one-out), 87.62{\%}, 66.71{\%}, and 88.06{\%} (1NN with holdout), and 98.62{\%}, 96.16{\%}, and 91.34{\%} (LDA with holdout) of success rate (percentage of samples correctly classified) for these three databases, respectively. These results prove that the proposed approach is a powerful tool for color texture analysis to be explored.},
author = {{de Mesquita Sa Junior}, Jarbas Joaci and Cortez, Paulo Cesar and Backes, Andre Ricardo},
doi = {10.1109/TIP.2014.2333655},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Mesquita Sa Junior, Cortez, Backes - 2014 - Color texture classification using shortest paths in graphs.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
month = {sep},
number = {9},
pages = {3751--3761},
pmid = {24988594},
title = {{Color texture classification using shortest paths in graphs.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24988594},
volume = {23},
year = {2014}
}
@article{Denton,
abstract = {In this paper we introduce a generative parametric model capable of producing high quality samples of natural images. Our approach uses a cascade of convo-lutional networks within a Laplacian pyramid framework to generate images in a coarse-to-fine fashion. At each level of the pyramid, a separate generative con-vnet model is trained using the Generative Adversarial Nets (GAN) approach [10]. Samples drawn from our model are of significantly higher quality than alternate approaches. In a quantitative assessment by human evaluators, our CIFAR10 sam-ples were mistaken for real images around 40{\%} of the time, compared to 10{\%} for samples drawn from a GAN baseline model. We also show samples from models trained on the higher resolution images of the LSUN scene dataset.},
archivePrefix = {arXiv},
arxivId = {arXiv:1506.05751v1},
author = {Denton, Emily and Chintala, Soumith and Szlam, Arthur and Fergus, Rob},
eprint = {arXiv:1506.05751v1},
file = {:home/gabi/Downloads/1506.05751v1.pdf:pdf},
pages = {1--10},
title = {{Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks}}
}
@article{Derrac2014a,
abstract = {The analysis of the performance of different approaches is a staple concern in the design of Computational Intelligence experiments. Any proper analysis of evolutionary optimization algorithms should incorporate a full set of benchmark problems and state-of-the-art comparison algorithms. For the sake of rigor, such an analysis may be completed with the use of statistical procedures, supporting the conclusions drawn. In this paper, we point out that these conclusions are usually limited to the final results, whereas intermediate results are seldom considered. We propose a new methodology for comparing evolutionary algorithms’ convergence capabilities, based on the use of Page’s trend test. The methodology is presented with a case of use, incorporating real results from selected techniques of a recent special issue. The possible applications of the method are highlighted, particularly in those cases in which the final results do not enable a clear evaluation of the differences among several evolutionary techniques.},
author = {Derrac, Joaqu{\'{\i}}n and Garc{\'{\i}}a, Salvador and Hui, Sheldon and Suganthan, Ponnuthurai Nagaratnam and Herrera, Francisco},
doi = {10.1016/j.ins.2014.06.009},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Derrac et al. - 2014 - Analyzing convergence performance of evolutionary algorithms A statistical approach.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Convergence-based algorithmic comparison,Evolutionary algorithms,Nonparametric tests,Page’s trend test},
month = {dec},
pages = {41--58},
title = {{Analyzing convergence performance of evolutionary algorithms: A statistical approach}},
url = {http://www.sciencedirect.com/science/article/pii/S0020025514006276},
volume = {289},
year = {2014}
}
@article{Donahue2013,
abstract = {We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.},
archivePrefix = {arXiv},
arxivId = {1310.1531},
author = {Donahue, Jeff and Jia, Yangqing and Vinyals, Oriol and Hoffman, Judy and Zhang, Ning and Tzeng, Eric and Darrell, Trevor},
eprint = {1310.1531},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Donahue et al. - 2013 - DeCAF A Deep Convolutional Activation Feature for Generic Visual Recognition.pdf:pdf},
month = {oct},
title = {{DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition}},
url = {http://arxiv.org/abs/1310.1531},
year = {2013}
}
@misc{Drummond2003,
author = {Drummond, Chris and Holte, Robert C.},
booktitle = {Workshop on Learning from Imbalanced Datasets II},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Drummond, Holte - 2003 - C4.5, Class Imbalance, and Cost Sensitivity Why Under-Sampling beats Over-Sampling.pdf:pdf},
title = {{C4.5, Class Imbalance, and Cost Sensitivity: Why Under-Sampling beats Over-Sampling}},
url = {https://www.site.uottawa.ca/{~}nat/Workshop2003/drummondc.pdf},
urldate = {2014-10-13},
year = {2003}
}
@article{Egmont-Petersen2002,
abstract = {We review more than 200 applications of neural networks in image processing and discuss the present and possible future role of neural networks, especially feed-forward neural networks, Kohonen feature maps and Hopfield neural networks. The various applications are categorised into a novel two-dimensional taxonomy for image processing algorithms. One dimension specifies the type of task performed by the algorithm: preprocessing, data reduction/feature extraction, segmentation, object recognition, image understanding and optimisation. The other dimension captures the abstraction level of the input data processed by the algorithm: pixel-level, local feature-level, structure-level, object-level, object-set-level and scene characterisation. Each of the six types of tasks poses specific constraints to a neural-based approach. These specific conditions are discussed in detail. A synthesis is made of unresolved problems related to the application of pattern recognition techniques in image processing and specifically to the application of neural networks. Finally, we present an outlook into the future application of neural networks and relate them to novel developments.},
author = {Egmont-Petersen, M. and de Ridder, D. and Handels, H.},
doi = {10.1016/S0031-3203(01)00178-9},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Egmont-Petersen, de Ridder, Handels - 2002 - Image processing with neural networks—a review.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Digital image processing,Feature extraction,Image compression,Image understanding,Invariant pattern recognition,Neural networks,Object recognition,Optimization,Preprocessing,Segmentation,preprocessing},
mendeley-tags = {preprocessing},
month = {oct},
number = {10},
pages = {2279--2301},
title = {{Image processing with neural networks—a review}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320301001789},
volume = {35},
year = {2002}
}
@article{Estabrooks2004,
author = {Estabrooks, Andrew and Jo, Taeho and Japkowicz, Nathalie},
doi = {10.1111/j.0824-7935.2004.t01-1-00228.x},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Estabrooks, Jo, Japkowicz - 2004 - A Multiple Resampling Method for Learning from Imbalanced Data Sets.pdf:pdf},
issn = {0824-7935},
journal = {Computational Intelligence},
month = {feb},
number = {1},
pages = {18--36},
title = {{A Multiple Resampling Method for Learning from Imbalanced Data Sets}},
url = {http://doi.wiley.com/10.1111/j.0824-7935.2004.t01-1-00228.x},
volume = {20},
year = {2004}
}
@book{Faceli2011,
author = {Faceli, K},
publisher = {Grupo Gen-LTC},
title = {{Intelig{\^{e}}ncia artificial: uma abordagem de aprendizado de m{\'{a}}quina}},
year = {2011}
}
@article{Farfade2015,
archivePrefix = {arXiv},
arxivId = {1502.02766v3},
author = {Farfade, Sachin S. and Saberian, Mohammad and Li, Li-Jia},
eprint = {1502.02766v3},
file = {:home/gabi/Downloads/1502.02766v3.pdf:pdf},
isbn = {9781450332743},
keywords = {convolutional neural network,deep learning,face detection},
pages = {8},
title = {{Multi-view Face Detection Using Deep Convolutional Neural Networks}},
url = {http://arxiv.org/pdf/1502.02766.pdf},
year = {2015}
}
@article{Farquad2012,
abstract = {This paper deals with the application of support vector machine (SVM) to deal with the class imbalance problem. The objective of this paper is to examine the feasibility and efficiency of SVM as a preprocessor. Our study analyzes different classification algorithms that are employed to predict the customers with caravan car policy based on his/her sociodemographic data and history of product ownership. A series of experiments was conducted to test various computational intelligence techniques viz., Multilayer Perceptron (MLP), Logistic Regression (LR), and Random Forest (RF). Various standard balancing techniques such as under-sampling, over-sampling and Synthetic Minority Over-sampling TEchnique (SMOTE) are also employed. Subsequently, a strategy of data balancing for handling imbalanced distribution in data is proposed. The proposed approach first employs SVM as a preprocessor and the actual target values of training data are then replaced by the predictions of trained SVM. Later, this modified training data is used to train techniques such as MLP, LR, and RF. Based on the measure of sensitivity, it is observed that the proposed approach not only balances the data effectively but also provides more number of instances for minority class, which in turn enhances the performance of the intelligence techniques.},
author = {Farquad, M.A.H. A H and Bose, Indranil},
doi = {10.1016/j.dss.2012.01.016},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farquad, Bose - 2012 - Preprocessing unbalanced data using support vector machine.pdf:pdf},
issn = {01679236},
journal = {Decision Support Systems},
keywords = {COIL data,Hybrid method,Preprocessor,SVM,Unbalanced data,imbalancing},
mendeley-tags = {imbalancing},
month = {apr},
number = {1},
pages = {226--233},
title = {{Preprocessing unbalanced data using support vector machine}},
url = {http://www.sciencedirect.com/science/article/pii/S0167923612000425},
volume = {53},
year = {2012}
}
@article{Fawcett2006,
abstract = {Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.},
author = {Fawcett, Tom},
doi = {10.1016/j.patrec.2005.10.010},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fawcett - 2006 - An introduction to ROC analysis.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Classifier evaluation,Evaluation metrics,ROC analysis},
month = {jun},
number = {8},
pages = {861--874},
title = {{An introduction to ROC analysis}},
url = {http://www.sciencedirect.com/science/article/pii/S016786550500303X},
volume = {27},
year = {2006}
}
@article{Fei-Fei2007,
abstract = {Current computational approaches to learning visual object categories require thousands of training images, are slow, cannot learn in an incremental manner and cannot incorporate prior information into the learning process. In addition, no algorithm presented in the literature has been tested on more than a handful of object categories. We present an method for learning object categories from just a few training images. It is quick and it uses prior information in a principled way. We test it on a dataset composed of images of objects belonging to 101 widely varied categories. Our proposed method is based on making use of prior information, assembled from (unrelated) object categories which were previously learnt. A generative probabilistic model is used, which represents the shape and appearance of a constellation of features belonging to the object. The parameters of the model are learnt incrementally in a Bayesian manner. Our incremental algorithm is compared experimentally to an earlier batch Bayesian algorithm, as well as to one based on maximum likelihood. The incremental and batch versions have comparable classification performance on small training sets, but incremental learning is significantly faster, making real-time learning feasible. Both Bayesian methods outperform maximum likelihood on small training sets.},
author = {Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
doi = {10.1016/j.cviu.2005.09.012},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fei-Fei, Fergus, Perona - 2007 - Learning generative visual models from few training examples An incremental Bayesian approach tested on.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {Bayesian model,Categorization,Generative model,Incremental learning,Object recognition},
month = {apr},
number = {1},
pages = {59--70},
title = {{Learning generative visual models from few training examples: An incremental Bayesian approach tested on 101 object categories}},
url = {http://www.sciencedirect.com/science/article/pii/S1077314206001688},
volume = {106},
year = {2007}
}
@inproceedings{Fergus2005,
abstract = {Current approaches to object category recognition require datasets of training images to be manually prepared, with varying degrees of supervision. We present an approach that can learn an object category from just its name, by utilizing the raw output of image search engines available on the Internet. We develop a new model, TSI-pLSA, which extends pLSA (as applied to visual words) to include spatial information in a translation and scale invariant manner. Our approach can handle the high intra-class variability and large proportion of unrelated images returned by search engines. We evaluate tire models on standard test sets, showing performance competitive with existing methods trained on hand prepared datasets},
author = {Fergus, R. and Fei-Fei, L. and Perona, P. and Zisserman, A.},
booktitle = {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
doi = {10.1109/ICCV.2005.142},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fergus et al. - 2005 - Learning object categories from Google's image search.pdf:pdf},
isbn = {0-7695-2334-X},
issn = {1550-5499},
keywords = {Airplanes,Computer vision,Google,Image recognition,Image segmentation,Internet,Motorcycles,Search engines,TSI-pLSA,Testing,Watches,Wrist,classification,image classification,image retrieval,image search engines,object category learning,object category recognition,search engines},
pages = {1816----1823 Vol. 2},
publisher = {IEEE},
shorttitle = {Computer Vision, 2005. ICCV 2005. Tenth IEEE Inter},
title = {{Learning object categories from Google's image search}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1544937},
volume = {2},
year = {2005}
}
@article{Fernandez-Navarro2011,
abstract = {Classification with imbalanced datasets supposes a new challenge for researches in the framework of machine learning. This problem appears when the number of patterns that represents one of the classes of the dataset (usually the concept of interest) is much lower than in the remaining classes. Thus, the learning model must be adapted to this situation, which is very common in real applications. In this paper, a dynamic over-sampling procedure is proposed for improving the classification of imbalanced datasets with more than two classes. This procedure is incorporated into a memetic algorithm (MA) that optimizes radial basis functions neural networks (RBFNNs). To handle class imbalance, the training data are resampled in two stages. In the first stage, an over-sampling procedure is applied to the minority class to balance in part the size of the classes. Then, the MA is run and the data are over-sampled in different generations of the evolution, generating new patterns of the minimum sensitivity class (the class with the worst accuracy for the best RBFNN of the population). The methodology proposed is tested using 13 imbalanced benchmark classification datasets from well-known machine learning problems and one complex problem of microbial growth. It is compared to other neural network methods specifically designed for handling imbalanced data. These methods include different over-sampling procedures in the preprocessing stage, a threshold-moving method where the output threshold is moved toward inexpensive classes and ensembles approaches combining the models obtained with these techniques. The results show that our proposal is able to improve the sensitivity in the generalization set and obtains both a high accuracy level and a good classification level for each class.},
author = {Fern{\'{a}}ndez-Navarro, Francisco and Herv{\'{a}}s-Mart{\'{\i}}nez, C{\'{e}}sar and {Antonio Guti{\'{e}}rrez}, Pedro},
doi = {10.1016/j.patcog.2011.02.019},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fern{\'{a}}ndez-Navarro, Herv{\'{a}}s-Mart{\'{\i}}nez, Antonio Guti{\'{e}}rrez - 2011 - A dynamic over-sampling procedure based on sensitivity for multi-clas.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Accuracy,Classification,Imbalanced datasets,Memetic algorithm,Multi-class,Over-sampling method,SMOTE,Sensitivity},
month = {aug},
number = {8},
pages = {1821--1833},
title = {{A dynamic over-sampling procedure based on sensitivity for multi-class problems}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320311000823},
volume = {44},
year = {2011}
}
@article{Fischer2014,
abstract = {Restricted Boltzmann machines (RBMs) are probabilistic graphical models that can be interpreted as stochastic neural networks. They have attracted much attention as building blocks for the multi-layer learning systems called deep belief networks, and variants and extensions of RBMs have found application in a wide range of pattern recognition tasks. This tutorial introduces RBMs from the viewpoint of Markov random fields, starting with the required concepts of undirected graphical models. Different learning algorithms for RBMs, including contrastive divergence learning and parallel tempering, are discussed. As sampling from RBMs, and therefore also most of their learning algorithms, are based on Markov chain Monte Carlo (MCMC) methods, an introduction to Markov chains and MCMC techniques is provided. Experiments demonstrate relevant aspects of RBM training.},
author = {Fischer, Asja and Igel, Christian},
doi = {10.1016/j.patcog.2013.05.025},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fischer, Igel - 2014 - Training restricted Boltzmann machines An introduction.pdf:pdf;:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fischer, Igel - 2014 - Training restricted Boltzmann machines An introduction(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Contrastive divergence learning,Gibbs sampling,Markov chains,Markov random fields,Neural networks,Parallel tempering,Restricted Boltzmann machines},
month = {jan},
number = {1},
pages = {25--39},
title = {{Training restricted Boltzmann machines: An introduction}},
volume = {47},
year = {2014}
}
@inproceedings{google09,
abstract = {The last two years have witnessed the introduction and rapid expansion of products based upon large, systematically-gathered, street-level image collections, such as Google Street View, EveryScape, and Mapjack. In the process of gathering images of public spaces, these projects also capture license plates, faces, and other information considered sensitive from a privacy standpoint. In this work, we present a system that addresses the challenge of automatically detecting and blurring faces and license plates for the purpose of privacy protection in Google Street View. Though some in the field would claim face detection is “solved”, we show that state-of-the-art face detectors alone are not sufficient to achieve the recall desired for large-scale privacy protection. In this paper we present a system that combines a standard sliding-window detector tuned for a high recall, low-precision operating point with a fast post-processing stage that is able to remove additional false positives by incorporating domain-specific information not available to the sliding-window detector. Using a completely automatic system, we are able to sufficiently blur more than 89{\%} of faces and 94 - 96{\%} of license plates in evaluation sets sampled from Google Street View imagery.},
author = {Frome, Andrea and Cheung, German and Abdulkader, Ahmad and Zennaro, Marco and Bissacco, Alessandro and Adam, Hartwig and Neven, Hartmut and Vincent, Luc},
booktitle = {2009 IEEE 12th International Conference on Computer Vision},
doi = {10.1109/ICCV.2009.5459413},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frome et al. - 2009 - Large-scale privacy protection in Google Street View.pdf:pdf},
isbn = {978-1-4244-4420-5},
issn = {1550-5499},
keywords = {Automatic control,Cameras,Computer vision,Continents,Detectors,EveryScape,Face detection,Google Street View,Large-scale systems,Licenses,Mapjack,Privacy,Protection,data privacy,face blurring,face detection,face detectors,face recognition,image gathering,privacy protection,sliding-window detector},
month = {sep},
pages = {2373--2380},
publisher = {IEEE},
shorttitle = {Computer Vision, 2009 IEEE 12th International Conf},
title = {{Large-scale privacy protection in Google Street View}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5459413},
year = {2009}
}
@article{Galbally2014,
author = {Galbally, Javier and Marcel, Sebastien and Fierrez, Julian},
doi = {10.1109/TIP.2013.2292332},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Galbally, Marcel, Fierrez - 2014 - Image Quality Assessment for Fake Biometric Detection Application to Iris, Fingerprint, and Face Reco.pdf:pdf},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
month = {feb},
number = {2},
pages = {710--724},
title = {{Image Quality Assessment for Fake Biometric Detection: Application to Iris, Fingerprint, and Face Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6671991},
volume = {23},
year = {2014}
}
@article{Garc2009,
author = {Garc, V},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garc - 2009 - Index of Balanced Accuracy A Performance Measure.pdf:pdf},
pages = {441--448},
title = {{Index of Balanced Accuracy : A Performance Measure}},
year = {2009}
}
@article{Garcia2009,
abstract = {With the continuous expansion of data availability in many large-scale, complex, and networked systems, such as surveillance, security, Internet, and finance, it becomes critical to advance the fundamental understanding of knowledge discovery and analysis from raw data to support decision-making processes. Although existing knowledge discovery and data engineering techniques have shown great success in many real-world applications, the problem of learning from imbalanced data (the imbalanced learning problem) is a relatively new challenge that has attracted growing attention from both academia and industry. The imbalanced learning problem is concerned with the performance of learning algorithms in the presence of underrepresented data and severe class distribution skews. Due to the inherent complex characteristics of imbalanced data sets, learning from such data requires new understandings, principles, algorithms, and tools to transform vast amounts of raw data efficiently into information and knowledge representation. In this paper, we provide a comprehensive review of the development of research in learning from imbalanced data. Our focus is to provide a critical review of the nature of the problem, the state-of-the-art technologies, and the current assessment metrics used to evaluate learning performance under the imbalanced learning scenario. Furthermore, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potential important research directions for learning from imbalanced data.},
author = {Garcia, E.A. A},
doi = {10.1109/TKDE.2008.239},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garcia - 2009 - Learning from Imbalanced Data.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Imbalanced learning,active learning,assessment metrics.,classification,complex systems,cost-sensitive learning,data availability,data engineering,data mining,decision making,imbalanced data,kernel-based learning,knowledge discovery,large-scale systems,learning,learning (artificial intelligence),networked systems,sampling methods},
month = {sep},
number = {9},
pages = {1263--1284},
shorttitle = {Knowledge and Data Engineering, IEEE Transactions},
title = {{Learning from Imbalanced Data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5128907},
volume = {21},
year = {2009}
}
@article{friedman2010,
abstract = {Experimental analysis of the performance of a proposed method is a crucial and necessary task in an investigation. In this paper, we focus on the use of nonparametric statistical inference for analyzing the results obtained in an experiment design in the field of computational intelligence. We present a case study which involves a set of techniques in classification tasks and we study a set of nonparametric procedures useful to analyze the behavior of a method with respect to a set of algorithms, such as the framework in which a new proposal is developed. Particularly, we discuss some basic and advanced nonparametric approaches which improve the results offered by the Friedman test in some circumstances. A set of post hoc procedures for multiple comparisons is presented together with the computation of adjusted p-values. We also perform an experimental analysis for comparing their power, with the objective of detecting the advantages and disadvantages of the statistical tests described. We found that some aspects such as the number of algorithms, number of data sets and differences in performance offered by the control method are very influential in the statistical tests studied. Our final goal is to offer a complete guideline for the use of nonparametric statistical procedures for performing multiple comparisons in experimental studies.},
author = {Garc{\'{\i}}a, Salvador and Fern{\'{a}}ndez, Alberto and Luengo, Juli{\'{a}}n and Herrera, Francisco},
doi = {10.1016/j.ins.2009.12.010},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garc{\'{\i}}a et al. - 2010 - Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Computational intelligence,Data mining,Fuzzy classification systems,Genetics-based machine learning,Multiple comparisons procedures,Nonparametric statistics,Statistical analysis},
month = {may},
number = {10},
pages = {2044--2064},
title = {{Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence and data mining: Experimental analysis of power}},
url = {http://www.sciencedirect.com/science/article/pii/S0020025509005404},
volume = {180},
year = {2010}
}
@article{Garcia2012,
abstract = {The present paper investigates the influence of both the imbalance ratio and the classifier on the performance of several resampling strategies to deal with imbalanced data sets. The study focuses on evaluating how learning is affected when different resampling algorithms transform the originally imbalanced data into artificially balanced class distributions. Experiments over 17 real data sets using eight different classifiers, four resampling algorithms and four performance evaluation measures show that over-sampling the minority class consistently outperforms under-sampling the majority class when data sets are strongly imbalanced, whereas there are not significant differences for databases with a low imbalance. Results also indicate that the classifier has a very poor influence on the effectiveness of the resampling strategies.},
author = {Garc{\'{\i}}a, V. and S{\'{a}}nchez, J.S. S and Mollineda, R.A. A},
doi = {10.1016/j.knosys.2011.06.013},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garc{\'{\i}}a, S{\'{a}}nchez, Mollineda - 2012 - On the effectiveness of preprocessing methods when dealing with different levels of class imbalanc.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Classification,Imbalance,Multi-dimensional scaling,Performance measures,Resampling},
month = {feb},
number = {1},
pages = {13--21},
title = {{On the effectiveness of preprocessing methods when dealing with different levels of class imbalance}},
url = {http://www.sciencedirect.com/science/article/pii/S0950705111001286},
volume = {25},
year = {2012}
}
@phdthesis{thesisDeep,
author = {George, Dileep},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/George - 2008 - How the brain might work a hierarchical and temporal model for learning and recognition.pdf:pdf},
school = {Stanford University},
title = {{How the brain might work: a hierarchical and temporal model for learning and recognition}},
type = {Dissertation},
year = {2008}
}
@book{Gerstner1997,
address = {Berlin, Heidelberg},
doi = {10.1007/BFb0020124},
editor = {Gerstner, Wulfram and Germond, Alain and Hasler, Martin and Nicoud, Jean-Daniel},
isbn = {978-3-540-63631-1},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Artificial Neural Networks — ICANN'97}},
url = {http://link.springer.com/10.1007/BFb0020124},
volume = {1327},
year = {1997}
}
@inproceedings{Girshick2014,
abstract = {Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30{\%} relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3{\%}. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/{\~{}}rbg/rcnn.},
author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
booktitle = {2014 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2014.81},
isbn = {978-1-4799-5118-5},
keywords = {Feature extraction,Object detection,Proposals,R-CNN,Support vector machines,Training,Vectors,Visualization,auxiliary task,bottom-up region proposal,canonical PASCAL VOC dataset,detection algorithm,domain-specific fine-tuning,high-capacity convolutional neural network,image features,image segmentation,labeled training data,low-level image feature,mAP,mean average precision,neural nets,object detection,object detection performance,performance boost,rich feature hierarchy,segment objects,semantic segmentation,source code,supervised pretraining},
month = {jun},
pages = {580--587},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6909475},
year = {2014}
}
@book{Gonzalez2007,
abstract = {THE leader in the field for more than twenty years, this introduction to basic concepts and methodologies for digital image processing continues its cutting-edge focus on contemporary developments in all mainstream areas of image processing. Completely self-contained, heavily illustrated, and mathematically accessible, it has a scope of application that is not limited to the solution of specialized problems. Digital Image Fundamentals. Image Enhancement in the Spatial Domain. Image Enhancement in the Frequency Domain. Image Restoration. Color Image Processing. Wavelets and Multiresolution Processing. Image Compression. Morphological Image Processing. Image Segmentation. Representation and Description. Object Recognition. For technicians interested in the fundamentals and contemporary applications of digital imaging processing},
author = {Gonzalez, Rafael C and Woods, Richard E},
booktitle = {3nd edition},
edition = {3},
isbn = {013168728X},
publisher = {Prentice-Hall},
title = {{Digital Image Processing}},
year = {2007}
}
@article{Gregor2015,
abstract = {This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye.},
archivePrefix = {arXiv},
arxivId = {1502.04623},
author = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and Wierstra, Daan},
eprint = {1502.04623},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gregor et al. - 2015 - DRAW A Recurrent Neural Network For Image Generation.pdf:pdf},
month = {feb},
title = {{DRAW: A Recurrent Neural Network For Image Generation}},
url = {http://arxiv.org/abs/1502.04623},
year = {2015}
}
@article{Gross2003,
author = {Gross, Ralph and Brajovic, Vladimir},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gross, Brajovic - 2003 - An image preprocessing algorithm for illumination invariant face recognition.pdf:pdf},
journal = {Audio and Video-Based Biometric Person Authentication},
pages = {10--18},
title = {{An image preprocessing algorithm for illumination invariant face recognition}},
year = {2003}
}
@book{Grus2015,
author = {Grus, Joel},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grus - 2015 - Data Science from Scratch.pdf:pdf},
isbn = {9781491901427},
title = {{Data Science from Scratch}},
year = {2015}
}
@article{Hala2014,
abstract = {There is a great need for accurate and autonomous spectral classification methods in astrophysics. This thesis is about training a convolutional neural network (ConvNet) to recognize an object class (quasar, star or galaxy) from one-dimension spectra only. Author developed several scripts and C programs for datasets preparation, preprocessing and postprocessing of the data. EBLearn library (developed by Pierre Sermanet and Yann LeCun) was used to create ConvNets. Application on dataset of more than 60000 spectra yielded success rate of nearly 95{\%}. This thesis conclusively proved great potential of convolutional neural networks and deep learning methods in astrophysics.},
archivePrefix = {arXiv},
arxivId = {1412.8341},
author = {H{\'{a}}la, Pavel},
eprint = {1412.8341},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/H{\'{a}}la - 2014 - Spectral classification using convolutional neural networks.pdf:pdf},
month = {dec},
pages = {71},
title = {{Spectral classification using convolutional neural networks}},
url = {http://arxiv.org/abs/1412.8341},
year = {2014}
}
@article{Hall1971,
abstract = {Feature extraction is one of the more difficult steps in image pattern recognition. Some sources of difficulty are the presence of irrelevant information and the relativity of a feature set to a particular application. Several preprocessing techniques for enhancing selected features and removing irrelevant data are described and compared. The techniques include gray level distribution linearization, digital spatial filtering, contrast enhancement, and image subtraction. Also, several feature extraction techniques are illustrated. The techniques are divided into spatial and Fourier domain operations. The spatial domain operations of directional signatures and contour tracing are first described. Then, the Fourier domain techniques of frequency signatures and template matching are illustrated. Finally, a practical image pattern recognition problem is solved using some of the described techniques.},
author = {Hall, E.L. L and Kruger, R.P. P and Dwyer, S.J. J and Hall, D.L. L and Mclaren, R.W. W and Lodwick, G.S. S},
doi = {10.1109/T-C.1971.223399},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hall et al. - 1971 - A Survey of Preprocessing and Feature Extraction Techniques for Radiographic Images.pdf:pdf},
issn = {0018-9340},
journal = {IEEE Transactions on Computers},
keywords = {Data mining,Diagnostic radiography,Digital filters,Feature extraction,Filtering,Image analysis,Image processing,Matched filters,Pattern recognition,Radiology,pattern recognition,preproces,preprocessing},
mendeley-tags = {preprocessing},
month = {sep},
number = {9},
pages = {1032--1044},
shorttitle = {Computers, IEEE Transactions on},
title = {{A Survey of Preprocessing and Feature Extraction Techniques for Radiographic Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1671992},
volume = {C-20},
year = {1971}
}
@article{Han2003,
abstract = {Biometrics-based authentication is a verification approach using the biological features inherent in each individual. They are processed based on the identical, portable, and arduous duplicate characteristics. In this paper, we propose a scanner-based personal authentication system by using the palm-print features. It is very suitable in many network-based applications. The authentication system consists of enrollment and verification stages. In the enrollment stage, the training samples are collected and processed by the pre-processing, feature extraction, and modeling modules to generate the matching templates. In the verification stage, a query sample is also processed by the pre-processing and feature extraction modules, and then is matched with the reference templates to decide whether it is a genuine sample or not. The region of interest (ROI) for each sample is first obtained from the pre-processing module. Then, the palm-print features are extracted from the ROI by using Sobel and morphological operations. The reference templates for a specific user are generated in the modeling module. Last, we use the template-matching and the backpropagation neural network to measure the similarity in the verification stage. Experimental results verify the validity of our proposed approaches in personal authentication.},
author = {Han, Chin-Chuan and Cheng, Hsu-Liang and Lin, Chih-Lung and Fan, Kuo-Chin},
doi = {10.1016/S0031-3203(02)00037-7},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han et al. - 2003 - Personal authentication using palm-print features.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Backpropagation neural network,Multi-template matching,Palmprint features,Personal authentication,preprocessing},
mendeley-tags = {preprocessing},
month = {feb},
number = {2},
pages = {371--381},
title = {{Personal authentication using palm-print features}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320302000377},
volume = {36},
year = {2003}
}
@article{Han2005,
abstract = {In recent years, mining with imbalanced data sets receives more and more attentions in both theoretical and practical aspects. This paper introduces the importance of imbalanced data sets and their broad application domains in data mining, and then summarizes the evaluation metrics and the existing methods to evaluate and solve the imbalance problem. Synthetic minority over-sampling technique (SMOTE) is one of the over-sampling methods addressing this problem. Based on SMOTE method, this paper presents two new minority over-sampling methods, borderline-SMOTE1 and borderline-SMOTE2, in which only the minority examples near the borderline are over-sampled. For the minority class, experiments show that our approaches achieve better TP rate and F-value than SMOTE and random over-sampling methods.},
author = {Han, Hui and Wang, Wen-Yuan and Mao, Bing-Huan},
journal = {Advances in intelligent computing},
keywords = {High dimensional data,Multidimensional projection,Visual data mining,classification,imbalance,oversampling,smote},
number = {12},
pages = {878--887},
publisher = {Alvey Vision Club},
title = {{Borderline-SMOTE: A new over-sampling method in imbalanced data sets learning}},
volume = {17},
year = {2005}
}
@article{Hanmandlu2003,
abstract = {A Gaussian membership function to model image information in spatial domain has been proposed in this paper. We introduce a new contrast intensification operator, which involves a parameter t for enhancement of color images. By minimizing the fuzzy entropy of the image information, the parameter t is calculated globally. A visible improvement in the image quality for human contrast perception is observed, also demonstrated here by the reduction in 'index of fuzziness' and 'entropy' of the output image. © 2002 Elsevier Science B.V. All rights reserved.},
author = {Hanmandlu, M. and Jha, Devendra and Sharma, Rochak},
doi = {10.1016/S0167-8655(02)00191-5},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hanmandlu, Jha, Sharma - 2003 - Color image enhancement by fuzzy intensification.pdf:pdf},
isbn = {0-7695-0750-6},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Color enhancement,Entropy,Fuzzifier,Fuzzy contrast,Fuzzy logic,Image processing,Index of fuzziness,Intensification operator},
number = {1-3},
pages = {81--87},
title = {{Color image enhancement by fuzzy intensification}},
volume = {24},
year = {2003}
}
@article{Haralick1973,
abstract = {Texture is one of the important characteristics used in identifying objects or regions of interest in an image, whether the image be a photomicrograph, an aerial photograph, or a satellite image. This paper describes some easily computable textural features based on gray-tone spatial dependancies, and illustrates their application in category-identification tasks of three different kinds of image data: photomicrographs of five kinds of sandstones, 1:20 000 panchromatic aerial photographs of eight land-use categories, and Earth Resources Technology Satellite (ERTS) multispecial imagery containing seven land-use categories. We use two kinds of decision rules: one for which the decision regions are convex polyhedra (a piecewise linear decision rule), and one for which the decision regions are rectangular parallelpipeds (a min-max decision rule). In each experiment the data set was divided into two parts, a training set and a test set. Test set identification accuracy is 89 percent for the photomicrographs, 82 percent for the aerial photographic imagery, and 83 percent for the satellite imagery. These results indicate that the easily computable textural features probably have a general applicability for a wide variety of image-classification applications.},
author = {Haralick, Robert M. and Shanmugam, K. and Dinstein, Its'Hak},
doi = {10.1109/TSMC.1973.4309314},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haralick, Shanmugam, Dinstein - 1973 - Textural Features for Image Classification.pdf:pdf},
issn = {0018-9472},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
keywords = {Application software,Crops,Earth,Humans,Image classification,Image resolution,Piecewise linear techniques,Satellites,Spatial resolution,Testing,features,image classification,texture},
mendeley-tags = {features,image classification,texture},
month = {nov},
number = {6},
pages = {610--621},
shorttitle = {Systems, Man and Cybernetics, IEEE Transactions on},
title = {{Textural Features for Image Classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4309314},
volume = {3},
year = {1973}
}
@inproceedings{Han2005b,
author = {Harris, Chris and Stephens, Mike},
booktitle = {Proceedings of the Alvey Vision Conference},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han, Wang, Mao - 2005 - Borderline-SMOTE a new over-sampling method in imbalanced data sets learning.pdf:pdf},
keywords = {High dimensional data,Multidimensional projection,Visual data mining},
pages = {147----152},
publisher = {Alvey Vision Club},
title = {{A combined corner and edge detector}},
url = {http://www.bmva.org/bmvc/1988/avc-88-023.html},
year = {1998}
}
@article{Hashemi2010,
abstract = {Contrast enhancement plays a fundamental role in image/video processing. Histogram Equalization (HE) is one of the most commonly used methods for image contrast enhancement. However, HE and most other contrast enhancement methods may produce un-natural looking images and the images obtained by these methods are not desirable in applications such as consumer electronic products where brightness preservation is necessary to avoid annoying artifacts. To solve such problems, we proposed an efficient contrast enhancement method based on genetic algorithm in this paper. The proposed method uses a simple and novel chromosome representation together with corresponding operators. Experimental results showed that this method makes natural looking images especially when the dynamic range of input image is high. Also, it has been shown by simulation results that the proposed genetic method had better results than related ones in terms of contrast and detail enhancement and the resulted images were suitable for consumer electronic products. © 2010 Elsevier B.V. All rights reserved.},
author = {Hashemi, Sara and Kiani, Soheila and Noroozi, Navid and Moghaddam, Mohsen Ebrahimi},
doi = {10.1016/j.patrec.2009.12.006},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hashemi et al. - 2010 - An image contrast enhancement method based on genetic algorithm.pdf:pdf},
isbn = {0167-8655},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Contrast enhancement,Genetic algorithm,Natural looking images},
number = {13},
pages = {1816--1824},
publisher = {Elsevier B.V.},
title = {{An image contrast enhancement method based on genetic algorithm}},
url = {http://dx.doi.org/10.1016/j.patrec.2009.12.006},
volume = {31},
year = {2010}
}
@incollection{He2004,
abstract = {Many problems in information processing involve some form of dimen- sionality reduction. In this paper, we introduce Locality Preserving Pro- jections (LPP). These are linear projective maps that arise by solving a variational problem that optimally preserves the neighborhood structure of the data set. LPP should be seen as an alternative to Principal Com- ponent Analysis (PCA) – a classical linear technique that projects the data along the directions of maximal variance. When the high dimen- sional data lies on a low dimensional manifold embedded in the ambient space, the Locality Preserving Projections are obtained by finding the optimal linear approximations to the eigenfunctions of the Laplace Bel- trami operator on the manifold. As a result, LPP shares many of the data representation properties of nonlinear techniques such as Laplacian Eigenmaps or Locally Linear Embedding. Yet LPP is linear and more crucially is defined everywhere in ambient space rather than just on the training data points. This is borne out by illustrative examples on some high dimensional data sets.},
author = {He, Xiaofei and Niyogi, Partha},
booktitle = {Neural information processing systems},
doi = {10.1.1.19.9400},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He, Niyogi - 2004 - Locality preserving projections.pdf:pdf},
isbn = {0262201526},
issn = {10495258},
pages = {153--160},
title = {{Locality preserving projections}},
volume = {16},
year = {2004}
}
@article{He2009,
abstract = {Iris segmentation is an essential module in iris recognition because it defines the effective image region used for subsequent processing such as feature extraction. Traditional iris segmentation methods often involve an exhaustive search of a large parameter space, which is time consuming and sensitive to noise. To address these problems, this paper presents a novel algorithm for accurate and fast iris segmentation. After efficient reflection removal, an Adaboost-cascade iris detector is first built to extract a rough position of the iris center. Edge points of iris boundaries are then detected, and an elastic model named pulling and pushing is established. Under this model, the center and radius of the circular iris boundaries are iteratively refined in a way driven by the restoring forces of Hooke's law. Furthermore, a smoothing spline-based edge fitting scheme is presented to deal with noncircular iris boundaries. After that, eyelids are localized via edge detection followed by curve fitting. The novelty here is the adoption of a rank filter for noise elimination and a histogram filter for tackling the shape irregularity of eyelids. Finally, eyelashes and shadows are detected via a learned prediction model. This model provides an adaptive threshold for eyelash and shadow detection by analyzing the intensity distributions of different iris regions. Experimental results on three challenging iris image databases demonstrate that the proposed algorithm outperforms state-of-the-art methods in both accuracy and speed.},
author = {He, Zhaofeng and Tan, Tieniu and Sun, Zhenan and Qiu, Xianchao},
doi = {10.1109/TPAMI.2008.183},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2009 - Toward accurate and fast iris segmentation for iris biometrics.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Biometry,Biometry: methods,Computer-Assisted,Computer-Assisted: methods,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Iris,Iris: anatomy {\&} histology,Pattern Recognition,Subtraction Technique},
month = {sep},
number = {9},
pages = {1670--84},
pmid = {19574626},
title = {{Toward accurate and fast iris segmentation for iris biometrics}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19574626},
volume = {31},
year = {2009}
}
@article{Heikkila2009,
abstract = {This paper presents a novel method for interest region description. We adopted the idea that the appearance of an interest region can be well characterized by the distribution of its local features. The most well-known descriptor built on this idea is the SIFT descriptor that uses gradient as the local feature. Thus far, existing texture features are not widely utilized in the context of region description. In this paper, we introduce a new texture feature called center-symmetric local binary pattern (CS-LBP) that is a modified version of the well-known local binary pattern (LBP) feature. To combine the strengths of the SIFT and LBP, we use the CS-LBP as the local feature in the SIFT algorithm. The resulting descriptor is called the CS-LBP descriptor. In the matching and object category classification experiments, our descriptor performs favorably compared to the SIFT. Furthermore, the CS-LBP descriptor is computationally simpler than the SIFT.},
author = {Heikkil{\"{a}}, Marko and Pietik{\"{a}}inen, Matti and Schmid, Cordelia},
doi = {10.1016/j.patcog.2008.08.014},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heikkil{\"{a}}, Pietik{\"{a}}inen, Schmid - 2009 - Description of interest regions with local binary patterns.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Image matching,Local binary patterns,Object recognition,Region description,Region detection,SIFT},
month = {mar},
number = {3},
pages = {425--436},
title = {{Description of interest regions with local binary patterns}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320308003282},
volume = {42},
year = {2009}
}
@article{Heusch2006,
author = {Heusch, G. and Rodriguez, Y. and Marcel, S.},
doi = {10.1109/FGR.2006.72},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heusch, Rodriguez, Marcel - 2006 - Local Binary Patterns as an Image Preprocessing for Face Authentication.pdf:pdf},
isbn = {0-7695-2503-2},
journal = {7th International Conference on Automatic Face and Gesture Recognition (FGR06)},
pages = {9--14},
publisher = {Ieee},
title = {{Local Binary Patterns as an Image Preprocessing for Face Authentication}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1612990},
year = {2006}
}
@article{Hinton2006,
author = {Hinton, G and Osindero, Simon and Teh, YW W},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hinton, Osindero, Teh - 2006 - A fast learning algorithm for deep belief nets.pdf:pdf},
journal = {Neural computation},
title = {{A fast learning algorithm for deep belief nets}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6796673},
year = {2006}
}
@article{Hinton2006a,
author = {Hinton, Geoffrey},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hinton - 2006 - To Recognize Shapes , First Learn to Generate Images To Recognize Shapes.pdf:pdf},
title = {{To Recognize Shapes , First Learn to Generate Images To Recognize Shapes , First Learn to Generate Images}},
year = {2006}
}
@article{Hoseini2013,
abstract = {In this paper, we propose a hybrid algorithm including Genetic Algorithm (GA), Ant Colony Optimisation (ACO), and Simulated Annealing (SA) metaheuristics for increasing the contrast of images. In this way, contrast enhancement is obtained by global transformation of the input intensities. Ant colony optimisation is used to generate the transfer functions which map the input intensities to the output intensities. Simulated annealing as a local search method is utilised to modify the transfer functions generated by ant colony optimisation. And genetic algorithm has the responsibility of evolutionary process of antsE characteristics. The employed fitness function operates automatically and tends to provide a balance between contrast and naturalness of images. The results indicate that the new method achieves images with higher contrast than the previously presented methods from the subjective and objective viewpoints. Further, the proposed algorithm preserves the natural look of input images. ?? 2012 Elsevier Inc.},
author = {Hoseini, Pourya and Shayesteh, Mahrokh G.},
doi = {10.1016/j.dsp.2012.12.011},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoseini, Shayesteh - 2013 - Efficient contrast enhancement of images using hybrid ant colony optimisation, genetic algorithm, and simula.pdf:pdf},
isbn = {1051-2004},
issn = {10512004},
journal = {Digital Signal Processing: A Review Journal},
keywords = {Ant Colony Optimisation (ACO),Contrast enhancement,Genetic Algorithm (GA),Hybrid metaheuristics,Image processing,Simulated Annealing (SA)},
number = {3},
pages = {879--893},
publisher = {Elsevier Inc.},
title = {{Efficient contrast enhancement of images using hybrid ant colony optimisation, genetic algorithm, and simulated annealing}},
url = {http://dx.doi.org/10.1016/j.dsp.2012.12.011},
volume = {23},
year = {2013}
}
@article{Hu2015,
abstract = {Deep learning, in particular Convolutional Neural Network (CNN), has achieved promising results in face recognition recently. However, it remains an open question: why CNNs work well and how to design a 'good' architecture. The existing works tend to focus on reporting CNN architectures that work well for face recognition rather than investigate the reason. In this work, we conduct an extensive evaluation of CNN-based face recognition systems (CNN-FRS) on a common ground to make our work easily reproducible. Specifically, we use public database LFW (Labeled Faces in the Wild) to train CNNs, unlike most existing CNNs trained on private databases. We propose three CNN architectures which are the first reported architectures trained using LFW data. This paper quantitatively compares the architectures of CNNs and evaluate the effect of different implementation choices. We identify several useful properties of CNN-FRS. For instance, the dimensionality of the learned features can be significantly reduced without adverse effect on face recognition accuracy. In addition, traditional metric learning method exploiting CNN-learned features is evaluated. Experiments show two crucial factors to good CNN-FRS performance are the fusion of multiple CNNs and metric learning. To make our work reproducible, source code and models will be made publicly available.},
archivePrefix = {arXiv},
arxivId = {1504.02351},
author = {Hu, Guosheng and Yang, Yongxin and Yi, Dong and Kittler, Josef and Christmas, William and Li, Stan Z. and Hospedales, Timothy},
eprint = {1504.02351},
month = {apr},
pages = {7},
title = {{When Face Recognition Meets with Deep Learning: an Evaluation of Convolutional Neural Networks for Face Recognition}},
url = {http://arxiv.org/abs/1504.02351},
year = {2015}
}
@article{Hu2013,
abstract = {We present an image retrieval system for the interactive search of photo collections using free-hand sketches depicting shape. We describe Gradient Field HOG (GF-HOG); an adapted form of the HOG descriptor suitable for Sketch Based Image Retrieval (SBIR). We incorporate GF-HOG into a Bag of Visual Words (BoVW) retrieval framework, and demonstrate how this combination may be harnessed both for robust SBIR, and for localizing sketched objects within an image. We evaluate over a large Flickr sourced dataset comprising 33 shape categories, using queries from 10 non-expert sketchers. We compare GF-HOG against state-of-the-art descriptors with common distance measures and language models for image retrieval, and explore how affine deformation of the sketch impacts search performance. GF-HOG is shown to consistently outperform retrieval versus SIFT, multi-resolution HOG, Self Similarity, Shape Context and Structure Tensor. Further, we incorporate semantic keywords into our GF-HOG system to enable the use of annotated sketches for image search. A novel graph-based measure of semantic similarity is proposed and two applications explored: semantic sketch based image retrieval and a semantic photo montage.},
author = {Hu, Rui and Collomosse, John},
doi = {10.1016/j.cviu.2013.02.005},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, Collomosse - 2013 - A performance evaluation of gradient field HOG descriptor for sketch based image retrieval.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {Bag-of-visual-words,Image descriptors,Matching,Sketch based image retrieval},
month = {jul},
number = {7},
pages = {790--806},
title = {{A performance evaluation of gradient field HOG descriptor for sketch based image retrieval}},
url = {http://www.sciencedirect.com/science/article/pii/S1077314213000349},
volume = {117},
year = {2013}
}
@article{Huang2014,
abstract = {Recent investigations on human vision discover that the retinal image is a landscape or a geometric surface, consisting of features such as ridges and summits. However, most of existing popular local image descriptors in the literature, e.g., scale invariant feature transform (SIFT), histogram of oriented gradient (HOG), DAISY, local binary Patterns (LBP), and gradient location and orientation histogram, only employ the first-order gradient information related to the slope and the elasticity, i.e., length, area, and so on of a surface, and thereby partially characterize the geometric properties of a landscape. In this paper, we introduce a novel and powerful local image descriptor that extracts the histograms of second-order gradients (HSOGs) to capture the curvature related geometric properties of the neural landscape, i.e., cliffs, ridges, summits, valleys, basins, and so on. We conduct comprehensive experiments on three different applications, including the problem of local image matching, visual object categorization, and scene classification. The experimental results clearly evidence the discriminative power of HSOG as compared with its first-order gradient-based counterparts, e.g., SIFT, HOG, DAISY, and center-symmetric LBP, and the complementarity in terms of image representation, demonstrating the effectiveness of the proposed local descriptor.},
author = {Huang, Di and Zhu, Chao and Wang, Yunhong and Chen, Liming},
doi = {10.1109/TIP.2014.2353814},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2014 - HSOG A Novel Local Image Descriptor Based on Histograms of the Second-Order Gradients.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing},
month = {nov},
number = {11},
pages = {4680--95},
pmid = {25203990},
title = {{HSOG: A Novel Local Image Descriptor Based on Histograms of the Second-Order Gradients.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25203990},
volume = {23},
year = {2014}
}
@inproceedings{ccv-modified,
author = {Huang, Jing and Kumar, S Ravi and Mitra, Mandar and Zhu, Wei-Jing and Zabih, Ramin},
booktitle = {Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.1997.609412},
isbn = {0-8186-7822-4},
issn = {1063-6919},
keywords = {Cameras,Histograms,Image databases,Image retrieval,Indexing,Layout,Optical computing,Robustness,Shape,Spatial databases,camera zooms,color correlograms,content-based image retrieval,histogram refinement methods,image feature,image indexing,image retrieval,indexing,information retrieval systems,spatial correlation,viewing positions,visual databases},
language = {English},
pages = {762--768},
publisher = {IEEE},
title = {{Image indexing using color correlograms}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=609412},
year = {1997}
}
@article{Huang2006,
abstract = {To a significant degree, multimedia applications derive their effectiveness from the use of color graphics, images, and videos. In these applications, human visual system (HVS) often gives the final evaluation of the processed results. In this paper, we first propose a novel color image enhancement method, which is named HVS Controlled Color Image Enhancement and Evaluation algorithm (HCCIEE algorithm). We then applied the HCCIEE to color image by considering natural image quality metrics. This HCCIEE algorithm is base on multiscale representation of pattern, luminance, and color processing in the HVS. Experiments illustrated that the HCCIEE algorithm can produce distinguished details without ringing or halo artifacts. (These two problems often occur in conventional multiscale enhancement techniques.) As a result, the experimental results appear as similar as possible to the viewers’ perception of the actual scenes.},
author = {Huang, Kai-Qi and Wang, Qiao and Wu, Zhen-Yang},
doi = {10.1016/j.cviu.2006.02.007},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Wang, Wu - 2006 - Natural color image enhancement and evaluation algorithm based on human visual system.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {color image enhancement,human visual system},
number = {1},
pages = {52--63},
title = {{Natural color image enhancement and evaluation algorithm based on human visual system}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1077314206000233},
volume = {103},
year = {2006}
}
@article{Inpainting2014,
author = {Inpainting, Sparsity-based Image and Li, Fang and Zeng, Tieyong},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Inpainting, Li, Zeng - 2014 - A Universal Variational Framework for.pdf:pdf},
journal = {IEEE Trans},
number = {10},
pages = {4242--4254},
title = {{A Universal Variational Framework for}},
volume = {23},
year = {2014}
}
@misc{Intel2010,
abstract = {BSD license},
author = {Intel},
keywords = {Intel Corporation},
publisher = {Intel Corporation, BSD license.},
title = {{OpenCV: open source computer vision library}},
url = {http://opencv.willowgarage.com/wiki/},
year = {2010}
}
@article{Jain2014,
abstract = {In this work, we propose a novel and efficient method for articulated human pose estimation in videos using a convolutional network architecture, which incorporates both color and motion features. We propose a new human body pose dataset, FLIC-motion, that extends the FLIC dataset with additional motion features. We apply our architecture to this dataset and report significantly better performance than current state-of-the-art pose detection systems.},
archivePrefix = {arXiv},
arxivId = {1409.7963},
author = {Jain, Arjun and Tompson, Jonathan and LeCun, Yann and Bregler, Christoph},
eprint = {1409.7963},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain et al. - 2014 - MoDeep A Deep Learning Framework Using Motion Features for Human Pose Estimation.pdf:pdf},
month = {sep},
title = {{MoDeep: A Deep Learning Framework Using Motion Features for Human Pose Estimation}},
url = {http://arxiv.org/abs/1409.7963},
year = {2014}
}
@article{Jaouen2014,
abstract = {In this paper, we extend the gradient vector flow field for robust variational segmentation of vector-valued images. Rather than using scalar edge information, we define a vectorial edge map derived from a weighted local structure tensor of the image that enables the diffusion of the gradient vectors in accurate directions through the 4D gradient vector flow equation. To reduce the contribution of noise in the structure tensor, image channels are weighted according to a blind estimator of contrast. The method is applied to biological volume delineation in dynamic PET imaging, and validated on realistic Monte Carlo simulations of numerical phantoms as well as on real images.},
author = {Jaouen, Vincent and Gonzalez, Paulo and Stute, Simon and Guilloteau, Denis and Chalon, Sylvie and Buvat, Irene and Tauber, Clovis},
doi = {10.1109/TIP.2014.2353854},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaouen et al. - 2014 - Variational segmentation of vector-valued images with gradient vector flow.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing},
month = {nov},
number = {11},
pages = {4773--85},
pmid = {25203991},
title = {{Variational segmentation of vector-valued images with gradient vector flow}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25203991},
volume = {23},
year = {2014}
}
@article{Japkowicz2003,
author = {Japkowicz, N},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Japkowicz - 2003 - Class imbalances are we focusing on the right issue.ps:ps},
journal = {Workshop on Learning from Imbalanced Data Sets II},
title = {{Class imbalances: are we focusing on the right issue}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Class+Imbalances:+Are+We+Focusing+on+the+Right+Issue?{\#}0},
year = {2003}
}
@misc{Japkowicz2000,
author = {Japkowicz, Nathalie},
booktitle = {AAAI Technical Report},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Japkowicz - 2000 - Learning from Imbalanced Data Sets A Comparison of Various Strategies.pdf:pdf},
pages = {10--15},
title = {{Learning from Imbalanced Data Sets: A Comparison of Various Strategies}},
url = {http://www.aaai.org/Papers/Workshops/2000/WS-00-05/WS00-05-003.pdf},
urldate = {2014-10-13},
year = {2000}
}
@article{Japkowicz2002,
author = {Japkowicz, Nathalie and Stephen, Shaju},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Japkowicz, Stephen - 2002 - The class imbalance problem A systematic study.pdf:pdf},
journal = {Intelligent data analysis},
keywords = {0,c5,class imbalances,concept learning,misclassification costs,multi-layer perceptrons,re-sampling,support},
number = {5},
pages = {429--449},
publisher = {IOS Press},
title = {{The class imbalance problem : A systematic study}},
volume = {6},
year = {2002}
}
@inproceedings{Jegou2010,
abstract = {We address the problem of image search on a very large scale, where three constraints have to be considered jointly: the accuracy of the search, its efficiency, and the memory usage of the representation. We first propose a simple yet efficient way of aggregating local image descriptors into a vector of limited dimension, which can be viewed as a simplification of the Fisher kernel representation. We then show how to jointly optimize the dimension reduction and the indexing algorithm, so that it best preserves the quality of vector comparison. The evaluation shows that our approach significantly outperforms the state of the art: the search accuracy is comparable to the bag-of-features approach for an image representation that fits in 20 bytes. Searching a 10 million image dataset takes about 50ms.},
author = {Jegou, Herve and Douze, Matthijs and Schmid, Cordelia and Perez, Patrick},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5540039},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jegou et al. - 2010 - Aggregating local descriptors into a compact image representation.pdf:pdf},
isbn = {978-1-4244-6984-0},
issn = {1063-6919},
keywords = {Aggregates,Constraint optimization,Fisher kernel representation,Image databases,Image representation,Indexing,Kernel,Large-scale systems,Robustness,Support vector machine classification,Support vector machines,bag-of-features,compact image representation,image database,image representation,image retrieval,image search,local descriptors,pattern clustering},
month = {jun},
pages = {3304--3311},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Aggregating local descriptors into a compact image representation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5540039},
year = {2010}
}
@article{Jia2014,
archivePrefix = {arXiv},
arxivId = {1408.5093},
author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
eprint = {1408.5093},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jia et al. - 2014 - Caffe Convolutional Architecture for Fast Feature Embedding.pdf:pdf},
month = {jun},
title = {{Caffe: Convolutional Architecture for Fast Feature Embedding}},
url = {http://arxiv.org/abs/1408.5093},
year = {2014}
}
@article{Joia2011,
abstract = {Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP's versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents.},
author = {Joia, Paulo and Paulovich, Fernando V. and Coimbra, Danilo and Cuminato, Jos{\'{e}} Alberto and Nonato, Luis Gustavo},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Joia et al. - 2011 - Local Affine Multidimensional Projection.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {High dimensional data,Multidimensional projection,Visual data mining},
number = {12},
pages = {2563--2571},
title = {{Local Affine Multidimensional Projection}},
volume = {17},
year = {2011}
}
@article{JonathanMasci2015,
abstract = {Feature descriptors play a crucial role in a wide range of geometry analysis and processing applications, including shape correspondence, retrieval, and segmentation. In this paper, we propose ShapeNet, a generalization of the popular convolutional neural networks (CNN) paradigm to non-Euclidean manifolds. Our construction is based on a local geodesic system of polar coordinates to extract "patches", which are then passed through a cascade of filters and linear and non-linear operators. The coefficients of the filters and linear combination weights are optimization variables that are learned to minimize a task-specific cost function. We use ShapeNet to learn invariant shape feature descriptors that significantly outperform recent state-of-the-art methods, and show that previous approaches such as heat and wave kernel signatures, optimal spectral descriptors, and intrinsic shape contexts can be obtained as particular configurations of ShapeNet.},
archivePrefix = {arXiv},
arxivId = {1501.06297v1},
author = {{Jonathan Masci} and {Davide Boscaini} and {Michael M. Bronstein} and {Pierre Vandergheynst}},
eprint = {1501.06297v1},
file = {:home/gabi/Downloads/1501.06297v1.pdf:pdf},
keywords = {convolutional neural networks,deep learning,shape},
title = {{ShapeNet: Convolutional Neural Networks on Non-Euclidean Manifolds}},
url = {http://arxiv.org/abs/1501.06297v1},
year = {2015}
}
@article{Jorge,
author = {Jorge, Rodrigues},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jorge - Unknown - Sele{\c{c}}{\~{a}}o de caracter{\'{\i}}sticas e aprendizado ativo para classifica{\c{c}}{\~{a}}o de imagens de sensoriamento remoto.pdf:pdf},
title = {{Sele{\c{c}}{\~{a}}o de caracter{\'{\i}}sticas e aprendizado ativo para classifica{\c{c}}{\~{a}}o de imagens de sensoriamento remoto}}
}
@article{Kaiqi2005,
author = {Kaiqi, Huang and Zhenyang, Wu and Qiao, Wang},
doi = {10.1016/j.imavis.2004.07.005},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaiqi, Zhenyang, Qiao - 2005 - Image enhancement based on the statistics of visual representation.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {brightness,contrast,image enhancement,visual representation},
number = {1},
pages = {51--57},
title = {{Image enhancement based on the statistics of visual representation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885604001878},
volume = {23},
year = {2005}
}
@inproceedings{Kanan2010,
abstract = {Classification of images in many category datasbets has rapidly improved in recent years. However, systems that perform well on particular datasets typically have one or more limitations such as a failure to generalize across visual tasks (e.g., requiring a face detector or extensive retuning of parameters), insufficient translation invariance, inability to cope with partial views and occlusion, or significant performance degradation as the number of classes is increased. Here we attempt to overcome these challenges using a model that combines sequential visual attention using fixations with sparse coding. The model's biologically-inspired filters are acquired using unsupervised learning applied to natural image patches. Using only a single feature type, our approach achieves 78.5{\%} accuracy on Caltech-101 and 75.2{\%} on the 102 Flowers dataset when trained on 30 instances per class and it achieves 92.7{\%} accuracy on the AR Face database with 1 training instance per person. The same features and parameters are used across these datasets to illustrate its robust performance.},
author = {Kanan, Christopher and Cottrell, Garrison},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5539947},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kanan, Cottrell - 2010 - Robust classification of objects, faces, and flowers using natural image statistics.pdf:pdf},
isbn = {978-1-4244-6984-0},
issn = {1063-6919},
keywords = {Biological system modeling,Degradation,Detectors,Face detection,Filters,Image databases,Robustness,Spatial databases,Statistics,Unsupervised learning,image classification,image coding,image statistic,object classification,preprocessing,sparse coding,translation invariance,unsupervised learning},
mendeley-tags = {preprocessing},
month = {jun},
pages = {2472--2479},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Robust classification of objects, faces, and flowers using natural image statistics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5539947},
year = {2010}
}
@article{Kanan2012,
abstract = {In image recognition it is often assumed the method used to convert color images to grayscale has little impact on recognition performance. We compare thirteen different grayscale algorithms with four types of image descriptors and demonstrate that this assumption is wrong: not all color-to-grayscale algorithms work equally well, even when using descriptors that are robust to changes in illumination. These methods are tested using a modern descriptor-based image recognition framework, on face, object, and texture datasets, with relatively few training instances. We identify a simple method that generally works best for face and object recognition, and two that work well for recognizing textures.},
author = {Kanan, Christopher and Cottrell, Garrison W},
doi = {10.1371/journal.pone.0029740},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kanan, Cottrell - 2012 - Color-to-grayscale does the method matter in image recognition.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Algorithms,Animals,Automated,Automated: methods,Color,Computer-Assisted,Computer-Assisted: methods,Databases as Topic,Humans,Image Interpretation,Pattern Recognition},
month = {jan},
number = {1},
pages = {e29740},
pmid = {22253768},
title = {{Color-to-grayscale: does the method matter in image recognition?}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3254613{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2012}
}
@article{An1980,
author = {kanneth ivan Laws and kanneth ivan Laws},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laws - 1980 - texture image segmentation.pdf:pdf},
number = {3119},
title = {texture image segmentation},
year = {1980}
}
@article{Knaus2014,
abstract = {Image denoising continues to be an active research topic. Although state-of-the-art denoising methods are numerically impressive and approch theoretical limits, they suffer from visible artifacts.While they produce acceptable results for natural images, human eyes are less forgiving when viewing synthetic images. At the same time, current methods are becoming more complex, making analysis, and implementation difficult. We propose image denoising as a simple physical process, which progressively reduces noise by deterministic annealing. The results of our implementation are numerically and visually excellent. We further demonstrate that our method is particularly suited for synthetic images. Finally, we offer a new perspective on image denoising using robust estimators.},
author = {Knaus, Claude and Zwicker, Matthias},
doi = {10.1109/TIP.2014.2326771},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Knaus, Zwicker - 2014 - Progressive image denoising.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing},
keywords = {Annealing,Fourier transforms,Frequency-domain analysis,Image denoising,Kernel,Noise,Noise reduction,Robustness,bilateral filtering,deterministic annealing,human eyes,image denoising,natural images,noise reduction,preprocessing,progressive image denoising,robust estimation,robust estimators,short-time Fourier transform,synthetic images,visible artifacts},
mendeley-tags = {image denoising,preprocessing},
month = {jul},
number = {7},
pages = {3114--3125},
pmid = {24876125},
shorttitle = {Image Processing, IEEE Transactions on},
title = {{Progressive image denoising.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24876125},
volume = {23},
year = {2014}
}
@article{Kohonen1982,
author = {Kohonen, Teuvo},
doi = {10.1007/BF00337288},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kohonen - 1982 - Self-organized formation of topologically correct feature maps.pdf:pdf},
issn = {0340-1200},
journal = {Biological Cybernetics},
number = {1},
pages = {59--69},
title = {{Self-organized formation of topologically correct feature maps}},
url = {http://link.springer.com/10.1007/BF00337288},
volume = {43},
year = {1982}
}
@article{Kotsiantis2006,
author = {Kotsiantis, Sotiris},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kotsiantis - 2006 - Handling imbalanced datasets A review.pdf:pdf},
journal = {International Transactions on Computer Science and Engineering},
title = {{Handling imbalanced datasets: A review}},
url = {http://adaptiveilp.googlecode.com/svn/trunk/imbalanced datasets survey paper gests.pdf http://adaptiveilp.googlecode.com/svn/trunk/imbalanced datasets survey paper gests.pdf},
volume = {30},
year = {2006}
}
@techreport{Krizhevsky2009,
author = {Krizhevsky, Alex and Hinton, Geoffrey},
doi = {10.1.1.222.9220},
keywords = {Alex Krizhevsky},
publisher = {Citeseer},
title = {{Learning Multiple Layers of Features from Tiny Images}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.222.9220{\&}rep=rep1{\&}type=pdf},
year = {2009}
}
@inproceedings{Krizhevsky,
annote = {
        

        

        From Duplicate 2 ( 
        

        

        

        
          

          

          

        
        
          ImageNet Classification with Deep Convolutional Neural Networks
        
        
          

          

          

        
        

        

        

         - Krizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffrey E. )

          

          

          

        
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

      },
author = {Krizhevsky, Alex and Hinton, Geoffrey E. and Sutskever, Ilya},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krizhevsky, Hinton - Unknown - ImageNet Classification with Deep Convolutional Neural Networks(2).pdf:pdf},
pages = {1--9},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {http://papers.nips.cc/paper/4824-imagenet},
year = {2012}
}
@article{Kumar2010,
author = {Kumar, MP P and Packer, Benjamin and Koller, Daphne},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar, Packer, Koller - 2010 - Self-paced learning for latent variable models.pdf:pdf},
journal = {Advances in Neural Information {\ldots}},
pages = {1--9},
title = {{Self-paced learning for latent variable models}},
url = {http://papers.nips.cc/paper/3923-self-paced-learning-for-latent-variable-models},
year = {2010}
}
@book{Kuncheva2004,
author = {Kuncheva, LI},
publisher = {John Wiley {\&} Sons},
title = {{Combining pattern classifiers: methods and algorithms}},
year = {2004}
}
@book{Laurikkala2001,
address = {London, UK},
author = {Laurikkala, Jorma},
booktitle = {Proceedings of the 8th Conference on AI in Medicine in Europe: Artificial Intelligence Medicine},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laurikkala - 2001 - Improving identification of difficult small classes by balancing class distribution.pdf:pdf},
isbn = {3-540-42294-3},
month = {jul},
pages = {63--66},
publisher = {Springer-Verlag},
title = {{Improving identification of difficult small classes by balancing class distribution}},
url = {http://dl.acm.org/citation.cfm?id=648155.757340 http://link.springer.com/chapter/10.1007/3-540-48229-6{\_}9},
year = {2001}
}
@article{Lawrence1997,
abstract = {We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer.},
author = {Lawrence, S and Giles, C L and Tsoi, A C and Back, A D},
doi = {10.1109/72.554195},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lawrence et al. - 1997 - Face recognition a convolutional neural-network approach.pdf:pdf},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
keywords = {Face recognition,Feature extraction,Humans,Image databases,Image sampling,Karhunen-Loeve transforms,Multilayer perceptrons,Neural networks,Quantization,Spatial databases,computational complexity,convolution,convolutional neural-network,dimensionality reduction,face recognition,feature extraction,image matching,invariance,local image sampling,quantisation (signal),quantization,self-organising feature maps,self-organizing map,template matching,topological space,topology},
month = {jan},
number = {1},
pages = {98--113},
pmid = {18255614},
shorttitle = {Neural Networks, IEEE Transactions on},
title = {{Face recognition: a convolutional neural-network approach.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18255614},
volume = {8},
year = {1997}
}
@article{Lazaridou,
abstract = {We introduce language-driven image generation, the task of generating an im-age visualizing the semantic contents of a word embedding, e.g., given the word embedding of grasshopper, we generate a natural image of a grasshopper. We implement a simple method based on two mapping functions. The first takes as input a word embedding (as produced, e.g., by the word2vec toolkit) and maps it onto a high-level visual space (e.g., the space defined by one of the top layers of a Convolutional Neural Network). The second function maps this abstract visual representation to pixel space, in order to generate the target image. Several user studies suggest that the current system produces images that capture general vi-sual properties of the concepts encoded in the word embedding, such as color or typical environment, and are sufficient to discriminate between general categories of objects.},
archivePrefix = {arXiv},
arxivId = {arXiv:1506.03500v1},
author = {Lazaridou, Angeliki and Nguyen, Dat Tien and Bernardi, Raffaella and Baroni, Marco},
eprint = {arXiv:1506.03500v1},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lazaridou et al. - Unknown - Unveiling the Dreams of Word Embeddings Towards Language-Driven Image Generation.pdf:pdf},
pages = {1--11},
title = {{Unveiling the Dreams of Word Embeddings: Towards Language-Driven Image Generation}}
}
@inproceedings{lecun1998,
author = {LeCun, Yann and Bottou, L},
booktitle = {Proceedings of the IEEE},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/LeCun, Bottou - 1998 - Gradient-based learning applied to document recognition.pdf:pdf},
pages = {2278----2324},
title = {{Gradient-based learning applied to document recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=726791},
volume = {86},
year = {1998}
}
@article{Lecun2006,
author = {Lecun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato, Marc Aurelio and Huang, Fu Jie},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lecun et al. - 2006 - A Tutorial on Energy-Based Learning 1 Introduction Energy-Based Models.pdf:pdf},
pages = {1--59},
title = {{A Tutorial on Energy-Based Learning 1 Introduction : Energy-Based Models}},
year = {2006}
}
@inproceedings{lecun2010,
author = {LeCun, Yann and Kavukcuoglu, Koray and Farabet, Clement},
booktitle = {International Symposium on Circuits and Systems},
doi = {10.1109/ISCAS.2010.5537907},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/LeCun, Kavukcuoglu, Farabet - 2010 - Convolutional networks and applications in vision.pdf:pdf},
isbn = {978-1-4244-5308-5},
keywords = {ConvNets,Filter bank,Learning systems,Machine learning,Mobile robots,Navigation,Object recognition,Optical character recognition software,Unsupervised learning,Video surveillance,Visual perception,biologically-inspired architecture,convolutional networks,feature pooling layers,filter bank,intelligent tasks,internal representations,labeled training samples,machine learning,mobile robots,multilevel hierarchies,object recognition,off-road mobile robots,robot vision,unsupervised learning,vision navigation,visual object recognition},
language = {English},
month = {may},
pages = {253--256},
publisher = {IEEE},
title = {{Convolutional networks and applications in vision}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5537907},
year = {2010}
}
@article{Lindenbaum1994,
abstract = {Dennis Gabor is mainly known for the invention of optical holography and the introduction of the so-called Gabor functions in communications. A few people know that he was also interested in image processing. In a paper entitled “Information theory in electron microscopy” (Laboratory Investigation14(6), 801–807 (1965)), written in 1965, he examined the problem of image deblurring and was the first to suggest a method for edge enhancement based on principles widely accepted today and implemented in advanced image processing systems. In this paper his ideas are reviewed, their relation to contemporary methods is shown, and some simulations he could not do in 1965 are performed.},
author = {Lindenbaum, M and Fischer, M and Bruckstein, A},
doi = {10.1016/0031-3203(94)90013-2},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lindenbaum, Fischer, Bruckstein - 1994 - On Gabor's contribution to image enhancement.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Anisotropic diffusion,Directional filtering,Edge detection,Image enhancement,preprocessing},
mendeley-tags = {preprocessing},
month = {jan},
number = {1},
pages = {1--8},
title = {{On Gabor's contribution to image enhancement}},
url = {http://www.sciencedirect.com/science/article/pii/0031320394900132},
volume = {27},
year = {1994}
}
@article{Lippmann1987,
abstract = {Artificial neural net models have been studied for many years in the hope of achieving human-like performance in the fields of speech and image recognition. These models are composed of many nonlinear computational elements operating in parallel and arranged in patterns reminiscent of biological neural nets. Computational elements or nodes are connected via weights that are typically adapted during use to improve performance. There has been a recent resurgence in the field of artificial neural nets caused by new net topologies and algorithms, analog VLSI implementation techniques, and the belief that massive parallelism is essential for high performance speech and image recognition. This paper provides an introduction to the field of artificial neural nets by reviewing six important neural net models that can be used for pattern classification. These nets are highly parallel building blocks that illustrate neural net components and design principles and can be used to construct more complex systems. In addition to describing these nets, a major emphasis is placed on exploring how some existing classification and clustering algorithms can be performed using simple neuron-like components. Single-layer nets can implement algorithms required by Gaussian maximum-likelihood classifiers and optimum minimum-error classifiers for binary patterns corrupted by noise. More generally, the decision regions required by any classification algorithm can be generated in a straightforward manner by three-layer feed-forward nets.},
author = {Lippmann, R.},
doi = {10.1109/MASSP.1987.1165576},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lippmann - 1987 - An introduction to computing with neural nets.pdf:pdf},
issn = {0740-7467},
journal = {IEEE ASSP Magazine},
keywords = {Artificial neural networks,Biological system modeling,Biology computing,Classification algorithms,Clustering algorithms,Concurrent computing,Image recognition,Neural networks},
number = {2},
pages = {4--22},
shorttitle = {ASSP Magazine, IEEE},
title = {{An introduction to computing with neural nets}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1165576},
volume = {4},
year = {1987}
}
@article{Long2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1411.4038v2},
author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
eprint = {arXiv:1411.4038v2},
file = {:home/gabi/Downloads/1411.4038v2.pdf:pdf},
journal = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {{Fully Convolutional Networks for Semantic Segmentation}},
year = {2015}
}
@article{Lowe2004a,
abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance. Keywords:},
annote = {
        From Duplicate 1 ( 
        
          Distinctive image features from scale-invariant keypoints
        
         - Lowe, David G. DG )

        
        

        From Duplicate 1 ( 
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        
          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

        
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        
          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

        
        

        

        

        
          

          

          

        
        
          Distinctive image features from scale-invariant keypoints
        
        
          

          

          

        
        

        

        

        
          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

        
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        
          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

        
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        - Lowe, David G. DG )

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

        
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        From Duplicate 2 ( 
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        
          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

        
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        
          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

        
        

        

        

        
          

          

          

        
        
          Distinctive image features from scale-invariant keypoints
        
        
          

          

          

        
        

        

        

        
          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

        
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        
          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

        
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        - Lowe, David G. )

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

        
        

        

        From Duplicate 2 ( 
        
          Distinctive image features from scale-invariant keypoints
        
         - Lowe, David G D G )

        
        
From Duplicate 1 ( 

        

      },
author = {Lowe, David G. DG G},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lowe - 2004 - Distinctive image features from scale-invariant keypoints.pdf:pdf},
journal = {International Journal of Computer Vision},
keywords = {Image matching,Invariant features,Object recognition,Scale invariance,image matching,invariant features,object recognition,scale invariance},
number = {2},
pages = {91--110},
pmid = {20064111},
title = {{Distinctive image features from scale-invariant keypoints}},
url = {http://link.springer.com/article/10.1023/B:VISI.0000029664.99615.94},
volume = {60},
year = {2004}
}
@article{Lu2014,
abstract = {The count of mitotic cells is a critical factor in most cancer grading systems. Extracting the mitotic cell from the histopathological image is a very challenging task. In this paper, we propose an efficient technique for detecting and segmenting the mitotic cells in the high-resolution multispectral image. The proposed technique consists of three main modules: discriminative image generation, mitotic cell candidate detection and segmentation, and mitotic cell candidate classification. In the first module, a discriminative image is obtained by linear discriminant analysis using ten different spectral band images. A set of mitotic cell candidate regions is then detected and segmented by the Bayesian modeling and local-region threshold method. In the third module, a 226 dimension feature is extracted from the mitotic cell candidates and their surrounding regions. An imbalanced classification framework is then applied to perform the classification for the mitotic cell candidates in order to detect the real mitotic cells. The proposed technique has been evaluated on a publicly available dataset of 35 × 10 multispectral images, in which 224 mitotic cells are manually labeled by experts. The proposed technique is able to provide superior performance compared to the existing technique, 81.5{\%} sensitivity rate and 33.9{\%} precision rate in terms of detection performance, and 89.3{\%} sensitivity rate and 87.5{\%} precision rate in terms of segmentation performance.},
author = {Lu, Cheng and Mandal, Mrinal},
doi = {10.1109/JBHI.2013.2277837},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, Mandal - 2014 - Toward automatic mitotic cell detection and segmentation in multispectral histopathological images.pdf:pdf},
issn = {2168-2208},
journal = {IEEE journal of biomedical and health informatics},
keywords = {Bayes methods,Bayesian modeling,Cancer,Feature extraction,Histopathological image analysis,Image resolution,Image segmentation,Linear discriminant analysis,Microscopy,Shape,automatic mitotic cell detection,cancer,cancer grading systems,cellular biophysics,detection performance,discriminative image generation,feature extraction,high-resolution multispectral image,image classification,image generation,image resolution,image segmentation,imbalanced classification framework,linear discriminant analysis,local-region threshold method,medical image processing,mitotic cell candidate classification,mitotic cell candidate detection,mitotic cell candidate segmentation,mitotic cell extraction,multispectral histopathological image segmentation,object detection,pattern recognition,precision rate,publicly available dataset,sensitivity,sensitivity rate,spectral band images},
mendeley-tags = {image generation},
month = {mar},
number = {2},
pages = {594--605},
pmid = {24608059},
shorttitle = {Biomedical and Health Informatics, IEEE Journal of},
title = {{Toward automatic mitotic cell detection and segmentation in multispectral histopathological images.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24608059},
volume = {18},
year = {2014}
}
@article{Lu2007,
author = {Lu, D. and Weng, Q.},
doi = {10.1080/01431160600746456},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, Weng - 2007 - A survey of image classification methods and techniques for improving classification performance.pdf:pdf},
issn = {0143-1161},
journal = {International Journal of Remote Sensing},
month = {mar},
number = {5},
pages = {823--870},
title = {{A survey of image classification methods and techniques for improving classification performance}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01431160600746456},
volume = {28},
year = {2007}
}
@article{Luo2014,
abstract = {Distance metric learning (DML) is a critical factor for image analysis and pattern recognition. To learn a robust distance metric for a target task, we need abundant side information (i.e., the similarity/dissimilarity pairwise constraints over the labeled data), which is usually unavailable in practice due to the high labeling cost. This paper considers the transfer learning setting by exploiting the large quantity of side information from certain related, but different source tasks to help with target metric learning (with only a little side information). The state-of-the-art metric learning algorithms usually fail in this setting because the data distributions of the source task and target task are often quite different. We address this problem by assuming that the target distance metric lies in the space spanned by the eigenvectors of the source metrics (or other randomly generated bases). The target metric is represented as a combination of the base metrics, which are computed using the decomposed components of the source metrics (or simply a set of random bases); we call the proposed method, decomposition-based transfer DML (DTDML). In particular, DTDML learns a sparse combination of the base metrics to construct the target metric by forcing the target metric to be close to an integration of the source metrics. The main advantage of the proposed method compared with existing transfer metric learning approaches is that we directly learn the base metric coefficients instead of the target metric. To this end, far fewer variables need to be learned. We therefore obtain more reliable solutions given the limited side information and the optimization tends to be faster. Experiments on the popular handwritten image (digit, letter) classification and challenge natural image annotation tasks demonstrate the effectiveness of the proposed method.},
author = {Luo, Yong and Liu, Tongliang and Tao, Dacheng and Xu, Chao},
doi = {10.1109/TIP.2014.2332398},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luo et al. - 2014 - Decomposition-based transfer distance metric learning for image classification.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
month = {sep},
number = {9},
pages = {3789--801},
pmid = {24968169},
title = {{Decomposition-based transfer distance metric learning for image classification.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24968169},
volume = {23},
year = {2014}
}
@unpublished{Mahendran2014,
archivePrefix = {arXiv},
arxivId = {1412.0035},
author = {Mahendran, Aravindh and Vedaldi, Andrea},
booktitle = {arXiv preprint arXiv:1412.0035},
eprint = {1412.0035},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahendran, Vedaldi - 2014 - Understanding Deep Image Representations by Inverting Them.pdf:pdf},
month = {nov},
title = {{Understanding Deep Image Representations by Inverting Them}},
url = {http://arxiv.org/abs/1412.0035v1},
year = {2014}
}
@article{Mansimov2015,
abstract = {Motivated by the recent progress in generative models, we introduce a model that generates images from natural language descriptions. The proposed model iteratively draws patches on a canvas, while attending to the relevant words in the description. After training on Microsoft COCO, we compare our model with several baseline generative models on image generation and retrieval tasks. We demonstrate that our model produces higher quality samples than other approaches and generates images with novel scene compositions corresponding to previously unseen captions in the dataset.},
archivePrefix = {arXiv},
arxivId = {1511.02793},
author = {Mansimov, Elman and Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
eprint = {1511.02793},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mansimov et al. - 2015 - Generating Images from Captions with Attention.pdf:pdf},
month = {nov},
title = {{Generating Images from Captions with Attention}},
url = {http://arxiv.org/abs/1511.02793},
year = {2015}
}
@article{Mazurowski2008,
author = {Mazurowski, Maciej A and Habas, Piotr A and Zurada, Jacek M and Lo, Joseph Y and Baker, Jay A and Tourassi, Georgia D},
doi = {10.1016/j.neunet.2007.12.031},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mazurowski et al. - 2008 - Training neural network classifiers for medical decision making The effects of imbalanced datasets on classif.pdf:pdf},
keywords = {class imbalance,classification,computer-aided diagnosis,feed-forward neural networks},
pages = {427--436},
title = {{Training neural network classifiers for medical decision making: The effects of imbalanced datasets on classification performance {\$}}},
volume = {21},
year = {2008}
}
@article{Meer2012,
abstract = {This paper presents an opinion on research progress in computer vision.},
author = {Meer, Peter},
doi = {10.1016/j.imavis.2011.10.004},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meer - 2012 - Are we making real progress in computer vision today.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Computer vision,Human vision,computer vision},
mendeley-tags = {computer vision},
month = {aug},
number = {8},
pages = {472--473},
title = {{Are we making real progress in computer vision today?}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885612000662},
volume = {30},
year = {2012}
}
@book{Montavon2012,
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-642-35289-8},
editor = {Montavon, Gr{\'{e}}goire and Orr, Genevi{\`{e}}ve B. and M{\"{u}}ller, Klaus-Robert},
isbn = {978-3-642-35288-1},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Neural Networks: Tricks of the Trade}},
url = {http://link.springer.com/10.1007/978-3-642-35289-8},
volume = {7700},
year = {2012}
}
@article{Mosley2013,
author = {Mosley, Lawrence},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mosley - 2013 - A balanced approach to the multi-class imbalance problem.pdf:pdf},
title = {{A balanced approach to the multi-class imbalance problem}},
year = {2013}
}
@article{Munechika1993,
author = {Munechika, Curtis K and Warnick, James S and Salvaggio, Carl and Schott, John R},
file = {:home/gabi/Downloads/10.1.1.178.5210.pdf:pdf},
keywords = {1993 American,January 1993,No. 1,Photogrammetric Engineering {\&} Remote Sensing,Society for Photogrammetry and Remote Sensing,Vol. 59,pp.67-72},
number = {1},
pages = {67--72},
title = {{Resolution Enhancement of Multispectral Image Data to Improve Classification Accuracy}},
volume = {59},
year = {1993}
}
@book{neuralNielsen,
author = {Nielsen, Michael A.},
publisher = {Determination Press},
title = {{Neural Networks and Deep Learning}},
year = {2015}
}
@article{Ojala2002,
abstract = {Presents a theoretically very simple, yet efficient, multiresolution approach to gray-scale and rotation invariant texture classification based on local binary patterns and nonparametric discrimination of sample and prototype distributions. The method is based on recognizing that certain local binary patterns, termed "uniform," are fundamental properties of local image texture and their occurrence histogram is proven to be a very powerful texture feature. We derive a generalized gray-scale and rotation invariant operator presentation that allows for detecting the "uniform" patterns for any quantization of the angular space and for any spatial resolution and presents a method for combining multiple operators for multiresolution analysis. The proposed approach is very robust in terms of gray-scale variations since the operator is, by definition, invariant against any monotonic transformation of the gray scale. Another advantage is computational simplicity as the operator can be realized with a few operations in a small neighborhood and a lookup table. Experimental results demonstrate that good discrimination can be achieved with the occurrence statistics of simple rotation invariant local binary patterns},
author = {Ojala, T. and Pietikainen, M. and Maenpaa, T.},
doi = {10.1109/TPAMI.2002.1017623},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ojala, Pietikainen, Maenpaa - 2002 - Multiresolution gray-scale and rotation invariant texture classification with local binary patterns.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Gray-scale,Histograms,Image recognition,Image texture,Multiresolution analysis,Pattern recognition,Prototypes,Quantization,Robustness,Spatial resolution,angular space,computational simplicity,gray-scale variations,image classification,image texture,invariance,local binary patterns,local image texture,multiresolution analysis,multiresolution gray-scale texture classification,nonparametric discrimination,nonparametric statistics,occurrence histogram,prototype distributions,rotation invariant texture classification,sample distributions,spatial resolution,uniform patterns},
month = {jul},
number = {7},
pages = {971--987},
shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
title = {{Multiresolution gray-scale and rotation invariant texture classification with local binary patterns}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1017623},
volume = {24},
year = {2002}
}
@article{Oliveira,
author = {Oliveira, SRM R M},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oliveira - Unknown - Aprendizado com Classes Desbalanceadas.pdf:pdf},
journal = {SLIDES},
title = {{Aprendizado com Classes Desbalanceadas}},
url = {http://www.ime.unicamp.br/{~}wanderson/Aulas/Aula11/MT803-Aula11-Balanceamento-Classes.pdf}
}
@article{Paiva2011,
abstract = {An alternative form to multidimensional projections for the visual analysis of data represented in multidimensional spaces is the deployment of similarity trees, such as Neighbor Joining trees. They organize data objects on the visual plane emphasizing their levels of similarity with high capability of detecting and separating groups and subgroups of objects. Besides this similarity-based hierarchical data organization, some of their advantages include the ability to decrease point clutter; high precision; and a consistent view of the data set during focusing, offering a very intuitive way to view the general structure of the data set as well as to drill down to groups and subgroups of interest. Disadvantages of similarity trees based on neighbor joining strategies include their computational cost and the presence of virtual nodes that utilize too much of the visual space. This paper presents a highly improved version of the similarity tree technique. The improvements in the technique are given by two procedures. The first is a strategy that replaces virtual nodes by promoting real leaf nodes to their place, saving large portions of space in the display and maintaining the expressiveness and precision of the technique. The second improvement is an implementation that significantly accelerates the algorithm, impacting its use for larger data sets. We also illustrate the applicability of the technique in visual data mining, showing its advantages to support visual classification of data sets, with special attention to the case of image classification. We demonstrate the capabilities of the tree for analysis and iterative manipulation and employ those capabilities to support evolving to a satisfactory data organization and classification.},
author = {Paiva, Jose Gustavo S and Florian, Laura and Pedrini, Helio and Telles, Guilherme P. and Minghim, Rosane},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paiva et al. - 2011 - Improved similarity trees and their application to visual data classification.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Image Classification,Multidimensional Projections,Similarity Trees},
number = {12},
pages = {2459--2468},
publisher = {IEEE},
title = {{Improved similarity trees and their application to visual data classification}},
volume = {17},
year = {2011}
}
@article{Pal1993,
abstract = {Many image segmentation techniques are available in the literature. Some of these techniques use only the gray level histogram, some use spatial details while others use fuzzy set theoretic approaches. Most of these techniques are not suitable for noisy environments. Some works have been done using the Markov Random Field (MRF) model which is robust to noise, but is computationally involved. Neural network architectures which help to get the output in real time because of their parallel processing ability, have also been used for segmentation and they work fine even when the noise level is very high. The literature on color image segmentation is not that rich as it is for gray tone images. This paper critically reviews and summarizes some of these techniques. Attempts have been made to cover both fuzzy and non-fuzzy techniques including color image segmentation and neural network based approaches. Adequate attention is paid to segmentation of range images and magnetic resonance images. It also addresses the issue of quantitative evaluation of segmentation results.},
author = {Pal, Nikhil R and Pal, Sankar K},
doi = {10.1016/0031-3203(93)90135-J},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pal, Pal - 1993 - A review on image segmentation techniques.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Clustering,Edge detection,Fuzzy sets,Image segmentation,Markov Random Field,Relaxation,Thresholding,preprocessing},
mendeley-tags = {preprocessing},
month = {sep},
number = {9},
pages = {1277--1294},
title = {{A review on image segmentation techniques}},
url = {http://www.sciencedirect.com/science/article/pii/003132039390135J},
volume = {26},
year = {1993}
}
@article{Pal1994,
abstract = {Genetic algorithms represent a class of highly parallel adaptive search processes for solving a wide range of optimization and machine learning problems. The present work is an attempt to demonstrate their adaptivity and effectiveness for searching global optimal solutions in selecting an appropriate image enhancement operator automatically.},
author = {Pal, Sankar K. and Bhandari, Dinabandhu and Kundu, Malay K.},
doi = {10.1016/0167-8655(94)90058-2},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pal, Bhandari, Kundu - 1994 - Genetic algorithms for optimal image enhancement.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Pattern recognition,ambiguity measures,genetic algorithms,image enhancement},
number = {3},
pages = {261--271},
title = {{Genetic algorithms for optimal image enhancement}},
url = {http://www.sciencedirect.com/science/article/pii/0167865594900582},
volume = {15},
year = {1994}
}
@article{Papari2011,
abstract = {We present an overview of various edge and line oriented approaches to contour detection that have been proposed in the last two decades. By edge and line oriented we mean methods that do not rely on segmentation. Distinction is made between edges and contours. Contour detectors are divided in local and global operators. The former are mainly based on differential analysis, statistical approaches, phase congruency, rank order filters, and combinations thereof. The latter include computation of contour saliency, perceptual grouping, relaxation labeling and active contours. Important aspects are covered, such as preprocessing aimed to suppress texture and noise, multiresolution techniques, connections between computational models and properties of the human visual system, and use of shape priors. An overview of procedures and metrics for quantitative performance evaluation is also presented. Our main conclusion is that contour detection has reached high degree of sophistication, taking into account multimodal contour definition (by luminance, color or texture changes), mechanisms for reducing the contour masking influence of noise and texture, perceptual grouping, multiscale aspects and high-level vision information.},
author = {Papari, Giuseppe and Petkov, Nicolai},
doi = {10.1016/j.imavis.2010.08.009},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Papari, Petkov - 2011 - Edge and line oriented contour detection State of the art.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Closure,Contour detection,Contour salience,Gestalt grouping,Local pattern analysis,Performance evaluation,Preprocessing,Scale–space,contour detection},
mendeley-tags = {contour detection},
month = {feb},
number = {2-3},
pages = {79--103},
title = {{Edge and line oriented contour detection: State of the art}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885610001253},
volume = {29},
year = {2011}
}
@inproceedings{acc,
address = {New York, USA},
author = {Pass, Greg and Zabih, Ramin and Miller, Justin},
booktitle = {Proceedings of the fourth ACM international conference on Multimedia},
doi = {10.1145/244130.244148},
isbn = {0897918711},
keywords = {color histograms,content-based image retrieval,processing},
month = {feb},
pages = {65--73},
publisher = {ACM Press},
title = {{Comparing images using color coherence vectors}},
url = {http://dl.acm.org/citation.cfm?id=244130.244148},
year = {1996}
}
@article{Paulinas2007,
abstract = {It was proved that genetic algorithms are the most powerful unbiased optimization techniques for sampling a large solution space. Because of unbiased stochastic sampling, they were quickly adapted in image processing. They were applied for the image enhancement, segmentation, feature extraction and classification as well as the image generation. This article gives a brief overview of the canonical genetic algorithm and it also reviews the tasks of image pre-processing. The survey of publications of this topic leads to the conclusion that the field of genetic algorithms applications is growing fast. The constant improvement of genetic algorithms will definitely help to solve various complex image processing tasks in the future. 1. Introduction In computer world, genetic material is replaced by Genetic algorithms (GAs) [19] are a relatively new paradigm for a search, based on principles of natural selection. For the first time they have been introduced},
author = {Paulinas, Mantas and U{\v{s}}inskas, Andrius},
doi = {10.1.1.120.4391},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paulinas, U{\v{s}}inskas - 2007 - A survey of genetic algorithms applications for image enhancement and segmentation.pdf:pdf},
issn = {1392-124X},
journal = {Information Technology and control},
number = {3},
pages = {278--284},
title = {{A survey of genetic algorithms applications for image enhancement and segmentation}},
url = {http://itc.ktu.lt/itc363/paulinas363.pdf},
volume = {36},
year = {2007}
}
@inproceedings{Paulovich2007,
abstract = {Multidimensional projections map data points, defined in a high-dimensional data space, into a 1D, 2D or 3D representation space. Such a mapping may be typically achieved with dimensional reduction, clustering, or force directed point placement. Projections can be displayed and navigated by data analysts by means of visual representations, which may vary from points on a plane to graphs, surfaces or volumes. Typically, projections strive to preserve distance relationships amongst data points, as defined in the original space. Information loss is inevitable and the projection approach defines the extent to which the distance preserving goal is attained. We introduce PEx-the projection explorer - a visualization tool for mapping and exploration of high-dimensional data via projections. A set of examples - on both structured (table) and unstructured (text) data - illustrate how projection based visualizations, coupled with appropriate exploration tools, offer a flexible set-up for multidimensional data exploration. The projections in PEx handle relatively large data sets at a computational cost adequate to user interaction.},
author = {Paulovich, Fernando V. and Oliveira, Maria Cristina F. and Minghim, Rosane},
booktitle = {XX Brazilian Symposium on Computer Graphics and Image Processing (SIBGRAPI 2007)},
doi = {10.1109/SIBGRAPI.2007.21},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paulovich, Oliveira, Minghim - 2007 - The Projection Explorer A Flexible Tool for Projection-based Multidimensional Visualization.pdf:pdf},
isbn = {0-7695-2996-8},
issn = {1530-1834},
keywords = {Cognitive science,Computational efficiency,Computer graphics,Data analysis,Data visualization,Eigenvalues and eigenfunctions,Image processing,Multidimensional systems,Navigation,Principal component analysis,computational cost,data structures,data visualisation,dimensional reduction,distance relationships,force directed point placement,projection explorer,projection-based multidimensional visualization,user interaction,user interfaces,visual representations},
month = {oct},
pages = {27--36},
publisher = {IEEE},
shorttitle = {Computer Graphics and Image Processing, 2007. SIBG},
title = {{The Projection Explorer: A Flexible Tool for Projection-based Multidimensional Visualization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4368165},
year = {2007}
}
@article{Penatti2012,
abstract = {This paper presents a comparative study of color and texture descriptors considering the Web as the environment of use. We take into account the diversity and large-scale aspects of the Web considering a large number of descriptors (24 color and 28 texture descriptors, including both traditional and recently proposed ones). The evaluation is made on two levels: a theoretical analysis in terms of algorithms complexities and an experimental comparison considering efficiency and effectiveness aspects. The experimental comparison contrasts the performances of the descriptors in small-scale datasets and in a large heterogeneous database containing more than 230 thousand images. Although there is a significant correlation between descriptors performances in the two settings, there are notable deviations, which must be taken into account when selecting the descriptors for large-scale tasks. An analysis of the correlation is provided for the best descriptors, which hints at the best opportunities of their use in combination.},
author = {Penatti, Ot{\'{a}}vio A.B. and Valle, Eduardo and Torres, Ricardo da S.},
doi = {10.1016/j.jvcir.2011.11.002},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Penatti, Valle, Torres - 2012 - Comparative study of global color and texture descriptors for web image retrieval.pdf:pdf},
issn = {10473203},
journal = {Journal of Visual Communication and Image Representation},
keywords = {Asymptotic complexity,Color descriptors,Comparative study,Content-based image retrieval,Correlation analysis,Efficiency and effectiveness,Texture descriptors,Web},
month = {feb},
number = {2},
pages = {359--380},
title = {{Comparative study of global color and texture descriptors for web image retrieval}},
url = {http://www.sciencedirect.com/science/article/pii/S1047320311001465},
volume = {23},
year = {2012}
}
@article{Peng2014,
abstract = {Recent studies witness the success of Bag-of-Features (BoF) frameworks for video based human action recognition. The detection and description of local interest regions are two fundamental problems in BoF framework. In this paper, we propose a motion boundary based sampling strategy and spatial-temporal (3D) co-occurrence descriptors for action video representation and recognition. Our sampling strategy is partly inspired by the recent success of dense trajectory (DT) based features [Wang et al., 2013] for action recognition. Compared with DT, we densely sample spatial-temporal cuboids along a motion boundary which can greatly reduce the number of valid trajectories and preserve the discriminative power. Moreover, we develop a set of 3D co-occurrence descriptors which take account of the spatial-temporal context within local cuboids and deliver rich information for recognition. Furthermore, we decompose each 3D co-occurrence descriptor at pixel level and bin level and integrate the decomposed components with a multi-channel framework, which can improve the performance significantly. To evaluate the proposed methods, we conduct extensive experiments on three benchmarks including KTH, YouTube and HMDB51. The results show that our sampling strategy significantly reduces the computational cost of point tracking without degrading performance. Meanwhile, we achieve superior performance than the state-of-the-art methods. We report 95.6{\%} on KTH, 87.6{\%} on YouTube and 51.8{\%} on HMDB51.},
author = {Peng, Xiaojiang and Qiao, Yu and Peng, Qiang},
doi = {10.1016/j.imavis.2014.06.011},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peng, Qiao, Peng - 2014 - Motion boundary based sampling and 3D co-occurrence descriptors for action recognition.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {3D co-occurrence descriptors,Action recognition,Bag of Features,Dense trajectory,Motion boundary},
month = {sep},
number = {9},
pages = {616--628},
title = {{Motion boundary based sampling and 3D co-occurrence descriptors for action recognition}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885614001103},
volume = {32},
year = {2014}
}
@article{Peng2014,
abstract = {Deep convolutional neural networks learn extremely powerful image representations, yet most of that power is hidden in the millions of deep-layer parameters. What exactly do these parameters represent? Recent work has started to analyse CNN representations, finding that, e.g., they are invariant to some 2D transformations, but are confused by particular types of image noise. In this paper, we delve deeper and ask: how invariant are CNNs to object-class variations caused by 3D shape, pose, and photorealism? These invariance properties are difficult to analyse using traditional data, so we propose an approach that renders synthetic data from freely available 3D CAD models. Using our approach we can easily generate an infinite amount of training images for almost any object. We explore the invariance of CNNs to various intra-class variations by simulating different rendering conditions, with surprising findings. Based on these results, we propose an optimal synthetic data generation strategy for training object detectors from CAD models. We show that our Virtual CNN approach significantly outperforms previous methods for learning object detectors from synthetic data on the benchmark PASCAL VOC2007 dataset.},
archivePrefix = {arXiv},
arxivId = {1412.7122},
author = {Peng, Xingchao and Sun, Baochen and Ali, Karim and Saenko, Kate},
eprint = {1412.7122},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peng et al. - 2014 - Exploring Invariances in Deep Convolutional Neural Networks Using Synthetic Images.pdf:pdf},
month = {dec},
title = {{Exploring Invariances in Deep Convolutional Neural Networks Using Synthetic Images}},
url = {http://arxiv.org/abs/1412.7122},
year = {2014}
}
@inproceedings{Perronnin2010,
address = {Crete, Greece},
author = {Perronnin, Florent and Dance, C},
booktitle = {European Conference on Computer Vision},
doi = {10.1007/978-3-642-15561-1{\_}11},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perronnin, Dance - 2010 - Improving the Fisher Kernel for Large-Scale Image Classification.pdf:pdf},
pages = {143--156},
publisher = {Springer Berlin Heidelberg},
title = {{Improving the Fisher Kernel for Large-Scale Image Classification}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-15561-1{\_}11},
year = {2010}
}
@inproceedings{Perronnin2007a,
abstract = {Within the field of pattern classification, the Fisher kernel is a powerful framework which combines the strengths of generative and discriminative approaches. The idea is to characterize a signal with a gradient vector derived from a generative probability model and to subsequently feed this representation to a discriminative classifier. We propose to apply this framework to image categorization where the input signals are images and where the underlying generative model is a visual vocabulary: a Gaussian mixture model which approximates the distribution of low-level features in images. We show that Fisher kernels can actually be understood as an extension of the popular bag-of-visterms. Our approach demonstrates excellent performance on two challenging databases: an in-house database of 19 object/scene categories and the recently released VOC 2006 database. It is also very practical: it has low computational needs both at training and test time and vocabularies trained on one set of categories can be applied to another set without any significant loss in performance.},
author = {Perronnin, Florent and Dance, Christopher},
booktitle = {2007 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2007.383266},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perronnin, Dance - 2007 - Fisher Kernels on Visual Vocabularies for Image Categorization.pdf:pdf},
isbn = {1-4244-1179-3},
issn = {1063-6919},
keywords = {Character generation,Feeds,Fisher kernels,Gaussian mixture model,Gaussian processes,Image databases,Kernel,Pattern classification,Power generation,Signal generators,Spatial databases,Visual databases,Vocabulary,generative probability model,gradient methods,gradient vector,image categorization,image classification,pattern classification,visual vocabularies},
month = {jun},
pages = {1--8},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition, 2007. CVP},
title = {{Fisher Kernels on Visual Vocabularies for Image Categorization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4270291},
year = {2007}
}
@inproceedings{Perronnin2007,
address = {Minneapolis, MN},
author = {Perronnin, Florent and Dance, Christopher},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2007.383266},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perronnin, Dance - 2007 - Fisher kernels on visual vocabularies for image categorization.pdf:pdf},
pages = {1--8},
publisher = {IEEE},
title = {{Fisher kernels on visual vocabularies for image categorization}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4270291},
year = {2007}
}
@article{Petrou2012,
abstract = {It is argued that robotic platforms are the way forward towards building intelligent systems, where multiple sensors and manipulation are used for cognitive processes. It is also argued that the cue for developing the right architecture for such a system is human language.},
author = {Petrou, Maria},
doi = {10.1016/j.imavis.2011.10.005},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrou - 2012 - The road to intelligence.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Human language,Intelligent systems,System architecture,Tower of knowledge},
month = {aug},
number = {8},
pages = {474--475},
title = {{The road to intelligence}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885612000716},
volume = {30},
year = {2012}
}
@article{Phoungphol2013,
author = {Phoungphol, Piyaphol},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phoungphol - 2013 - A Classification Framework for Imbalanced Data.pdf:pdf},
title = {{A Classification Framework for Imbalanced Data}},
year = {2013}
}
@inproceedings{Picon2011,
author = {Picon, CT and Rossi, Isadora and Ponti-Jr, M},
booktitle = {Workshop of Undergraduate Works},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Picon, Rossi, Jr - 2011 - An{\'{a}}lise da classifica{\c{c}}{\~{a}}o de imagens por descritores de cor utilizando v{\'{a}}rias resolu{\c{c}}{\~{o}}es.pdf:pdf},
keywords = {-reconhecimento de padr{\~{o}}es,abstract,classifica{\c{c}}{\~{a}}o de ima-,descritores de cor,feature extraction and classification,gens,involves choices in,pattern recognition in images,steps of acquisition,the},
publisher = {SIBGRAPI},
title = {{An{\'{a}}lise da classifica{\c{c}}{\~{a}}o de imagens por descritores de cor utilizando v{\'{a}}rias resolu{\c{c}}{\~{o}}es}},
url = {http://www.icmc.usp.br/{~}moacir/papers/Picon{\_}WUW2011.pdf},
year = {2011}
}
@article{Polesel2000,
abstract = {This paper presents a new method for unsharp masking for contrast enhancement of images. The approach employs an adaptive filter that controls the contribution of the sharpening path in such a way that contrast enhancement occurs in high detail areas and little or no image sharpening occurs in smooth areas.},
author = {Polesel, Andrea and Ramponi, Giovanni and Mathews, V. John},
doi = {10.1109/83.826787},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Polesel, Ramponi, Mathews - 2000 - Image enhancement via adaptive unsharp masking.pdf:pdf},
issn = {1057-7149},
journal = {IEEE transactions on image processing},
month = {jan},
number = {3},
pages = {505--10},
pmid = {18255421},
title = {{Image enhancement via adaptive unsharp masking.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18255421},
volume = {9},
year = {2000}
}
@article{Ponti2013,
abstract = {The development of low-cost remote sensing systems is important in small agriculture business, particularly in developing countries, to allow feasible use of images to gather information. However, images obtained through such systems with uncalibrated cameras have often illumination variations, shadows, and other elements that can hinder the analysis by image processing techniques. This letter investigates the combination of vegetation indices (color index of vegetation extraction, visual vegetation index, and excess green) and the mean-shift algorithm, based on the local density estimation in the color space on images acquired by a low-cost system. The objective is to detect green coverage, gaps, and degraded areas. The results showed that combining local density estimation and vegetation indices improves the segmentation accuracy when compared with the competing methods. It deals well with images in different conditions and with regions of imbalanced sizes, confirming the practical application of the low-cost system.},
author = {Ponti, Moacir},
doi = {10.1109/LGRS.2012.2193113},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ponti - 2013 - Segmentation of Low-Cost Remote Sensing Images Combining Vegetation Indices and Mean Shift.pdf:pdf},
issn = {1545-598X},
journal = {IEEE Geoscience and Remote Sensing Letters},
keywords = {Accuracy,Agriculture,Image color analysis,Image segmentation,Indexes,Remote sensing,Vegetation mapping,precision agriculture,preprocessing,segmentation,vegetation indices},
mendeley-tags = {preprocessing,segmentation},
month = {jan},
number = {1},
pages = {67--70},
publisher = {IEEE},
shorttitle = {Geoscience and Remote Sensing Letters, IEEE},
title = {{Segmentation of Low-Cost Remote Sensing Images Combining Vegetation Indices and Mean Shift}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6202674},
volume = {10},
year = {2013}
}
@article{Ponti2010,
author = {Ponti, Moacir P},
doi = {10.4018/jncr.2010100104},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ponti - 2012 - Microscope volume segmentation improved through non-linear restoration.pdf:pdf},
issn = {1947-928X},
journal = {International Journal of Natural Computing Research},
keywords = {automatic segmentation,deconvolution,image analysis},
month = {jan},
number = {4},
pages = {37--46},
publisher = {IGI Global},
title = {{Microscope Volume Segmentation Improved through Non-Linear Restoration}},
url = {http://www.igi-global.com/article/microscope-segmentation-improved-through-non/52614 http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/jncr.2010100104},
volume = {1},
year = {2010}
}
@inproceedings{Ponti-Jr2013,
address = {Austin, TX, Estados Unidos},
author = {Ponti, Moacir and Escobar, Luciana},
booktitle = {Global Conference on Signal and Information Processing},
doi = {10.1109/GlobalSIP.2013.6737000},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ponti, Escobar - 2013 - Compact color features with bitwise quantization and reduced resolution for mobile processing.pdf:pdf},
pages = {751--754},
title = {{Compact color features with bitwise quantization and reduced resolution for mobile processing}},
url = {http://link.springer.com/article/10.1007/s11760-011-0216-x},
year = {2013}
}
@article{Ponti-Jr2011,
annote = {
        

        

        From Duplicate 1 ( 
        

        

        

        
          

          

          

        
        
          Three-dimensional noisy image restoration using filtered extrapolation and deconvolution
        
        
          

          

          

        
        

        

        

         - Ponti-Jr, M P Moacir P; Mascarenhas, Nelson D a. N D A; Ferreira, Paulo J S G; Suazo, Claudio a. T )

          

          

          

        
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        
From Duplicate 2 ( 

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        
Three-dimensional noisy image restoration using filtered extrapolation and deconvolution

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        
- Ponti-Jr, MP Moacir P.; Mascarenhas, Nelson D. a. NDA; Ferreira, Paulo J. S. G.; Suazo, Claudio a. T. )

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        From Duplicate 2 ( 
        

        

        

        
          

          

          

        
        
          Three-dimensional noisy image restoration using filtered extrapolation and deconvolution
        
        
          

          

          

        
        

        

        

         - Ponti-Jr, MP Moacir P.; Mascarenhas, Nelson D. a. NDA; Ferreira, Paulo J. S. G.; Suazo, Claudio a. T. )

          

          

          

        
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        From Duplicate 2 ( 
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        
          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

        
        

        

        

        
          

          

          

        
        
          Three-dimensional noisy image restoration using filtered extrapolation and deconvolution
        
        
          

          

          

        
        

        

        

        
          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

        
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

         - Ponti-Jr, MP Moacir P.; Mascarenhas, Nelson D. a. NDA; Ferreira, Paulo J. S. G.; Suazo, Claudio a. T. )

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

          

        
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        <br},
author = {Ponti, Moacir and Mascarenhas, Nelson and Ferreira, Paulo and Suazo, Claudio},
doi = {10.1007/s11760-011-0216-x},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ponti-Jr et al. - 2011 - Three-dimensional noisy image restoration using filtered extrapolation and deconvolution.pdf:pdf},
issn = {1863-1703},
journal = {Signal, Image and Video Processing},
keywords = {computational optical,filtered extrapolation,image restoration,sectioning microscopy},
month = {feb},
number = {1},
pages = {1--10},
title = {{Three-dimensional noisy image restoration using filtered extrapolation and deconvolution}},
url = {http://link.springer.com/10.1007/s11760-011-0216-x http://link.springer.com/article/10.1007/s11760-011-0216-x},
volume = {7},
year = {2011}
}
@article{Ponti2016,
abstract = {The image-based visual recognition pipeline includes a step that converts color images into images with a single channel, obtaining a color-quantized image that can be processed by feature extraction methods. In this paper we explore this step in order to produce compact features that can be used in retrieval and classification systems. We show that different quantization methods produce very different results in terms of accuracy. While compared with more complex methods, this procedure allows the feature extraction in order to achieve a significant dimensionality reduction, while preserving or improving system accuracy. The results indicate that quantization simplify images before feature extraction and dimensionality reduction, producing more compact vectors and reducing system complexity.},
author = {Ponti, Moacir and Nazar{\'{e}}, Tiago S. and Thum{\'{e}}, Gabriela S.},
doi = {10.1016/j.neucom.2015.04.114},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ponti, Nazar{\'{e}}, Thum{\'{e}} - 2016 - Image quantization as a dimensionality reduction procedure in color and texture feature extraction(2).pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Compact features extraction,Image quantization,LPP},
month = {jan},
pages = {385--396},
title = {{Image quantization as a dimensionality reduction procedure in color and texture feature extraction}},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215012771},
volume = {173},
year = {2016}
}
@incollection{Prati2004,
author = {Prati, RC R.C. C R C and Batista, G.E. GE E G E and Monard, MC M.C. C M C},
booktitle = {MICAI 2004: Advances in Artificial Intelligence},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prati, Batista, Monard - 2004 - Class imbalances versus class overlapping an analysis of a learning system behavior.pdf:pdf},
pages = {312--321},
publisher = {Springer Berlin Heidelberg},
title = {{Class imbalances versus class overlapping: an analysis of a learning system behavior}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-24694-7{\_}32 http://download.springer.com/static/pdf/643/chp:10.1007/978-3-540-24694-7{\_}32.pdf?auth66=1413225006{\_}a0c4923c4afec687226c795df4981889{\&}ext=.pdf http://download.springer.com/static/pdf/643/chp{\%}3A10.1007{\%}2F978-3-540-24694-7{\_}32.pdf?auth66=1413225006{\_}a0c4923c4afec687226c795df4981889{\&}ext=.pdf},
year = {2004}
}
@article{Ramanath2005,
author = {Ramanath, R and Snyder, WE E},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramanath, Snyder - 2005 - Color image processing pipeline.pdf:pdf},
journal = {IEEE SIGNAL PROCESSING MAGAZINE},
number = {January},
pages = {34--43},
title = {{Color image processing pipeline}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1407713},
year = {2005}
}
@article{Rehman2012,
author = {Rehman, Amjad and Saba, Tanzila},
doi = {10.1007/s10462-012-9337-z},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rehman, Saba - 2012 - Neural networks for document image preprocessing state of the art.pdf:pdf},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
month = {apr},
number = {2},
pages = {253--273},
title = {{Neural networks for document image preprocessing: state of the art}},
url = {http://link.springer.com/10.1007/s10462-012-9337-z},
volume = {42},
year = {2012}
}
@article{Ringner2008,
abstract = {Principal component analysis is often incorporated into genome-wide expression studies, but what is it and how can it be used to explore high-dimensional data?},
author = {Ringner, M},
doi = {10.1038/nbt0308-303},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ringner - 2008 - What is principal component analysis.pdf:pdf},
isbn = {1546-1696},
issn = {1087-0156},
journal = {Nat Biotechnol},
number = {3},
pages = {303--304},
pmid = {18327243},
title = {{What is principal component analysis?}},
url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve{\&}db=PubMed{\&}dopt=Citation{\&}list{\_}uids=18327243},
volume = {26},
year = {2008}
}
@article{Roadmap2010,
author = {Roadmap, Technological and Network, European and Learning, Machine},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roadmap, Network, Learning - 2010 - On multi-class cost-sensitive learning.pdf:pdf},
keywords = {class-imbalance learning,cost-sensitive learning,data mining,machine learning,multi-class problems,rescaling},
number = {3},
title = {{On multi-class cost-sensitive learning}},
volume = {26},
year = {2010}
}
@article{Rocha2010,
abstract = {Contemporary Vision and Pattern Recognition problems such as face recognition, fingerprinting identification, image categorization, and DNA sequencing often have an arbitrarily large number of classes and properties to consider. To deal with such complex problems using just one feature descriptor is a difficult task and feature fusion may become mandatory. Although normal feature fusion is quite effective for some problems, it can yield unexpected classification results when the different features are not properly normalized and preprocessed. Besides it has the drawback of increasing the dimensionality which might require more training data. To cope with these problems, this paper introduces a unified approach that can combine many features and classifiers that requires less training and is more adequate to some problems than a na{\"{\i}}ve method, where all features are simply concatenated and fed independently to each classification algorithm. Besides that, the presented technique is amenable to continuous learning, both when refining a learned model and also when adding new classes to be discriminated. The introduced fusion approach is validated using a multi-class fruit-and-vegetable categorization task in a semi-controlled environment, such as a distribution center or the supermarket cashier. The results show that the solution is able to reduce the classification error in up to 15 percentage points with respect to the baseline.},
author = {Rocha, Anderson and Hauagge, Daniel C and Wainer, Jacques and Goldenstein, Siome},
doi = {10.1016/j.compag.2009.09.002},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rocha et al. - 2010 - Automatic fruit and vegetable classification from images.pdf:pdf},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {Automatic produce classification,Feature and classifier fusion,Image classification,Multi-class from binary},
month = {jan},
number = {1},
pages = {96--104},
title = {{Automatic fruit and vegetable classification from images}},
url = {http://www.sciencedirect.com/science/article/pii/S016816990900180X},
volume = {70},
year = {2010}
}
@article{Rosenblatt1958,
abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems.},
author = {Rosenblatt, F},
doi = {10.1037/h0042519},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosenblatt - 1958 - The perceptron A probabilistic model for information storage and organization in {\ldots}.pdf:pdf},
isbn = {0033-295X},
issn = {1939-1471(Electronic);0033-295X(Print)},
journal = {Psychological Review},
number = {6},
pages = {386--408},
pmid = {13602029},
title = {{The perceptron: A probabilistic model for information storage and organization in {\ldots}}},
url = {http://psycnet.apa.org/journals/rev/65/6/386.pdf$\backslash$npapers://c53d1644-cd41-40df-912d-ee195b4a4c2b/Paper/p15420},
volume = {65},
year = {1958}
}
@article{Russakovsky2015,
author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
doi = {10.1007/s11263-015-0816-y},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
month = {apr},
number = {3},
pages = {211--252},
title = {{ImageNet Large Scale Visual Recognition Challenge}},
url = {http://link.springer.com/10.1007/s11263-015-0816-y},
volume = {115},
year = {2015}
}
@article{Saliba,
author = {SALIBA, E and DIPANDA, A},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/SALIBA, DIPANDA - 2013 - An overview of Pattern Recognition.pdf:pdf},
journal = {wikiprogress. org},
keywords = {classification,feature extraction,pattern recognition,preprocessing},
pages = {1--7},
title = {{An overview of Pattern Recognition}},
url = {http://www.wikiprogress.org/images/An{\_}overview{\_}of{\_}Pattern{\_}Recognition.pdf},
year = {2013}
}
@inproceedings{Sato2014a,
abstract = {Recently, methods for the unsupervised learning of features from large data sets have been attracting much attention. These methods have been especially successful in the area of computer vision. However, there is a problem that it is difficult to determine what kind of features will result in a high classification performance. Indeed, the difficulty of determining the learning parameters is a widely known problem in the field of feature learning. To address this problem, this paper presents a feature-learning method which uses classification results to progressively learn multiple features of varied complexity. The proposed method enables the learning of both simple robust features and complex features which represents difficult patterns. In addition, we assign regularization weights that are based on the complexity of the features. This modification emphasizes simple representation and prevents over fitting. Experimental results with medical image classification show that the proposed method is superior to the conventional method, especially when classification is difficult.},
author = {Sato, Yoshikuni and Kozuka, Kazuki and Sawada, Yoshihide and Kiyono, Masaki},
booktitle = {2014 22nd International Conference on Pattern Recognition},
doi = {10.1109/ICPR.2014.580},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sato et al. - 2014 - Learning Multiple Complex Features Based on Classification Results.pdf:pdf},
isbn = {978-1-4799-5209-0},
issn = {1051-4651},
keywords = {Accuracy,Complexity theory,Computed tomography,Diseases,Feature extraction,Feature learning,Machine learning,Medical imaging,Training,Vectors,classification results,computer vision,feature-learning method,large data sets,learning parameters,medical image classification,medical image processing,multiple complex features learning,pattern classification,regularization weights,unsupervised learning},
month = {aug},
pages = {3369--3373},
publisher = {IEEE},
shorttitle = {Pattern Recognition (ICPR), 2014 22nd Internationa},
title = {{Learning Multiple Complex Features Based on Classification Results}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6977292},
year = {2014}
}
@article{Schmidhuber2014,
abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning {\&} evolutionary computation, and indirect search for short programs encoding deep and large networks.},
archivePrefix = {arXiv},
arxivId = {1404.7828},
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.1016/j.neunet.2014.09.003},
eprint = {1404.7828},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidhuber - 2014 - Deep learning in neural networks An overview.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
month = {oct},
pages = {88},
title = {{Deep learning in neural networks: An overview}},
url = {http://arxiv.org/abs/1404.7828},
year = {2014}
}
@article{Shaked2005,
abstract = {We propose a measure for image sharpness, which facilitates automatic image sharpness enhancement. This way blurry images will be sharpened more whereas sufficiently sharp images will not be sharpened at all. The measure employs localized frequency content analysis in a feature-based context. The proposed sharpness measure correlates well with perceived sharpness, and is to a large degree invariant to image content. Furthermore, we show that the proposed measure can be used to drive an enhancement algorithm, which will sharpen an input image to a nominal measure. Last but not least, the proposed sharpness measure is computationally efficient, and requires fewer computations than a 3{\&}amp;times;3 convolution.},
author = {Shaked, Doron and Tastl, Ingeborg},
doi = {10.1109/ICIP.2005.1529906},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shaked, Tastl - 2005 - Sharpness measure Towards automatic image enhancement.pdf:pdf},
isbn = {0780391349},
issn = {15224880},
journal = {Proceedings - International Conference on Image Processing, ICIP},
keywords = {feature extraction,image analysis,image enhancement,image sharpening},
number = {September},
pages = {937--940},
title = {{Sharpness measure: Towards automatic image enhancement}},
volume = {1},
year = {2005}
}
@article{Shyu1998,
abstract = {Image enhancement techniques are used to improve image quality or extract the fine details in the degraded images. Most existing color image enhancement techniques usually have three weaknesses: (1) color image enhancement applied in the RGB (red, green, blue) color space is inappropriate for the human visual system; (2) the uniform distribution constraint employed is not suitable for human visual perception; (3) they are not robust, i.e., one technique is usually suitable for one type of degradations only. In this study, a genetic algorithm (GA) approach to color image enhancement is proposed, in which color image enhancement is formulated as an optimization problem. In the proposed approach, a set of generalized transforms for color image enhancement is formed by linearly weighted combining four types of nonlinear transforms. The fitness (objective) function for GAs is formed by four performance measures, namely, the AC power measure, the compactness measure, the Brenner’s measure, and the information–noise change measure. Then GAs are used to determine the “optimal” set of generalized transforms with the largest fitness function value. Based on the experimental results obtained in this study, the enhanced color images by the proposed approach are better than that by any of the three existing approaches for comparison. This shows the feasibility of the proposed approach.},
author = {Shyu, Ming-Suen and Leou, Jin-Jang},
doi = {10.1016/S0031-3203(97)00073-3},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shyu, Leou - 1998 - A genetic algorithm approach to color image enhancement.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Color image enhancement,Fitness function,Generalized transform,Genetic algorithm (GA),Uniform distribution constraint},
number = {7},
pages = {871--880},
title = {{A genetic algorithm approach to color image enhancement}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320397000733},
volume = {31},
year = {1998}
}
@inproceedings{Simonyan2013,
abstract = {This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [Erhan et al., 2009], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [Zeiler et al., 2013].},
archivePrefix = {arXiv},
arxivId = {1312.6034},
author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
booktitle = {ICLR Workshop},
eprint = {1312.6034},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Simonyan, Vedaldi, Zisserman - 2013 - Deep Inside Convolutional Networks Visualising Image Classification Models and Saliency Maps.pdf:pdf},
month = {dec},
pages = {1--8},
title = {{Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps}},
url = {http://arxiv.org/abs/1312.6034},
year = {2013}
}
@article{Simonyan2014,
abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
archivePrefix = {arXiv},
arxivId = {1409.1556},
author = {Simonyan, Karen and Zisserman, Andrew},
eprint = {1409.1556},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Simonyan, Zisserman - 2014 - Very Deep Convolutional Networks for Large-Scale Image Recognition.pdf:pdf},
month = {sep},
title = {{Very Deep Convolutional Networks for Large-Scale Image Recognition}},
url = {http://arxiv.org/abs/1409.1556},
year = {2014}
}
@article{Sklansky1978,
abstract = {An overview of present computer techniques of partitioning continuous-tone images into meaningful segments and of characterizing these segments by sets of "features" is presented. Segmentation often consists of two methods:boundary detection and texture analysis. Both of these are discussed. The design of the segmenter and feature extractor are intimately related to the design of the rest of the image analysis system{\^{A}}¿particularly the preprocessor and the classifier. Toward aiding this design, a few guidelines and illustrative examples are included.},
author = {Sklansky, Jack},
doi = {10.1109/TSMC.1978.4309944},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sklansky - 1978 - Image Segmentation and Feature Extraction.pdf:pdf},
issn = {0018-9472},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
keywords = {Biomedical imaging,Computer vision,Detectors,Feature extraction,Guidelines,Image analysis,Image segmentation,Image texture analysis,Labeling,Layout,feature extraction,preprocessing,segmentation},
mendeley-tags = {feature extraction,preprocessing,segmentation},
number = {4},
pages = {237--247},
shorttitle = {Systems, Man and Cybernetics, IEEE Transactions on},
title = {{Image Segmentation and Feature Extraction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4309944},
volume = {8},
year = {1978}
}
@article{Smith1997,
abstract = {This paper describes a new approach to low level image processing; in particular, edge and corner detection and structure preserving noise reduction. Non-linear ﬁltering is used to deﬁne which parts of the image are closely related to each individual pixel; each pixel has associated with it a local image region which is of similar brightness to that pixel. The new feature detectors are based on the minimization of this local image region, and the noise reduction method uses this region as the smoothing neighbourhood. The resulting methods are accurate, noise resistant and fast. Details of the new feature detectors and of the new noise reduction method are described, along with test results.},
author = {Smith, SM M and Brady, JM M},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith, Brady - 1997 - SUSAN—a new approach to low level image processing.pdf:pdf},
journal = {International journal of computer vision},
number = {1},
pages = {45--78},
title = {{SUSAN—a new approach to low level image processing}},
url = {http://link.springer.com/article/10.1023/A:1007963824710},
volume = {23},
year = {1997}
}
@article{Snyers1995,
abstract = {image transformations and enhancement},
author = {Snyers, D. and P{\'{e}}tillot, Y.},
doi = {10.1016/0167-8655(95)00044-H},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Snyers, P{\'{e}}tillot - 1995 - Image processing optimization by genetic algorithm with a new coding scheme.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {1,genetic algorithm,i n t r,image processing,in a wide range,in the last ten,iterative optimization tech-,niques have been applied,o d u c,of domains,optimization,t i o n,years},
number = {8},
pages = {843--848},
title = {{Image processing optimization by genetic algorithm with a new coding scheme}},
volume = {16},
year = {1995}
}
@article{Soda2011,
abstract = {Class imbalance limits the performance of most learning algorithms since they cannot cope with large differences between the number of samples in each class, resulting in a low predictive accuracy over the minority class. In this respect, several papers proposed algorithms aiming at achieving more balanced performance. However, balancing the recognition accuracies for each class very often harms the global accuracy. Indeed, in these cases the accuracy over the minority class increases while the accuracy over the majority one decreases. This paper proposes an approach to overcome this limitation: for each classification act, it chooses between the output of a classifier trained on the original skewed distribution and the output of a classifier trained according to a learning method addressing the course of imbalanced data. This choice is driven by a parameter whose value maximizes, on a validation set, two objective functions, i.e. the global accuracy and the accuracies for each class. A series of experiments on ten public datasets with different proportions between the majority and minority classes show that the proposed approach provides more balanced recognition accuracies than classifiers trained according to traditional learning methods for imbalanced data as well as larger global accuracy than classifiers trained on the original skewed distribution.},
author = {Soda, Paolo},
doi = {10.1016/j.patcog.2011.01.015},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soda - 2011 - A multi-objective optimisation approach for class imbalance learning.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Class imbalance learning,Machine learning,Multi-objective optimisation,Pattern recognition},
month = {aug},
number = {8},
pages = {1801--1810},
title = {{A multi-objective optimisation approach for class imbalance learning}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320311000410},
volume = {44},
year = {2011}
}
@book{Soediono1989,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Soediono, Budi},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soediono - 1989 - No Title No Title.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
pages = {160},
pmid = {25246403},
title = {{Python Data Science Cookbook}},
volume = {53},
year = {2015}
}
@article{Sokolova2009,
author = {Sokolova, Marina and Lapalme, Guy},
doi = {10.1016/j.ipm.2009.03.002},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sokolova, Lapalme - 2009 - A systematic analysis of performance measures for classification tasks.pdf:pdf},
issn = {03064573},
journal = {Information Processing {\&} Management},
keywords = {performance evaluation},
month = {jul},
number = {4},
pages = {427--437},
publisher = {Elsevier Ltd},
title = {{A systematic analysis of performance measures for classification tasks}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0306457309000259},
volume = {45},
year = {2009}
}
@inproceedings{Sotiropoulos2012,
abstract = {In this paper, we compare the performance of Artificial Immune System (AIS)-based classification algorithms to the performance of Gaussian kernel-based Support Vector Machines (SVM) in problems with a high degree of class imbalance. Our experimentation indicates that the AIS-based classification paradigm has the intrinsic properly of dealing more efficiently with highly skewed datasets. Specifically, our experimental results indicate that AIS-based classifiers identify instances from the minority class quite efficiently.},
author = {Sotiropoulos, Dionysios N. and Tsihrintzis, George A.},
booktitle = {Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing},
doi = {10.1109/IIH-MSP.2012.39},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sotiropoulos, Tsihrintzis - 2012 - Artificial Immune System-based Classification in Class-Imbalanced Image Classification Problems.pdf:pdf},
isbn = {978-1-4673-1741-2},
keywords = {AIS-based classification algorithms,Artificial Immune Systems,Classification algorithms,Gaussian kernel-based support vector machines,Immune system,Machine learning,Machine learning algorithms,SVM,Support vector machines,Training,Vectors,artificial immune system-based classification,artificial immune systems,class imbalance,class-imbalanced image classification problems,image classification,imbalanced,minority class,support vector machines},
mendeley-tags = {imbalanced},
month = {jul},
pages = {138--141},
publisher = {IEEE},
shorttitle = {Intelligent Information Hiding and Multimedia Sign},
title = {{Artificial Immune System-based Classification in Class-Imbalanced Image Classification Problems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6274632},
year = {2012}
}
@inproceedings{bic,
address = {New York, USA},
author = {Stehling, Renato O. and Nascimento, Mario A. and Falc{\~{a}}o, Alexandre X.},
booktitle = {Proceedings of the eleventh international conference on Information and knowledge management},
doi = {10.1145/584792.584812},
isbn = {1581134924},
keywords = {CBIR,color histogram,content-based image retrieval,distance function,image analysis},
month = {nov},
pages = {102--109},
publisher = {ACM Press},
title = {{A compact and efficient image retrieval approach based on border/interior pixel classification}},
url = {http://dl.acm.org/citation.cfm?id=584792.584812},
year = {2002}
}
@article{Szegedy2014,
abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
archivePrefix = {arXiv},
arxivId = {1409.4842},
author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
eprint = {1409.4842},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Szegedy et al. - 2014 - Going Deeper with Convolutions.pdf:pdf},
month = {sep},
pages = {1--12},
title = {{Going Deeper with Convolutions}},
url = {http://arxiv.org/abs/1409.4842v1 http://arxiv.org/abs/1409.4842},
year = {2014}
}
@article{Talebi2014,
abstract = {In this paper, we introduce a new image editing tool based on the spectrum of a global filter computed from image affinities. Recently, it has been shown that the global filter derived from a fully connected graph representing the image can be approximated using the Nystr{\"{o}}m extension. This filter is computed by approximating the leading eigenvectors of the filter. These orthonormal eigenfunctions are highly expressive of the coarse and fine details in the underlying image, where each eigenvector can be interpreted as one scale of a data-dependent multiscale image decomposition. In this filtering scheme, each eigenvalue can boost or suppress the corresponding signal component in each scale. Our analysis shows that the mapping of the eigenvalues by an appropriate polynomial function endows the filter with a number of important capabilities, such as edge-aware sharpening, denoising, tone manipulation, and abstraction, to name a few. Furthermore, the edits can be easily propagated across the image.},
author = {Talebi, Hossein and Milanfar, Peyman},
doi = {10.1109/TIP.2014.2348870},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Talebi, Milanfar - 2014 - Nonlocal image editing.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
month = {oct},
number = {10},
pages = {4460--73},
pmid = {25148666},
title = {{Nonlocal image editing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25148666},
volume = {23},
year = {2014}
}
@article{Tan2012,
abstract = {Noisy iris recognition under visible lighting has recently drawn much attention. This paper proposes an effective method for visible light iris image matching by using multiple characteristics of iris and eye images. The method consists of image preprocessing, iris data matching, eye data matching, and multi-modal fusion. Ordinal measures and color analysis are adopted for iris data matching, and texton representation and semantic information are used for eye data matching. After we obtain the four matching scores, a robust score level fusion strategy is applied to generate the dissimilarity measure of the two images under consideration. Extensive experiments on the UBIRIS.v2 database and the NICE.II training dataset demonstrate that the proposed method is effective. Our method significantly outperforms all other algorithms submitted to the Noisy Iris Challenge Evaluation-Part II (NICE.II), an open contest in noisy iris image matching.},
author = {Tan, Tieniu and Zhang, Xiaobo and Sun, Zhenan and Zhang, Hui},
doi = {10.1016/j.patrec.2011.08.009},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tan et al. - 2012 - Noisy iris image matching by using multiple cues.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Eye data matching,Iris data matching,Iris recognition,Noisy iris image matching,Robust fusion,Visible lighting,preprocessing},
mendeley-tags = {preprocessing},
month = {jun},
number = {8},
pages = {970--977},
title = {{Noisy iris image matching by using multiple cues}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865511002601},
volume = {33},
year = {2012}
}
@article{Tan2010,
author = {Tan, Xiaoyang and Triggs, Bill},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tan, Triggs - 2010 - Enhanced Local Texture Feature Sets for Face Recognition Under Difficult Lighting Conditions.pdf:pdf},
journal = {IEEE transactions on image processing},
number = {6},
pages = {1635--1650},
title = {{Enhanced Local Texture Feature Sets for Face Recognition Under Difficult Lighting Conditions}},
volume = {19},
year = {2010}
}
@article{Tanimoto1975,
abstract = {In order to speed up several picture processing operations, including edge detection, a “pyramid” (hierarchy of fine to coarse resolution versions of a picture) is produced. The low spatial frequencies preserved in coarse pictures are helpful in finding regions of interest in fine pictures at law cost. Tree structure properties of the pyramid are investigated as well as the transfer function of the compression transformation. A recursive “refining” algorithm is given for edge detection. Its computational savings are demonstrated both theoretically and in practical examples.},
author = {Tanimoto, S. and Pavlidis, T.},
doi = {10.1016/S0146-664X(75)80003-7},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tanimoto, Pavlidis - 1975 - A hierarchical data structure for picture processing.pdf:pdf},
issn = {0146664X},
journal = {Computer Graphics and Image Processing},
month = {jun},
number = {2},
pages = {104--119},
title = {{A hierarchical data structure for picture processing}},
url = {http://www.sciencedirect.com/science/article/pii/S0146664X75800037},
volume = {4},
year = {1975}
}
@article{Taylor2010,
author = {Taylor, GW W and Fergus, Rob and LeCun, Y and Bregler, Christoph},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Taylor et al. - 2010 - Convolutional learning of spatio-temporal features.pdf:pdf},
journal = {Computer Vision–ECCV 2010},
keywords = {activity recognition,con-,optical flow,restricted boltzmann machines,unsupervised learning,video analysis,volutional nets},
title = {{Convolutional learning of spatio-temporal features}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-15567-3{\_}11},
year = {2010}
}
@article{Tieleman2014,
author = {Tieleman, Tijmen},
file = {:home/gabi/Downloads/tijmen{\_}thesis.pdf:pdf},
title = {{Optimizing Neural Networks that Generate Images}},
year = {2014}
}
@inproceedings{Tomasi1998,
abstract = {Bilateral filtering smooths images while preserving edges, by means of a nonlinear combination of nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness and their photometric similarity, and prefers near values to distant values in both domain and range. In contrast with filters that operate on the three bands of a color image separately, a bilateral filter can enforce the perceptual metric underlying the CIE-Lab color space, and smooth colors and preserve edges in a way that is tuned to human perception. Also, in contrast with standard filtering, bilateral filtering produces no phantom colors along edges in color images, and reduces phantom colors where they appear in the original image},
author = {Tomasi, C. and Manduchi, R.},
booktitle = {Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},
doi = {10.1109/ICCV.1998.710815},
file = {:home/gabi/Documentos/00710815.pdf:pdf},
isbn = {81-7319-221-9},
keywords = {Color,Computer science,Filtering,Humans,Imaging phantoms,Low pass filters,Photometry,Pixel,Shape measurement,Smoothing methods,bilateral filtering,color images,colour vision,computer vision,edges preservation,geometric closeness,gray images,image processing,perceptual metric,phantom colors,photometric similarity},
pages = {839--846},
publisher = {Narosa Publishing House},
shorttitle = {Computer Vision, 1998. Sixth International Confere},
title = {{Bilateral filtering for gray and color images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=710815},
year = {1998}
}
@article{Tompson2014,
abstract = {Recent state-of-the-art performance on human-body pose estimation has been achieved with Deep Convolutional Networks (ConvNets). Traditional ConvNet architectures include pooling layers which reduce computational requirements, introduce invariance and prevent over-training. These benefits of pooling come at the cost of reduced localization accuracy. We introduce a novel architecture which includes an efficient 'position refinement' model that is trained to estimate the joint offset location within a small region of the image. This refinement model is jointly trained in cascade with a state-of-the-art ConvNet model to achieve improved accuracy in human joint location estimation. We show that the variance of our detector approaches the variance of human annotations on the FLIC dataset and outperforms all existing approaches on the MPII-human-pose dataset.},
archivePrefix = {arXiv},
arxivId = {1411.4280},
author = {Tompson, Jonathan and Goroshin, Ross and Jain, Arjun and LeCun, Yann and Bregler, Christopher},
eprint = {1411.4280},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tompson et al. - 2014 - Efficient Object Localization Using Convolutional Networks.pdf:pdf},
month = {nov},
pages = {8},
title = {{Efficient Object Localization Using Convolutional Networks}},
url = {http://arxiv.org/abs/1411.4280},
year = {2014}
}
@article{Trussell2005,
author = {Trussell, HJ J and Saber, E and Vrhel, M},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Trussell, Saber, Vrhel - 2005 - Color image processing Basics and special issue overview.pdf:pdf},
journal = {IEEE Signal Processing Magazine},
title = {{Color image processing: Basics and special issue overview}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:No+Title{\#}0 http://www.google.com/patents/US5636290 https://ritdml.rit.edu/handle/1850/9013},
year = {2005}
}
@article{Turk1991,
abstract = {We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as "eigenfaces," because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture.},
author = {Turk, M and Pentland, a},
doi = {10.1162/jocn.1991.3.1.71},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Turk, Pentland - 1991 - Eigenfaces for recognition.pdf:pdf},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
month = {jan},
number = {1},
pages = {71--86},
pmid = {23964806},
title = {{Eigenfaces for recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23964806},
volume = {3},
year = {1991}
}
@inproceedings{VanHulse2007,
address = {New York, New York, USA},
author = {{Van Hulse}, Jason and Khoshgoftaar, Taghi M. and Napolitano, Amri},
booktitle = {Proceedings of the 24th international conference on Machine learning},
doi = {10.1145/1273496.1273614},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Hulse, Khoshgoftaar, Napolitano - 2007 - Experimental perspectives on learning from imbalanced data.pdf:pdf},
isbn = {9781595937933},
month = {jun},
pages = {935--942},
publisher = {ACM Press},
title = {{Experimental perspectives on learning from imbalanced data}},
url = {http://dl.acm.org/citation.cfm?id=1273496.1273614},
year = {2007}
}
@article{Verma2012,
abstract = {This paper presents a novel approach for the enhancement of high dynamic range color images using fuzzy logic and modified Artificial Ant Colony System techniques. Two thresholds, the lower and the upper are defined to provide an estimate of the underexposed, mixed-exposed and overexposed regions in the image. The red, green and blue (RGB) color space is converted into Hue Saturation and Value (HSV) color space so as to preserve the chromatic information. Gaussian MFs suitable for the underexposed and overexposed regions of the image are used for the fuzzification. Parametric sigmoid functions are used for enhancing the luminance components of under and over-exposed regions. Mixed-exposed regions are left untouched throughout the process. An objective function comprising of Shannon entropy function as the information factor and visual appeal indicator is optimized using Artificial Ant Colony System to ascertain the parameters needed for the enhancement of a particular image. Visual appeal is preferred over the consideration of entropy so as to make the image human-eye-friendly. Separate power law operators are used for the saturation adjustment so as to restore the lost information. On comparison, this approach is found to be better than the bacterial foraging (BF)-based approach [1]. ©},
author = {Verma, Om Prakash and Kumar, Puneet and Hanmandlu, Madasu and Chhabra, Sidharth},
doi = {10.1016/j.asoc.2011.08.033},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Verma et al. - 2012 - High dynamic range optimal fuzzy color image enhancement using Artificial Ant Colony System.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing},
keywords = {artificial ant colony system},
number = {1},
pages = {394--404},
publisher = {Elsevier B.V.},
title = {{High dynamic range optimal fuzzy color image enhancement using Artificial Ant Colony System}},
url = {http://dx.doi.org/10.1016/j.asoc.2011.08.033},
volume = {12},
year = {2012}
}
@article{Vidal2012,
abstract = {Hyperspectral Imaging is an essential technique to deep explore surfaces in which more detail than the one provided by the single point spectroscopy is needed. Many devices for acquiring hyperspectral images have been manufactured and there is an increasing interest for improving the data analysis techniques applied to such complex datasets. Regardless the instrumentation, the acquisition of the images is being constantly improved by setting faster and more robust detectors, including new cooling systems or improving the light sources. Nevertheless, there are several issues that must be handled before starting the data analysis of any sample (e.g. background removal, compression of the images, spiked points, dead pixels, etc.). Therefore, the step of image pre-processing is almost always required. The aim of this paper is to show the application of some of the most common possibilities to solve the above mentioned issues before the image processing. This is done in a practical way, providing examples of their application, pros and cons as well as their implementation. For this purpose, several real examples (pharmaceutical tablets and food stuff) have been used throughout this manuscript.},
author = {Vidal, Maider and Amigo, Jos{\'{e}} Manuel},
doi = {10.1016/j.chemolab.2012.05.009},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vidal, Amigo - 2012 - Pre-processing of hyperspectral images. Essential steps before image analysis.pdf:pdf},
issn = {01697439},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {Background removal,Hyperspectral,Near Infrared,Pre-processing,Raman,Spikes,Wavelets,preprocessing},
mendeley-tags = {preprocessing},
month = {aug},
pages = {138--148},
title = {{Pre-processing of hyperspectral images. Essential steps before image analysis}},
url = {http://www.sciencedirect.com/science/article/pii/S0169743912001220},
volume = {117},
year = {2012}
}
@inproceedings{Viola2001,
abstract = {This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the "integral image" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.},
author = {Viola, P. and Jones, M.},
booktitle = {Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},
doi = {10.1109/CVPR.2001.990517},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viola, Jones - 2001 - Rapid object detection using a boosted cascade of simple features.pdf:pdf},
isbn = {0-7695-1272-0},
issn = {1063-6919},
keywords = {AdaBoost,Detectors,Face detection,Filters,Focusing,Image representation,Machine learning,Object detection,Pixel,Robustness,Skin,background regions,boosted simple feature cascade,classification,classifiers,face detection,feature extraction,image classification,image processing,image representation,integral image,learning (artificial intelligence),machine learning,object detection,object specific focus-of-attention mechanism,rapid object detection,real-time applications,statistical guarantees,visual object detection},
mendeley-tags = {classification},
pages = {I--511--I--518},
publisher = {IEEE Comput. Soc},
shorttitle = {Computer Vision and Pattern Recognition, 2001. CVP},
title = {{Rapid object detection using a boosted cascade of simple features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=990517},
volume = {1},
year = {2001}
}
@article{Wall2003,
abstract = {This chapter describes gene expression analysis by Singular Value Decomposition (SVD), emphasizing initial characterization of the data. We describe SVD methods for visualization of gene expression data, representation of the data using a smaller number of variables, and detection of patterns in noisy gene expression data. In addition, we describe the precise relation between SVD analysis and Principal Component Analysis (PCA) when PCA is calculated using the covariance matrix, enabling our descriptions to apply equally well to either method. Our aim is to provide definitions, interpretations, examples, and references that will serve as resources for understanding and extending the application of SVD and PCA to gene expression analysis.},
archivePrefix = {arXiv},
arxivId = {physics/0208101v4},
author = {Wall, Me and Rechtsteiner, Andreas and Rocha, Lm},
doi = {10.1007/0-306-47815-3{\_}5},
eprint = {0208101v4},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wall, Rechtsteiner, Rocha - 2003 - Singular value decomposition and principal component analysis.pdf:pdf},
isbn = {1-4020-7260-0},
issn = {09240136},
journal = {A Practical Approach to Microarray Data Analysis},
pages = {91--109},
primaryClass = {physics},
title = {{Singular value decomposition and principal component analysis}},
url = {http://link.springer.com/content/pdf/10.1007/b101875.pdf{\#}page=104},
year = {2003}
}
@article{Wang2001,
abstract = {We present here SIMPLIcity (semantics-sensitive integrated matching for picture libraries), an image retrieval system, which uses semantics classification methods, a wavelet-based approach for feature extraction, and integrated region matching based upon image segmentation. An image is represented by a set of regions, roughly corresponding to objects, which are characterized by color, texture, shape, and location. The system classifies images into semantic categories. Potentially, the categorization enhances retrieval by permitting semantically-adaptive searching methods and narrowing down the searching range in a database. A measure for the overall similarity between images is developed using a region-matching scheme that integrates properties of all the regions in the images. The application of SIMPLIcity to several databases has demonstrated that our system performs significantly better and faster than existing ones. The system is fairly robust to image alterations},
author = {Wang, J.Z. and Wiederhold, G.},
doi = {10.1109/34.955109},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Content based retrieval,Image classification,Image databases,Image retrieval,Image segmentation,Image storage,Information retrieval,Libraries,Pixel,Robustness,SIMPLIcity,clustering,content based image retrieval,content-based retrieval,feature extraction,image classification,image retrieval,image segmentation,pattern clustering,pattern matching,region matching,semantics classification,visual databases,wavelet,wavelet transforms},
number = {9},
pages = {947--963},
shorttitle = {IEEE Transactions on Pattern Analysis and Machine },
title = {{SIMPLIcity: semantics-sensitive integrated matching for picture libraries}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=955109},
volume = {23},
year = {2001}
}
@inproceedings{Wang2010,
abstract = {The traditional SPM approach based on bag-of-features (BoF) requires nonlinear classifiers to achieve good image classification performance. This paper presents a simple but effective coding scheme called Locality-constrained Linear Coding (LLC) in place of the VQ coding in traditional SPM. LLC utilizes the locality constraints to project each descriptor into its local-coordinate system, and the projected coordinates are integrated by max pooling to generate the final representation. With linear classifier, the proposed approach performs remarkably better than the traditional nonlinear SPM, achieving state-of-the-art performance on several benchmarks. Compared with the sparse coding strategy [22], the objective function used by LLC has an analytical solution. In addition, the paper proposes a fast approximated LLC method by first performing a K-nearest-neighbor search and then solving a constrained least square fitting problem, bearing computational complexity of O(M + K2). Hence even with very large codebooks, our system can still process multiple frames per second. This efficiency significantly adds to the practical values of LLC for real applications.},
author = {Wang, Jinjun and Yang, Jianchao and Yu, Kai and Lv, Fengjun and Huang, Thomas and Gong, Yihong},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5540018},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2010 - Locality-constrained Linear Coding for image classification.pdf:pdf},
isbn = {978-1-4244-6984-0},
issn = {1063-6919},
keywords = {Image classification,Image coding,K-nearest-neighbor search,VQ coding,bag-of-features,computational complexity,constrained least square fitting problem,image classification,image coding,image matching,learning (artificial intelligence),least squares approximations,locality-constrained linear coding,nonlinear classifiers,sparse coding strategy,spatial pyramid matching,vector quantisation},
month = {jun},
pages = {3360--3367},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Locality-constrained Linear Coding for image classification}},
year = {2010}
}
@inproceedings{Wang2009a,
abstract = {By combining Histograms of Oriented Gradients (HOG) and Local Binary Pattern (LBP) as the feature set, we propose a novel human detection approach capable of handling partial occlusion. Two kinds of detectors, i.e., global detector for whole scanning windows and part detectors for local regions, are learned from the training data using linear SVM. For each ambiguous scanning window, we construct an occlusion likelihood map by using the response of each block of the HOG feature to the global detector. The occlusion likelihood map is then segmented by Mean-shift approach. The segmented portion of the window with a majority of negative response is inferred as an occluded region. If partial occlusion is indicated with high likelihood in a certain scanning window, part detectors are applied on the unoccluded regions to achieve the final classification on the current scanning window. With the help of the augmented HOG-LBP feature and the global-part occlusion handling method, we achieve a detection rate of 91.3{\%} with FPPW= 10−6, 94.7{\%} with FPPW= 10−5, and 97.9{\%} with FPPW= 10−4 on the INRIA dataset, which, to our best knowledge, is the best human detection performance on the INRIA dataset. The global-part occlusion handling method is further validated using synthesized occlusion data constructed from the INRIA and Pascal dataset.},
author = {Wang, Xiaoyu and Han, Tony X. and Yan, Shuicheng},
booktitle = {2009 IEEE 12th International Conference on Computer Vision},
doi = {10.1109/ICCV.2009.5459207},
file = {:media/gabi/Dados 2/pc-lab/Dropbox/MESTRADO/Referencias/05459207.pdf:pdf},
isbn = {978-1-4244-4420-5},
issn = {1550-5499},
keywords = {Detectors,Histograms,Humans,Image segmentation,Object detection,Pixel,Support vector machine classification,Support vector machines,Testing,Training data},
month = {sep},
pages = {32--39},
publisher = {IEEE},
shorttitle = {Computer Vision, 2009 IEEE 12th International Conf},
title = {{An HOG-LBP human detector with partial occlusion handling}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5459207},
year = {2009}
}
@article{Wang2009,
abstract = {By combining Histograms of Oriented Gradients (HOG) and Local Binary Pattern (LBP) as the feature set, we propose a novel human detection approach capable of handling partial occlusion. Two kinds of detectors, i.e., global detector for whole scanning windows and part detectors for local regions, are learned from the training data using linear SVM. For each ambiguous scanning window, we construct an occlusion likelihood map by using the response of each block of the HOG feature to the global detector. The occlusion likelihood map is then segmented by Mean-shift approach. The segmented portion of the window with a majority of negative response is inferred as an occluded region. If partial occlusion is indicated with high likelihood in a certain scanning window, part detectors are applied on the unoccluded regions to achieve the final classification on the current scanning window. With the help of the augmented HOG-LBP feature and the global-part occlusion handling method, we achieve a detection rate of 91.3{\%} with FPPW= 10{\&}{\#}x2212;6, 94.7{\%} with FPPW= 10{\&}{\#}x2212;5, and 97.9{\%} with FPPW= 10{\&}{\#}x2212;4 on the INRIA dataset, which, to our best knowledge, is the best human detection performance on the INRIA dataset. The global-part occlusion handling method is further validated using synthesized occlusion data constructed from the INRIA and Pascal dataset.},
author = {Wang, Xiaoyu and Han, Tony X. and Yan, Shuicheng},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Han, Yan - 2009 - An HOG-LBP human detector with partial occlusion handling.pdf:pdf},
journal = {IEEE 12th International Conference on Computer Vision},
publisher = {IEEE},
title = {{An HOG-LBP human detector with partial occlusion handling}},
year = {2009}
}
@article{Wang2004,
abstract = {Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a Structural Similarity Index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000.},
author = {Wang, Zhou and Bovik, Alan Conrad and Sheikh, Hamid Rahim and Simoncelli, Eero P},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2004 - Image quality assessment from error visibility to structural similarity.pdf:pdf},
issn = {1057-7149},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
keywords = {Algorithms,Automated,Computer-Assisted,Computer-Assisted: methods,Computer-Assisted: standards,Data Interpretation,Hypermedia,Image Enhancement,Image Enhancement: methods,Image Enhancement: standards,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Information Storage and Retrieval: standards,Models,Pattern Recognition,Quality Control,Reproducibility of Results,Sensitivity and Specificity,Signal Processing,Statistical,Subtraction Technique},
month = {apr},
number = {4},
pages = {600--612},
pmid = {15376593},
title = {{Image quality assessment: from error visibility to structural similarity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15376593},
volume = {13},
year = {2004}
}
@article{Will1971,
abstract = {The problem of machine vision as evidenced in the various robot projects in existence is attacked by analogy with the supposed nature of human visual processing in that edges are enhanced, texture is examined and various heuristic approaches are studied. This paper describes a non-anthropomorphically based method of decomposing a scene subjected to a special form of illumination into elementary planar areas. The method consists in coding the various planar areas as the modulation on a spatial frequency carrier grid so that the extraction of the planar areas becomes a matter of linear frequency domain filtering. The paper also addresses the application of grid coding to other problems in recording and extracting information from 3-D images.},
author = {Will, P.M. M and Pennington, K.S. S},
doi = {10.1016/0004-3702(71)90015-4},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Will, Pennington - 1971 - Grid coding A preprocessing technique for robot and machine vision.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {preprocessing},
mendeley-tags = {preprocessing},
month = {dec},
number = {3-4},
pages = {319--329},
title = {{Grid coding: A preprocessing technique for robot and machine vision}},
url = {http://www.sciencedirect.com/science/article/pii/0004370271900154},
volume = {2},
year = {1971}
}
@article{Wold1987,
abstract = {Principal component analysis of a data matrix extracts the dominant patterns in the matrix in terms of a complementary set of score and loading plots. It is the responsibility of the data analyst to formulate the scientific issue at hand in terms of PC projections, PLS regressions, etc. Ask yourself, or the investigator, why the data matrix was collected, and for what purpose the experiments and measurements were made. Specify before the analysis what kinds of patterns you would expect and what you would find exciting. The results of the analysis depend on the scaling of the matrix, which therefore must be specified. Variance scaling, where each variable is scaled to unit variance, can be recommended for general use, provided that almost constant variables are left unscaled. Combining different types of variables warrants blockscaling. In the initial analysis, look for outliers and strong groupings in the plots, indicating that the data matrix perhaps should be “polished” or whether disjoint modeling is the proper course. For plotting purposes, two or three principal components are usually sufficient, but for modeling purposes the number of significant components should be properly determined, e.g. by cross-validation. Use the resulting principal components to guide your continued investigation or chemical experimentation, not as an end in itself.},
author = {Wold, Svante and Esbensen, Kim and Geladi, Paul},
doi = {10.1016/0169-7439(87)80084-9},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wold, Esbensen, Geladi - 1987 - Principal component analysis.pdf:pdf},
issn = {01697439},
journal = {Chemometrics and Intelligent Laboratory Systems},
month = {aug},
number = {1-3},
pages = {37--52},
title = {{Principal component analysis}},
url = {http://www.sciencedirect.com/science/article/pii/0169743987800849},
volume = {2},
year = {1987}
}
@article{Xie2016,
abstract = {The convolutional neural network (ConvNet or CNN) is a powerful discriminative learning machine. In this paper, we show that a generative random field model that we call generative ConvNet can be derived from the discriminative ConvNet. The probability distribution of the generative ConvNet model is in the form of exponential tilting of a reference distribution. Assuming re-lu non-linearity and Gaussian white noise reference distribution, we show that the generative ConvNet model contains a representational structure with multiple layers of binary activation variables. The model is non-Gaussian, or more precisely, piecewise Gaussian, where each piece is determined by an instantiation of the binary activation variables that reconstruct the mean of the Gaussian piece. The Langevin dynamics for synthesis is driven by the reconstruction error, and the corresponding gradient descent dynamics converges to a local energy minimum that is auto-encoding. As for learning, we show that the contrastive divergence learning tends to reconstruct the observed images. Finally, we show that the maximum likelihood learning algorithm can generate realistic natural images.},
archivePrefix = {arXiv},
arxivId = {1602.03264},
author = {Xie, Jianwen and Lu, Yang and Zhu, Song-Chun and Wu, Ying Nian},
eprint = {1602.03264},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie et al. - 2016 - A Theory of Generative ConvNet.pdf:pdf},
month = {feb},
title = {{A Theory of Generative ConvNet}},
url = {http://arxiv.org/abs/1602.03264},
year = {2016}
}
@article{Xu2016,
abstract = {Though most of the faces are axis-symmetrical objects, few real-world face images are axis-symmetrical images. In the past years, there are many studies on face recognition, but only little attention is paid to this issue and few studies to explore and exploit the axis-symmetrical property of faces for face recognition are conducted. In this paper, we take the axis-symmetrical nature of faces into consideration and design a framework to produce approximately axis-symmetrical virtual dictionary for enhancing the accuracy of face recognition. It is noteworthy that the novel algorithm to produce axis-symmetrically virtual face images is mathematically very tractable and quite easy to implement. Extensive experimental results demonstrate the superiority in face recognition of the virtual face images obtained using our method to the original face images. Moreover, experimental results on different databases also show that the proposed method can achieve satisfactory classification accuracy in comparison with state-of-the-art image preprocessing algorithms. The MATLAB code of the proposed method can be available at http://www.yongxu.org/lunwen.html.},
author = {Xu, Yong and Zhang, Zheng and Lu, Guangming and Yang, Jian},
doi = {10.1016/j.patcog.2015.12.017},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2016 - Approximately symmetrical face images for image preprocessing in face recognition and sparse representation based cla.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Approximately symmetrical face,Face image preprocessing,Face recognition,Sparse representation,Virtual sample},
month = {jan},
title = {{Approximately symmetrical face images for image preprocessing in face recognition and sparse representation based classification}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316000121},
year = {2016}
}
@inproceedings{Yang2013,
abstract = {Most existing bottom-up methods measure the foreground saliency of a pixel or region based on its contrast within a local context or the entire image, whereas a few methods focus on segmenting out background regions and thereby salient objects. Instead of considering the contrast between the salient objects and their surrounding regions, we consider both foreground and background cues in a different way. We rank the similarity of the image elements (pixels or regions) with foreground cues or background cues via graph-based manifold ranking. The saliency of the image elements is defined based on their relevances to the given seeds or queries. We represent the image as a close-loop graph with super pixels as nodes. These nodes are ranked based on the similarity to background and foreground queries, based on affinity matrices. Saliency detection is carried out in a two-stage scheme to extract background regions and foreground salient objects efficiently. Experimental results on two large benchmark databases demonstrate the proposed method performs well when against the state-of-the-art methods in terms of accuracy and speed. We also create a more difficult benchmark database containing 5,172 images to test the proposed saliency model and make this database publicly available with this paper for further studies in the saliency field.},
author = {Yang, Chuan and Zhang, Lihe and Lu, Huchuan and Ruan, Xiang and Yang, Ming-Hsuan},
booktitle = {2013 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2013.407},
isbn = {978-0-7695-4989-7},
issn = {1063-6919},
keywords = {Computational modeling,Image color analysis,Image segmentation,Labeling,Manifolds,Object detection,Vectors,affinity matrices,background cues,background querying,background region extraction,background region segmentation,bottom-up methods,close-loop graph,feature extraction,foreground cues,foreground querying,foreground saliency,foreground salient object extraction,graph theory,graph-based manifold ranking,image representation,image segmentation,matrix algebra,saliency detection,saliency model},
month = {jun},
pages = {3166--3173},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Saliency Detection via Graph-Based Manifold Ranking}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6619251},
year = {2013}
}
@article{Yang2010,
abstract = {This paper presents a new approach to single-image super-resolution, based on sparse signal representation. Research on image statistics suggests that image patches can be well-represented as a sparse linear combination of elements from an appropriately chosen over-complete dictionary. Inspired by this observation, we seek a sparse representation for each patch of the low-resolution input, and then use the coefficients of this representation to generate the high-resolution output. Theoretical results from compressed sensing suggest that under mild conditions, the sparse representation can be correctly recovered from the downsampled signals. By jointly training two dictionaries for the low- and high-resolution image patches, we can enforce the similarity of sparse representations between the low resolution and high resolution image patch pair with respect to their own dictionaries. Therefore, the sparse representation of a low resolution image patch can be applied with the high resolution image patch dictionary to generate a high resolution image patch. The learned dictionary pair is a more compact representation of the patch pairs, compared to previous approaches, which simply sample a large amount of image patch pairs, reducing the computational cost substantially. The effectiveness of such a sparsity prior is demonstrated for both general image super-resolution and the special case of face hallucination. In both cases, our algorithm generates high-resolution images that are competitive or even superior in quality to images produced by other similar SR methods. In addition, the local sparse modeling of our approach is naturally robust to noise, and therefore the proposed algorithm can handle super-resolution with noisy inputs in a more unified framework.},
author = {Yang, Jianchao and Wright, John and Huang, Thomas S and Ma, Yi},
doi = {10.1109/TIP.2010.2050625},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2010 - Image super-resolution via sparse representation.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
month = {nov},
number = {11},
pages = {2861--2873},
pmid = {20483687},
title = {{Image super-resolution via sparse representation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20483687},
volume = {19},
year = {2010}
}
@article{Yong2013,
author = {Yong, Yang and Chixi, Wang and Bencheng, Yu and Zhi-Hao, Yin},
doi = {10.1109/ICCIS.2013.288},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yong et al. - 2013 - Research on the Method of Image Preprocessing in License Plate Location.pdf:pdf},
isbn = {978-0-7695-5004-6},
journal = {2013 International Conference on Computational and Information Sciences},
keywords = {image processing technology,key words,median value filter,preprocess},
month = {jun},
pages = {1084--1087},
publisher = {Ieee},
title = {{Research on the Method of Image Preprocessing in License Plate Location}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6643205},
year = {2013}
}
@article{Yosinski2014,
author = {Yosinski, J and Clune, J},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yosinski, Clune - 2014 - How transferable are features in deep neural networks.pdf:pdf},
journal = {Advances in Neural {\ldots}},
pages = {1--9},
title = {{How transferable are features in deep neural networks?}},
url = {http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks},
year = {2014}
}
@article{Yu2011,
abstract = {Recently, researchers are focusing more on the study of support vector machine (SVM) due to its useful applications in a number of areas, such as pattern recognition, multimedia, image processing and bioinformatics. One of the main research issues is how to improve the efficiency of the original SVM model, while preventing any deterioration of the classification performance of the model. In this paper, we propose a modified SVM based on the properties of support vectors and a pruning strategy to preserve support vectors, while eliminating redundant training vectors at the same time. The experiments on real images show that (1) our proposed approach can reduce the number of input training vectors, while preserving the support vectors, which leads to a significant reduction in the computational cost while attaining similar levels of accuracy. (2)The approach also works well when applied to image segmentation.},
author = {Yu, Zhiwen and Wong, Hau-San and Wen, Guihua},
doi = {10.1016/j.imavis.2010.08.003},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Wong, Wen - 2011 - A modified support vector machine and its application to image segmentation.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Classification,Image segmentation,Support vector machine,segmentation,svm},
mendeley-tags = {segmentation,svm},
month = {jan},
number = {1},
pages = {29--40},
title = {{A modified support vector machine and its application to image segmentation}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885610001113},
volume = {29},
year = {2011}
}
@article{Yuille2012,
abstract = {I argue that computer vision needs a core of techniques and foundational research to enable it to build on its current successes and achieve its enormous potential. “How do I know what papers to read in computer vision? There are so many. And they are so different.” Graduate Student. Xi'An. China. November, 2011.},
author = {Yuille, A.L. L},
doi = {10.1016/j.imavis.2011.12.013},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuille - 2012 - Computer vision needs a core and foundations.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Core,Foundations,computer vision},
mendeley-tags = {computer vision},
month = {aug},
number = {8},
pages = {469--471},
title = {{Computer vision needs a core and foundations}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885612000704},
volume = {30},
year = {2012}
}
@article{Zeiler2013,
abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky $\backslash$etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
archivePrefix = {arXiv},
arxivId = {1311.2901},
author = {Zeiler, Matthew D and Fergus, Rob},
edition = {2014},
eprint = {1311.2901},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeiler, Fergus - 2014 - Visualizing and Understanding Convolutional Networks.pdf:pdf},
journal = {Computer Vision--ECCV 2014},
month = {nov},
pages = {818--833},
publisher = {Springer},
title = {{Visualizing and Understanding Convolutional Networks}},
url = {http://arxiv.org/abs/1311.2901},
year = {2013}
}
@inproceedings{Zeiler2010,
abstract = {Building robust low and mid-level image representations, beyond edge primitives, is a long-standing goal in vision. Many existing feature detectors spatially pool edge information which destroys cues such as edge intersections, parallelism and symmetry. We present a learning framework where features that capture these mid-level cues spontaneously emerge from image data. Our approach is based on the convolutional decomposition of images under a spar-sity constraint and is totally unsupervised. By building a hierarchy of such decompositions we can learn rich feature sets that are a robust image representation for both the analysis and synthesis of images.},
author = {Zeiler, Matthew D. and Krishnan, Dilip and Taylor, Graham W. and Fergus, Rob},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5539957},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeiler et al. - 2010 - Deconvolutional networks.pdf:pdf},
isbn = {978-1-4244-6984-0},
issn = {1063-6919},
keywords = {Computer architecture,Convolution,Decoding,Feature extraction,Filters,Image edge detection,Image representation,Image restoration,Object recognition,Robustness,deconvolution,deconvolutional networks,edge primitives,feature detectors,image representation,image representations,images synthesis,pool edge information},
month = {jun},
pages = {2528--2535},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Deconvolutional networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5539957},
year = {2010}
}
@inproceedings{Zeiler2011,
abstract = {We present a hierarchical model that learns image decompositions via alternating layers of convolutional sparse coding and max pooling. When trained on natural images, the layers of our model capture image information in a variety of forms: low-level edges, mid-level edge junctions, high-level object parts and complete objects. To build our model we rely on a novel inference scheme that ensures each layer reconstructs the input, rather than just the output of the layer directly beneath, as is common with existing hierarchical approaches. This makes it possible to learn multiple layers of representation and we show models with 4 layers, trained on images from the Caltech-101 and 256 datasets. When combined with a standard classifier, features extracted from these models outperform SIFT, as well as representations from other feature learning methods.},
author = {Zeiler, Matthew D. and Taylor, Graham W. and Fergus, Rob},
booktitle = {International Conference on Computer Vision},
doi = {10.1109/ICCV.2011.6126474},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeiler, Taylor, Fergus - 2011 - Adaptive deconvolutional networks for mid and high level feature learning.pdf:pdf},
isbn = {978-1-4577-1102-2},
issn = {1550-5499},
keywords = {Adaptation models,Caltech-101 datasets,Caltech-256 datasets,Computational modeling,Deconvolution,Image reconstruction,Mathematical model,Switches,Training,adaptive deconvolutional networks,classifier,complete objects,convolutional sparse coding,deconvolution,feature extraction,hierarchical model,high level feature learning,high-level object parts,image classification,image decompositions,image representation,inference mechanisms,inference scheme,learning (artificial intelligence),low-level edges,max pooling,mid level feature learning,mid-level edge junctions,natural images},
month = {nov},
pages = {2018--2025},
publisher = {IEEE},
shorttitle = {Computer Vision (ICCV), 2011 IEEE International Co},
title = {{Adaptive deconvolutional networks for mid and high level feature learning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6126474},
year = {2011}
}
@article{Zhang2012,
author = {Zhang, David and Zuo, Wangmeng and Yue, Feng},
doi = {10.1145/2071389.2071391},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Zuo, Yue - 2012 - A Comparative Study of Palmprint Recognition Algorithms.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
month = {jan},
number = {1},
pages = {1--37},
title = {{A Comparative Study of Palmprint Recognition Algorithms}},
url = {http://dl.acm.org/citation.cfm?doid=2071389.2071391},
volume = {44},
year = {2012}
}
@article{Zhang1993,
author = {Zhang, HongJiang and Kankanhalli, Atreyi and Smoliar, Stephen W.},
doi = {10.1007/BF01210504},
issn = {0942-4962},
journal = {Multimedia Systems},
month = {jan},
number = {1},
pages = {10--28},
title = {{Automatic partitioning of full-motion video}},
url = {http://link.springer.com/10.1007/BF01210504},
volume = {1},
year = {1993}
}
@article{Zhang2014,
abstract = {Traditional patch-based sparse representation modeling of natural images usually suffer from two problems. First, it has to solve a large-scale optimization problem with high computational complexity in dictionary learning. Second, each patch is considered independently in dictionary learning and sparse coding, which ignores the relationship among patches, resulting in inaccurate sparse coding coefficients. In this paper, instead of using patch as the basic unit of sparse representation, we exploit the concept of group as the basic unit of sparse representation, which is composed of nonlocal patches with similar structures, and establish a novel sparse representation modeling of natural images, called group-based sparse representation (GSR). The proposed GSR is able to sparsely represent natural images in the domain of group, which enforces the intrinsic local sparsity and nonlocal self-similarity of images simultaneously in a unified framework. In addition, an effective self-adaptive dictionary learning method for each group with low complexity is designed, rather than dictionary learning from natural images. To make GSR tractable and robust, a split Bregman-based technique is developed to solve the proposed GSR-driven ℓ0 minimization problem for image restoration efficiently. Extensive experiments on image inpainting, image deblurring and image compressive sensing recovery manifest that the proposed GSR modeling outperforms many current state-of-the-art schemes in both peak signal-to-noise ratio and visual perception.},
author = {Zhang, Jian and Zhao, Debin and Gao, Wen},
doi = {10.1109/TIP.2014.2323127},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Zhao, Gao - 2014 - Group-based sparse representation for image restoration.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing},
month = {aug},
number = {8},
pages = {3336--51},
pmid = {24835225},
title = {{Group-based sparse representation for image restoration.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24835225},
volume = {23},
year = {2014}
}
@article{Zhang2015,
author = {Zhang, L and Fried, D and Fave, X and Mackin, D and Yang, J and Court, L},
doi = {10.1118/1.4924347},
issn = {0094-2405},
journal = {Medical Physics},
month = {jun},
number = {6},
pages = {3326--3327},
title = {{SU-E-J-261: The Importance of Appropriate Image Preprocessing to Augment the Information of Radiomics Image Features}},
url = {http://scitation.aip.org/content/aapm/journal/medphys/42/6/10.1118/1.4924347},
volume = {42},
year = {2015}
}
@article{Zhou2006,
author = {Zhou, Zhi-Hua and Liu, Xu-Ying},
doi = {10.1109/TKDE.2006.17},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou, Liu - 2006 - Training cost-sensitive neural networks with methods addressing the class imbalance problem.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Costs,Data mining,Decision trees,Index Terms- Machine learning,Learning systems,Machine learning,Neural networks,Sampling methods,Testing,Training data,Voting,class imbalance learning,cost-sensitive learning,cost-sensitive neural network training,data mining,ensemble learning,ensemble learning.,learning (artificial intelligence),machine learning,neural nets,neural networks,oversampling technique,sampling,sampling methods,threshold-moving,undersampling technique},
language = {English},
month = {jan},
number = {1},
pages = {63--77},
publisher = {IEEE},
title = {{Training cost-sensitive neural networks with methods addressing the class imbalance problem}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1549828},
volume = {18},
year = {2006}
}
@article{Zhuo2014,
author = {Zhuo, Li and Cheng, Bo and Zhang, Jing},
doi = {10.1016/j.neucom.2014.03.014},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhuo, Cheng, Zhang - 2014 - A comparative study of dimensionality reduction methods for large-scale image retrieval.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Dimensionality reduction,HSV histogram,Large-scale image retrieval,OPTIMIZED SIFT,Vocabulary tree,dimensionality reduction,large-scale image retrieval},
month = {oct},
pages = {202--210},
publisher = {Elsevier},
title = {{A comparative study of dimensionality reduction methods for large-scale image retrieval}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231214004238},
volume = {141},
year = {2014}
}
@article{Zliobaite2014,
author = {Zliobaite, Indre and Gabrys, Bogdan},
doi = {10.1109/TKDE.2012.147},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zliobaite, Gabrys - 2014 - Adaptive Preprocessing for Streaming Data.pdf:pdf},
isbn = {2011110726},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = {feb},
number = {2},
pages = {309--321},
title = {{Adaptive Preprocessing for Streaming Data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6247432},
volume = {26},
year = {2014}
}
@article{Zuo2014,
abstract = {Natural image statistics plays an important role in image denoising, and various natural image priors, including gradient-based, sparse representation-based, and nonlocal self-similarity-based ones, have been widely studied and exploited for noise removal. In spite of the great success of many denoising algorithms, they tend to smooth the fine scale image textures when removing noise, degrading the image visual quality. To address this problem, in this paper, we propose a texture enhanced image denoising method by enforcing the gradient histogram of the denoised image to be close to a reference gradient histogram of the original image. Given the reference gradient histogram, a novel gradient histogram preservation (GHP) algorithm is developed to enhance the texture structures while removing noise. Two region-based variants of GHP are proposed for the denoising of images consisting of regions with different textures. An algorithm is also developed to effectively estimate the reference gradient histogram from the noisy observation of the unknown image. Our experimental results demonstrate that the proposed GHP algorithm can well preserve the texture appearance in the denoised images, making them look more natural.},
author = {Zuo, Wangmeng and Zhang, Lei and Song, Chunwei and Zhang, David and Gao, Huijun},
doi = {10.1109/TIP.2014.2316423},
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zuo et al. - 2014 - Gradient histogram estimation and preservation for texture enhanced image denoising.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing},
month = {jun},
number = {6},
pages = {2459--72},
pmid = {24733013},
title = {{Gradient histogram estimation and preservation for texture enhanced image denoising.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24733013},
volume = {23},
year = {2014}
}
@book{,
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - www.allitebooks.com.pdf:pdf},
isbn = {9781783289004},
title = {www.allitebooks.com}
}
@misc{,
title = {{Saliency Detection via Graph-Based Manifold Ranking}},
url = {http://faculty.ucmerced.edu/mhyang/papers/cvpr13{\_}saliency.pdf},
urldate = {2015-06-11}
}
@article{,
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2015 - Handling imbalanced datasets A review.pdf:pdf},
number = {November},
title = {{Handling imbalanced datasets: A review}},
year = {2015}
}
@book{,
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - www.allitebooks.com(2).pdf:pdf},
isbn = {9781784396053},
title = {www.allitebooks.com}
}
@book{,
file = {:home/gabi/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - www.allitebooks.com(3).pdf:pdf},
isbn = {9781783555130},
title = {www.allitebooks.com}
}
@misc{,
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {http://www.cs.toronto.edu/{~}fritz/absps/imagenet.pdf},
urldate = {2015-06-10}
}
@incollection{Knuth1997,
author = {Knuth, Donald E.},
booktitle = {Art of Computer Programming, Volume 2: Seminumerical Algorithms},
chapter = {3.4.7},
edition = {3},
title = {{No Title}},
year = {1997}
}
@incollection{Marsland2015,
abstract = {A Proven, Hands-On Approach for Students without a Strong Statistical Foundation Since the best-selling first edition was published, there have been several prominent developments in the field of machine learning, including the increasing work on the statistical interpretations of machine learning algorithms. Unfortunately, computer science students without a strong statistical background often find it hard to get started in this area. Remedying this deficiency, Machine Learning: An Algorithmic Perspective, Second Edition helps students understand the algorithms of machine learning. It puts them on a path toward mastering the relevant mathematics and statistics as well as the necessary programming and experimentation. New to the Second Edition Two new chapters on deep belief networks and Gaussian processes Reorganization of the chapters to make a more natural flow of content Revision of the support vector machine material, including a simple implementation for experiments New material on random forests, the perceptron convergence theorem, accuracy methods, and conjugate gradient optimization for the multi-layer perceptron Additional discussions of the Kalman and particle filters Improved code, including better use of naming conventions in Python Suitable for both an introductory one-semester course and more advanced courses, the text strongly encourages students to practice with the code. Each chapter includes detailed examples along with further reading and problems. All of the code used to create the examples is available on the author’s website.},
author = {Marsland, Stephen},
booktitle = {Machine Learning: An Algorithmic Perspective},
chapter = {Support Ve},
isbn = {1498759785},
pages = {457},
publisher = {CRC Press},
title = {{Machine Learning: An Algorithmic Perspective}},
url = {https://books.google.com/books?hl=en{\&}lr={\&}id=y{\_}oYCwAAQBAJ{\&}pgis=1},
year = {2015}
}
@inproceedings{ccv,
address = {New York, New York, USA},
author = {Pass, Greg and Zabih, Ramin and Miller, Justin},
booktitle = {Proceedings of the fourth ACM international conference on Multimedia},
doi = {10.1145/244130.244148},
isbn = {0897918711},
pages = {65--73},
publisher = {ACM Press},
title = {{Comparing images using color coherence vectors}},
url = {http://portal.acm.org/citation.cfm?doid=244130.244148},
year = {1996}
}
