@unpublished{Bengio-et-al-2014-Book,
   title={Deep Learning},
   author={Yoshua Bengio and Ian J. Goodfellow and Aaron Courville},
   note={Book in preparation for MIT Press},
   url={http://www.iro.umontreal.ca/~bengioy/dlbook},
   year={2014}
}

@unpublished{Mahendran2014,
  author    = {Aravindh Mahendran and Andrea Vedaldi},
  title     = {Understanding Deep Image Representations by Inverting Them},
  note      = {arXiv preprint arXiv:1412.0035},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.0035}
}

@unpublished{Ponti2014,
author = {Ponti, Moacir and Nazar\'{e}, Tiago and Thum\'{e}, Gabriela},
note = {Submitted to Neurocomputing},
title = {{Image quantization as a dimensionality reduction procedure in color and texture feature extraction}},
year = {2014}
}



@article{Ahonen2004,
author = {Ahonen, Timo and Hadid, Abdenour and Pietik\"{a}inen, M},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Ahonen, Hadid, Pietik\"{a}inen - 2004 - Face recognition with local binary patterns.pdf:pdf},
journal = {Computer vision-eccv 2004},
pages = {469--481},
title = {{Face recognition with local binary patterns}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-24670-1\_36},
year = {2004}
}
@article{6,
abstract = {This paper presents a novel and efficient facial image representation based on local binary pattern (LBP) texture features. The face image is divided into several regions from which the LBP feature distributions are extracted and concatenated into an enhanced feature vector to be used as a face descriptor. The performance of the proposed method is assessed in the face recognition problem under different challenges. Other applications and several extensions are also discussed.},
author = {Ahonen, Timo and Hadid, Abdenour and Pietik\"{a}inen, Matti},
doi = {10.1109/TPAMI.2006.244},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Ahonen, Hadid, Pietik\"{a}inen - 2006 - Face description with local binary patterns application to face recognition(2).pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Biometry,Biometry: methods,Computer-Assisted,Computer-Assisted: methods,Face,Face: anatomy \& histology,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Numerical Analysis,Pattern Recognition,Reproducibility of Results,Sensitivity and Specificity,Signal Processing},
month = dec,
number = {12},
pages = {2037--2041},
pmid = {17108377},
title = {{Face description with local binary patterns: application to face recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17108377},
volume = {28},
year = {2006}
}
@article{Aono1984,
abstract = {The authors present botanical trees as models of biological objects, first by defining their developmental rules in a discrete grammatical form, then by defining them in continuous geometric forms. Having analyzed these models from several standpoints, they have developed an interactive synthetic tree manipulation system called the A-system. The A-system incorporates such constructs as leaves, shadows, and shades and can perform three-dimensional transformations of a tree. One of its applications is to assist with landscaping, which includes gardening and the design of street plants.},
author = {Aono, Masaki and Kunii, Tosiyasu},
doi = {10.1109/MCG.1984.276141},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Aono, Kunii - 1984 - Botanical Tree Image Generation(2).pdf:pdf},
issn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
keywords = {A-system,Algae,Biological system modeling,Computer graphics,Formal languages,Fractals,Image generation,Shape,Solid modeling,Testing,Tree graphs,biological objects,botanical trees,computer graphics,continuous geometric forms,developmental rules,discrete grammatical form,gardening,image generation,interactive synthetic tree manipulation system,landscaping,leaves,natural sciences computing,shades,shadows,street plants,three-dimensional transformations,town and country planning},
mendeley-tags = {image generation},
number = {5},
pages = {10--34},
shorttitle = {Computer Graphics and Applications, IEEE},
title = {{Botanical Tree Image Generation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4055766},
volume = {4},
year = {1984}
}
@article{Chornoboy1994,
author = {ApRil, O},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/ApRil - 1994 - Automated storm tracking for terminal air traffic control.pdf:pdf},
journal = {Lincoln Laboratory Journal},
number = {2},
pages = {427--448},
title = {{Automated storm tracking for terminal air traffic control}},
url = {http://www.ll.mit.edu/mission/aviation/publications/publication-files/journal-articles/Chornoboy\_1994\_JA-7198.pdf},
volume = {7},
year = {1994}
}
@article{Arici2009,
author = {Arici, Tarik and Dikbas, Salih and Altunbasak, Yucel},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Arici, Dikbas, Altunbasak - 2009 - A histogram modification framework and its application for image contrast enhancement.pdf:pdf},
journal = {Image Processing, IEEE \ldots},
number = {9},
pages = {1921--1935},
title = {{A histogram modification framework and its application for image contrast enhancement}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4895264},
volume = {18},
year = {2009}
}
@article{AurelienMayoueQuentinBarthelemySebastienOnis2012,
author = {{Aur\'{e}lien Mayoue, Quentin Barth\'{e}lemy, S\'{e}bastien Onis}, Anthony Larue.},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Aur\'{e}lien Mayoue, Quentin Barth\'{e}lemy, S\'{e}bastien Onis - 2012 - Preprocessing for classication of sparse data application to trajecto(2).pdf:pdf},
journal = {IEEE Statistical Signal Processing Workshop},
pages = {37--40},
title = {{Preprocessing for classication of sparse data: application to trajectory recognition.}},
url = {https://hal.archives-ouvertes.fr/hal-00730423/document},
year = {2012}
}
@article{Barua2014,
abstract = {Imbalanced learning problems contain an unequal distribution of data samples among different classes and pose a challenge to any classifier as it becomes hard to learn the minority class samples. Synthetic oversampling methods address this problem by generating the synthetic minority class samples to balance the distribution between the samples of the majority and minority classes. This paper identifies that most of the existing oversampling methods may generate the wrong synthetic minority samples in some scenarios and make learning tasks harder. To this end, a new method, called Majority Weighted Minority Oversampling TEchnique (MWMOTE), is presented for efficiently handling imbalanced learning problems. MWMOTE first identifies the hard-to-learn informative minority class samples and assigns them weights according to their euclidean distance from the nearest majority class samples. It then generates the synthetic samples from the weighted informative minority class samples using a clustering approach. This is done in such a way that all the generated samples lie inside some minority class cluster. MWMOTE has been evaluated extensively on four artificial and 20 real-world data sets. The simulation results show that our method is better than or comparable with some other existing methods in terms of various assessment metrics, such as geometric mean (G-mean) and area under the receiver operating curve (ROC), usually known as area under curve (AUC).},
author = {Barua, Sukarna and Islam, Md. Monirul and Yao, Xin and Murase, Kazuyuki},
doi = {10.1109/TKDE.2012.232},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Barua et al. - 2014 - MWMOTE--Majority Weighted Minority Oversampling Technique for Imbalanced Data Set Learning(2).pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {AUC,Abstracts,Boosting,Complexity theory,Euclidean distance,G-mean,Imbalanced learning,Interpolation,MWMOTE-majority weighted minority oversampling tec,Noise measurement,ROC,Sampling methods,Simulation,area under curve,clustering,clustering approach,geometric mean,hard-to-learn informative minority class samples,imbalanced data set learning,imbalanced learning problems,learning (artificial intelligence),majority class,minority class cluster,oversampling,pattern clustering,receiver operating curve,sampling methods,synthetic minority class samples,synthetic oversampling methods,synthetic sample generation,undersampling,weighted informative minority class samples},
month = feb,
number = {2},
pages = {405--425},
shorttitle = {Knowledge and Data Engineering, IEEE Transactions},
title = {{MWMOTE--Majority Weighted Minority Oversampling Technique for Imbalanced Data Set Learning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6361394},
volume = {26},
year = {2014}
}
@article{Batista2004,
author = {Batista, GE E and Prati, RC C and Monard, MC C},
file = {::},
journal = {ACM Sigkdd Explorations Newsletter},
number = {1},
pages = {20--29},
title = {{A study of the behavior of several methods for balancing machine learning training data}},
url = {http://dl.acm.org/citation.cfm?id=1007735},
volume = {6},
year = {2004}
}
@article{Belhumeur1997,
abstract = {We develop a face recognition algorithm which is insensitive to large variation in lighting direction and facial expression. Taking a pattern classification approach, we consider each pixel in an image as a coordinate in a high-dimensional space. We take advantage of the observation that the images of a particular face, under varying illumination but fixed pose, lie in a 3D linear subspace of the high dimensional image space-if the face is a Lambertian surface without shadowing. However, since faces are not truly Lambertian surfaces and do indeed produce self-shadowing, images will deviate from this linear subspace. Rather than explicitly modeling this deviation, we linearly project the image into a subspace in a manner which discounts those regions of the face with large deviation. Our projection method is based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variation in lighting and facial expressions. The eigenface technique, another method based on linearly projecting the image space to a low dimensional subspace, has similar computational requirements. Yet, extensive experimental results demonstrate that the proposed “Fisherface” method has error rates that are lower than those of the eigenface technique for tests on the Harvard and Yale face databases},
author = {Belhumeur, P.N. N and Hespanha, J.P. P and Kriegman, D.J. J},
doi = {10.1109/34.598228},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Belhumeur, Hespanha, Kriegman - 1997 - Eigenfaces vs. Fisherfaces recognition using class specific linear projection(2).pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {3D linear subspace,Error analysis,Face detection,Face recognition,Fisherfaces,Lambertian surface,Light scattering,Light sources,Lighting,Pattern classification,Pixel,Principal component analysis,Shadow mapping,class specific linear projection,computational requirements,eigenfaces,face recognition,facial expression insensitivity,high-dimensional space,lighting direction insensitivity,linear discriminant,linear projection,low-dimensional subspace,pattern classification},
month = jul,
number = {7},
pages = {711--720},
shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
title = {{Eigenfaces vs. Fisherfaces: recognition using class specific linear projection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=598228},
volume = {19},
year = {1997}
}
@article{bengio2009,
author = {Bengio, Yoshua},
doi = {10.1561/2200000006},
file = {::},
issn = {1935-8237},
journal = {Foundations and Trends in Machine Learning},
month = jan,
number = {1},
pages = {1--127},
publisher = {Now Publishers Inc.},
title = {{Learning Deep Architectures for AI}},
url = {http://dl.acm.org/citation.cfm?id=1658423.1658424},
volume = {2},
year = {2009}
}
@article{Bhattacharyya2011,
author = {Bhattacharyya, Siddhartha},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Bhattacharyya - 2011 - A brief survey of color image preprocessing and segmentation techniques(2).pdf:pdf},
journal = {Journal of Pattern Recognition Research},
keywords = {classical approaches,color image enhancement,color image segmentation,non-classical approaches},
pages = {120--129},
title = {{A brief survey of color image preprocessing and segmentation techniques}},
url = {http://jprr.org/index.php/jprr/article/view/191},
volume = {1},
year = {2011}
}
@article{Bielecki2008,
abstract = {In this paper, the first stage of studies concerning the computer analysis of hand X-ray digital images is described. The images are preprocessed and then skeletization of the fingers is carried out. Then, the interphapangeal and metacarpophalangeal joints are detected and contoured. Joint widths are also measured. The obtained results largely concur with those obtained by other authors—see Beier et al. [Segmentation of medical images combining local, regional, global, and hierarchical distances into a bottom-up region merging scheme, Proc. SPIE 5747 (2005) 546–555], Klooster et al. [Automatic quantification of osteoarthritis in hand radiographs: validation of a new method to measure joint space width, Osteoarthritis and Cartilage 16 (1) (2008) 18–25], Ogiela et al. [Image languages in intelligent radiological palm diagnostics, Pattern Recognition 39 (2006) 2157–2165] and Ogiela and Tadeusiewicz [Picture languages in automatic radiological palm interpretation, Int. J. Appl. Math. Comput. Sci. 15 (2) (2005) 305–312].},
author = {Bielecki, Andrzej and Korkosz, Mariusz and Zieliński, Bartosz},
doi = {10.1016/j.patcog.2008.05.032},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Bielecki, Korkosz, Zieliński - 2008 - Hand radiographs preprocessing, image representation in the finger regions and joint space wid(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Image processing,Joint space width,Medical imaging,Radiology,Rheumatoid arthritis,Thinning,Thresholding,X-ray photo,preprocessing},
mendeley-tags = {preprocessing},
month = dec,
number = {12},
pages = {3786--3798},
title = {{Hand radiographs preprocessing, image representation in the finger regions and joint space width measurements for image interpretation}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320308002094},
volume = {41},
year = {2008}
}
@inproceedings{Borges2013,
abstract = {This paper describes ongoing work on the use of visualization, mining and image analysis techniques to sup- port biologists conducting taxonomic classification of freshwater green microalgae. The classification of such organisms is highly problematic because traditional taxonomy is inconsistent and biologists must carry out complex and meticulous procedures that demand considerable expert knowledge. We are working with biologists to define a visual exploration process characterized by user interaction with visualizations based on similarity trees, that attempt to provide a hierarchical representation of the relationships among green algae families. This requires obtaining representative feature vectors and developing automatic feat ure extractors from green algae images. Preliminary experiments indicate that tree-based visualizations coupled with a visual exploration strategy and an automatic extractor for computing algae morphological features can assist biologists and potentially improve the taxonomic classification process.},
address = {Arequipa, Peru},
author = {Borges, Vinicius and de Oliveira, Maria Cristina and Ferreira, Thais Garcia and Vieira, Armando Augusto},
booktitle = {XXVI SIBGRAPI - Conference on graphics, patterns and images},
file = {::},
keywords = {-visual exploration,classification,feature extraction,green algae,similarity trees},
pages = {4},
title = {{Feature Extraction and Interactive Visualization to Assist Green Algae Taxonomic Classification}},
url = {http://www.ucsp.edu.pe/sibgrapi2013/eproceedings/wip/115151.pdf},
year = {2013}
}
@article{Buades2005,
abstract = {The search for efficient image denoising methods is still a valid challenge at the crossing of functional analysis and statistics. In spite of the sophistication of the recently proposed methods, most algorithms have not yet attained a desirable level of applicability. All show an outstanding performance when the image model corresponds to the algorithm assumptions but fail in general and create artifacts or remove image fine structures. The main focus of this paper is, first, to define a general mathematical and experimental methodology to compare and classify classical image denoising algorithms and, second, to propose a nonlocal means (NL-means) algorithm addressing the preservation of structure in a digital image. The mathematical analysis is based on the analysis of the "method noise," defined as the difference between a digital image and its denoised version. The NL-means algorithm is proven to be asymptotically optimal under a generic statistical image model. The denoising performance of all consid...},
author = {Buades, A. and Coll, B. and Morel, J. M.},
doi = {10.1137/040616024},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Buades, Coll, Morel - 2005 - A Review of Image Denoising Algorithms, with a New One(2).pdf:pdf},
issn = {1540-3459},
journal = {Multiscale Modeling \& Simulation},
keywords = {62H35,PDE smoothing filters,adaptive filters,frequency domain filters,image restoration,nonparametric estimation,preprocessing},
language = {en},
mendeley-tags = {preprocessing},
month = jan,
number = {2},
pages = {490--530},
publisher = {Society for Industrial and Applied Mathematics},
title = {{A Review of Image Denoising Algorithms, with a New One}},
url = {http://epubs.siam.org/doi/abs/10.1137/040616024},
volume = {4},
year = {2005}
}
@article{Burt1981,
abstract = {A highly efficient recursive algorithm is defined for simultaneously convolving an image (or other two-dimensional function) with a set of kernels which differ in width but not in shape. These kernels may closely resemble the Gaussian probability distribution, so that the algorithm generates a set of low-pass or band-pass versions of the image. Image correlation with spot, edge, and bar operators of many sized can be obtained with negligible additional computation},
author = {Burt, Peter J},
doi = {10.1016/0146-664X(81)90092-7},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Burt - 1981 - Fast filter transform for image processing(2).pdf:pdf},
issn = {0146664X},
journal = {Computer Graphics and Image Processing},
month = may,
number = {1},
pages = {20--51},
title = {{Fast filter transform for image processing}},
url = {http://www.sciencedirect.com/science/article/pii/0146664X81900927},
volume = {16},
year = {1981}
}
@article{Castro2011,
abstract = {Supervised Learning with Imbalanced Data Sets: An Overview Traditional learning algorithms induced by complex and highly imbalanced training sets may have difficulty in dis- tinguishing between examples of the groups. The tendency is to create classification models that are biased toward the overrepresented (majority) class, resulting in a low rate of recognition for the minority group. This paper provides a survey of this problem which has attracted the interest of many researchers in recent years. In the scope of two-class classification tasks, concepts related to the nature of the im- balanced class problem and evaluation metrics are presented, including the foundations of the ROC (Receiver Operating Characteristic) analysis; plus a state of the art of the pro- posed solutions. At the end of the paper a brief discussion on how the subject can be extended to multiclass learning is provided.},
author = {Castro, CL L and Braga, AP P},
file = {::},
journal = {Sba Controle \& Automa\c{c}\~{a}o},
keywords = {ROC analysis,cost-sensitive approach.,evaluation metrics,imbalanced data sets,resampling methods,supervised learning},
number = {5},
pages = {441 -- 446},
title = {{Aprendizado supervisionado com conjuntos de dados desbalanceados}},
volume = {22},
year = {2011}
}
@article{Chapelle1999a,
abstract = {Traditional classification approaches generalize poorly on image classification tasks, because of the high dimensionality of the feature space. This paper shows that support vector machines (SVM's) can generalize well on difficult image classification problems where the only features are high dimensional histograms. Heavy-tailed RBF kernels of the form K(x, y) = e(-rho)Sigma(i)/xia-yia/b with a < or = 1 and b < or = 2 are evaluated on the classification of images extracted from the Corel stock photo collection and shown to far outperform traditional polynomial or Gaussian radial basis function (RBF) kernels. Moreover, we observed that a simple remapping of the input x(i)-->x(i)(a) improves the performance of linear SVM's to such an extend that it makes them, for this problem, a valid alternative to RBF kernels.},
author = {Chapelle, O and Haffner, P and Vapnik, V N},
doi = {10.1109/72.788646},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Chapelle, Haffner, Vapnik - 1999 - Support vector machines for histogram-based image classification(2).pdf:pdf},
issn = {1045-9227},
journal = {IEEE transactions on neural networks},
keywords = {Classification tree analysis,Corel stock photo collection,Histograms,Image classification,Image databases,Image recognition,Kernel,Polynomials,Support vector machine classification,Support vector machines,Web pages,classification,corel,feature space dimensionality,heavy-tailed RBF kernels,high-dimensional histograms,histogram,histogram-based image classification,image classification,learning (artificial intelligence),linear SVM,radial basis function networks,remapping,support vector machines,svm},
mendeley-tags = {classification,corel,histogram,svm},
month = jan,
number = {5},
pages = {1055--64},
pmid = {18252608},
shorttitle = {Neural Networks, IEEE Transactions on},
title = {{Support vector machines for histogram-based image classification.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18252608},
volume = {10},
year = {1999}
}
@article{Chatfield2014,
abstract = {The latest generation of Convolutional Neural Networks (CNN) have achieved impressive results in challenging benchmarks on image recognition and object detection, significantly raising the interest of the community in these methods. Nevertheless, it is still unclear how different CNN methods compare with each other and with previous state-of-the-art shallow representations such as the Bag-of-Visual-Words and the Improved Fisher Vector. This paper conducts a rigorous evaluation of these new techniques, exploring different deep architectures and comparing them on a common ground, identifying and disclosing important implementation details. We identify several useful properties of CNN-based representations, including the fact that the dimensionality of the CNN output layer can be reduced significantly without having an adverse effect on performance. We also identify aspects of deep and shallow methods that can be successfully shared. In particular, we show that the data augmentation techniques commonly applied to CNN-based methods can also be applied to shallow methods, and result in an analogous performance boost. Source code and models to reproduce the experiments in the paper is made publicly available.},
archivePrefix = {arXiv},
arxivId = {1405.3531},
author = {Chatfield, Ken and Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
eprint = {1405.3531},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Chatfield et al. - 2014 - Return of the Devil in the Details Delving Deep into Convolutional Nets(2).pdf:pdf},
journal = {British Machine Vision Conference},
month = may,
title = {{Return of the Devil in the Details: Delving Deep into Convolutional Nets}},
url = {http://arxiv.org/abs/1405.3531},
year = {2014}
}
@article{Chawla2004,
author = {Chawla, Nitesh V. and Japkowicz, Nathalie and Kotcz, Aleksander},
doi = {10.1145/1007730.1007733},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Chawla, Japkowicz, Kotcz - 2004 - Editorial special issue on learning from imbalanced data sets(2).pdf:pdf},
issn = {19310145},
journal = {ACM SIGKDD Explorations Newsletter},
month = jun,
number = {1},
pages = {1},
publisher = {ACM},
title = {{Editorial: special issue on learning from imbalanced data sets}},
url = {http://dl.acm.org/citation.cfm?id=1007730.1007733},
volume = {6},
year = {2004}
}
@article{Chawla,
author = {Chawla, NV V},
file = {::},
journal = {Data mining and knowledge discovery handbook},
pages = {853--867},
title = {{Data mining for imbalanced datasets: An overview}},
url = {http://link.springer.com/chapter/10.1007/0-387-25465-X\_40},
year = {2005}
}
@article{Chawla2002,
author = {Chawla, NV V and Hall, LO O and Bowyer, KW W},
file = {::},
journal = {Journal of Artificial Intelligence Research},
pages = {321--357},
title = {{SMOTE: Synthetic Minority Over-sampling Technique}},
url = {http://link.springer.com/chapter/10.1007/3-540-45428-4\_5 http://arxiv.org/abs/1106.1813},
volume = {16},
year = {2002}
}
@article{Chellappa2012,
abstract = {In this discussion paper, I present my views on the role on mathematical statistics for solving computer vision problems.},
author = {Chellappa, Rama},
doi = {10.1016/j.imavis.2012.03.008},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Chellappa - 2012 - Mathematical statistics and computer vision(2).pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Computer vision,Manifolds,Markov random fields,Mathematical statistics,Particle filters,Simulated annealing,computer vision,mathematical statistics},
mendeley-tags = {computer vision,mathematical statistics},
month = aug,
number = {8},
pages = {467--468},
title = {{Mathematical statistics and computer vision}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885612000674},
volume = {30},
year = {2012}
}
@article{Cheng2010,
abstract = {Breast cancer is the second leading cause of death for women all over the world. Since the cause of the disease remains unknown, early detection and diagnosis is the key for breast cancer control, and it can increase the success of treatment, save lives and reduce cost. Ultrasound imaging is one of the most frequently used diagnosis tools to detect and classify abnormalities of the breast. In order to eliminate the operator dependency and improve the diagnostic accuracy, computer-aided diagnosis (CAD) system is a valuable and beneficial means for breast cancer detection and classification. Generally, a CAD system consists of four stages: preprocessing, segmentation, feature extraction and selection, and classification. In this paper, the approaches used in these stages are summarized and their advantages and disadvantages are discussed. The performance evaluation of CAD system is investigated as well.},
author = {Cheng, H.D. D and Shan, Juan and Ju, Wen and Guo, Yanhui and Zhang, Ling},
doi = {10.1016/j.patcog.2009.05.012},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Cheng et al. - 2010 - Automated breast cancer detection and classification using ultrasound images A survey(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Automated breast cancer detection and classificati,CAD (computer-aided diagnosis),Classifiers,Feature extraction and selection,Ultrasound (US) imaging,preprocessing},
mendeley-tags = {preprocessing},
month = jan,
number = {1},
pages = {299--317},
title = {{Automated breast cancer detection and classification using ultrasound images: A survey}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320309002027},
volume = {43},
year = {2010}
}
@inproceedings{Cheng2011,
abstract = {Reliable estimation of visual saliency allows appropriate processing of images without prior knowledge of their contents, and thus remains an important step in many computer vision tasks including image segmentation, object recognition, and adaptive compression. We propose a regional contrast based saliency extraction algorithm, which simultaneously evaluates global contrast differences and spatial coherence. The proposed algorithm is simple, efficient, and yields full resolution saliency maps. Our algorithm consistently outperformed existing saliency detection methods, yielding higher precision and better recall rates, when evaluated using one of the largest publicly available data sets. We also demonstrate how the extracted saliency map can be used to create high quality segmentation masks for subsequent image processing.},
author = {Cheng, Ming-Ming and Zhang, Guo-Xin and Mitra, Niloy J. and Huang, Xiaolei and Hu, Shi-Min},
booktitle = {CVPR 2011},
doi = {10.1109/CVPR.2011.5995344},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Cheng et al. - 2011 - Global contrast based salient region detection(2).pdf:pdf},
isbn = {978-1-4577-0394-2},
issn = {1063-6919},
keywords = {Histograms,Humans,Image color analysis,Image segmentation,Quantization,Smoothing methods,Visualization,adaptive compression,computer vision,feature extraction,full resolution saliency maps,global contrast based salient region detection,high quality segmentation,image processing,image resolution,image segmentation,object recognition,regional contrast based saliency extraction algori,spatial coherence,visual saliency estimation reliability},
month = jun,
pages = {409--416},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Global contrast based salient region detection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5995344},
year = {2011}
}
@article{Condat2010,
abstract = {We propose two new types of random patterns with R, G, B colors, which allow to design color filter arrays (CFAs) with good spectral properties. Indeed, the chrominance channels have blue noise characteristics, a property which maximizes the robustness of the acquisition system to aliasing. With these new CFAs, the demosaicking artifacts appear as incoherent noise, which is less visually disturbing than the moir\'{e} structures characteristic of CFAs with periodic patterns.},
author = {Condat, Laurent},
doi = {10.1016/j.imavis.2009.12.004},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Condat - 2010 - Color filter array design using random patterns with blue noise chromatic spectra(2).pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Blue noise,Color filter array,Demosaicking,Random pattern},
month = aug,
number = {8},
pages = {1196--1202},
title = {{Color filter array design using random patterns with blue noise chromatic spectra}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885609002741},
volume = {28},
year = {2010}
}
@article{Crone2012,
abstract = {To date, best practice in sampling credit applicants has been established based largely on expert opinion, which generally recommends that small samples of 1500 instances each of both goods and bads are sufficient, and that the heavily biased datasets observed should be balanced by undersampling the majority class. Consequently, the topics of sample sizes and sample balance have not been subject to either formal study in credit scoring, or empirical evaluations across different data conditions and algorithms of varying efficiency. This paper describes an empirical study of instance sampling in predicting consumer repayment behaviour, evaluating the relative accuracies of logistic regression, discriminant analysis, decision trees and neural networks on two datasets across 20 samples of increasing size and 29 rebalanced sample distributions created by gradually under- and over-sampling the goods and bads respectively. The paper makes a practical contribution to model building on credit scoring datasets, and provides evidence that using samples larger than those recommended in credit scoring practice provides a significant increase in accuracy across algorithms.},
author = {Crone, Sven F. and Finlay, Steven},
doi = {10.1016/j.ijforecast.2011.07.006},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Crone, Finlay - 2012 - Instance sampling in credit scoring An empirical study of sample size and balancing(2).pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Balancing,Credit scoring,Data pre-processing,Over-sampling,Sample size,Under-sampling},
month = jan,
number = {1},
pages = {224--238},
title = {{Instance sampling in credit scoring: An empirical study of sample size and balancing}},
url = {http://www.sciencedirect.com/science/article/pii/S0169207011001403},
volume = {28},
year = {2012}
}
@article{D.RandallWilson,
author = {{D. Randall Wilson}, Tony R. Martinez},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/D. Randall Wilson - Unknown - Reduction Techniques for Exemplar-Based Learning Algorithms(2).pdf:pdf},
title = {{Reduction Techniques for Exemplar-Based Learning Algorithms}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.50.6544}
}
@article{mahalanobis2000,
abstract = {The theory of many multivariate chemometrical methods is based on the measurement of distances. The Mahalanobis distance (MD), in the original and principal component (PC) space, will be examined and interpreted in relation with the Euclidean distance (ED). Techniques based on the MD and applied in different fields of chemometrics such as in multivariate calibration, pattern recognition and process control are explained and discussed.},
author = {{De Maesschalck}, R. and Jouan-Rimbaud, D. and Massart, D.L.},
doi = {10.1016/S0169-7439(99)00047-7},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/De Maesschalck, Jouan-Rimbaud, Massart - 2000 - The Mahalanobis distance.pdf:pdf},
issn = {01697439},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {Euclidean distance,Mahalanobis distance,Principal components},
month = jan,
number = {1},
pages = {1--18},
title = {{The Mahalanobis distance}},
url = {http://www.sciencedirect.com/science/article/pii/S0169743999000477},
volume = {50},
year = {2000}
}
@article{DeMesquitaSaJunior2014,
abstract = {Color textures are among the most important visual attributes in image analysis. This paper presents a novel method to analyze color textures by modeling a color image as a graph in two different and complementary manners (each color channel separately and the three color channels altogether) and by obtaining statistical moments from the shortest paths between specific vertices of this graph. Such an approach allows to create a set of feature vectors, which were extracted from VisTex, USPTex, and TC00013 color texture databases. The best classification results were 99.07\%, 96.85\%, and 91.54\% (LDA with leave-one-out), 87.62\%, 66.71\%, and 88.06\% (1NN with holdout), and 98.62\%, 96.16\%, and 91.34\% (LDA with holdout) of success rate (percentage of samples correctly classified) for these three databases, respectively. These results prove that the proposed approach is a powerful tool for color texture analysis to be explored.},
author = {{de Mesquita Sa Junior}, Jarbas Joaci and Cortez, Paulo Cesar and Backes, Andre Ricardo},
doi = {10.1109/TIP.2014.2333655},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/de Mesquita Sa Junior, Cortez, Backes - 2014 - Color texture classification using shortest paths in graphs(2).pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
month = sep,
number = {9},
pages = {3751--3761},
pmid = {24988594},
title = {{Color texture classification using shortest paths in graphs.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24988594},
volume = {23},
year = {2014}
}
@article{Derrac2014a,
abstract = {The analysis of the performance of different approaches is a staple concern in the design of Computational Intelligence experiments. Any proper analysis of evolutionary optimization algorithms should incorporate a full set of benchmark problems and state-of-the-art comparison algorithms. For the sake of rigor, such an analysis may be completed with the use of statistical procedures, supporting the conclusions drawn. In this paper, we point out that these conclusions are usually limited to the final results, whereas intermediate results are seldom considered. We propose a new methodology for comparing evolutionary algorithms’ convergence capabilities, based on the use of Page’s trend test. The methodology is presented with a case of use, incorporating real results from selected techniques of a recent special issue. The possible applications of the method are highlighted, particularly in those cases in which the final results do not enable a clear evaluation of the differences among several evolutionary techniques.},
author = {Derrac, Joaqu\'{\i}n and Garc\'{\i}a, Salvador and Hui, Sheldon and Suganthan, Ponnuthurai Nagaratnam and Herrera, Francisco},
doi = {10.1016/j.ins.2014.06.009},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Derrac et al. - 2014 - Analyzing convergence performance of evolutionary algorithms A statistical approach(2).pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Convergence-based algorithmic comparison,Evolutionary algorithms,Nonparametric tests,Page’s trend test},
month = dec,
pages = {41--58},
title = {{Analyzing convergence performance of evolutionary algorithms: A statistical approach}},
url = {http://www.sciencedirect.com/science/article/pii/S0020025514006276},
volume = {289},
year = {2014}
}
@article{Donahue2013,
abstract = {We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.},
archivePrefix = {arXiv},
arxivId = {1310.1531},
author = {Donahue, Jeff and Jia, Yangqing and Vinyals, Oriol and Hoffman, Judy and Zhang, Ning and Tzeng, Eric and Darrell, Trevor},
eprint = {1310.1531},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Donahue et al. - 2013 - DeCAF A Deep Convolutional Activation Feature for Generic Visual Recognition(2).pdf:pdf},
month = oct,
title = {{DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition}},
url = {http://arxiv.org/abs/1310.1531},
year = {2013}
}
@misc{Drummond2003,
author = {Drummond, Chris and Holte, Robert C.},
booktitle = {Workshop on Learning from Imbalanced Datasets II},
file = {::},
title = {{C4.5, Class Imbalance, and Cost Sensitivity: Why Under-Sampling beats Over-Sampling}},
url = {https://www.site.uottawa.ca/~nat/Workshop2003/drummondc.pdf},
urldate = {2014-10-13},
year = {2003}
}
@article{Egmont-Petersen2002,
abstract = {We review more than 200 applications of neural networks in image processing and discuss the present and possible future role of neural networks, especially feed-forward neural networks, Kohonen feature maps and Hopfield neural networks. The various applications are categorised into a novel two-dimensional taxonomy for image processing algorithms. One dimension specifies the type of task performed by the algorithm: preprocessing, data reduction/feature extraction, segmentation, object recognition, image understanding and optimisation. The other dimension captures the abstraction level of the input data processed by the algorithm: pixel-level, local feature-level, structure-level, object-level, object-set-level and scene characterisation. Each of the six types of tasks poses specific constraints to a neural-based approach. These specific conditions are discussed in detail. A synthesis is made of unresolved problems related to the application of pattern recognition techniques in image processing and specifically to the application of neural networks. Finally, we present an outlook into the future application of neural networks and relate them to novel developments.},
author = {Egmont-Petersen, M. and de Ridder, D. and Handels, H.},
doi = {10.1016/S0031-3203(01)00178-9},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Egmont-Petersen, de Ridder, Handels - 2002 - Image processing with neural networks—a review(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Digital image processing,Feature extraction,Image compression,Image understanding,Invariant pattern recognition,Neural networks,Object recognition,Optimization,Preprocessing,Segmentation,preprocessing},
mendeley-tags = {preprocessing},
month = oct,
number = {10},
pages = {2279--2301},
title = {{Image processing with neural networks—a review}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320301001789},
volume = {35},
year = {2002}
}
@article{Estabrooks2004,
author = {Estabrooks, Andrew and Jo, Taeho and Japkowicz, Nathalie},
doi = {10.1111/j.0824-7935.2004.t01-1-00228.x},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Estabrooks, Jo, Japkowicz - 2004 - A Multiple Resampling Method for Learning from Imbalanced Data Sets(2).pdf:pdf},
issn = {0824-7935},
journal = {Computational Intelligence},
month = feb,
number = {1},
pages = {18--36},
title = {{A Multiple Resampling Method for Learning from Imbalanced Data Sets}},
url = {http://doi.wiley.com/10.1111/j.0824-7935.2004.t01-1-00228.x},
volume = {20},
year = {2004}
}
@book{Faceli2011,
author = {Faceli, K},
publisher = {Grupo Gen-LTC},
title = {{Intelig\^{e}ncia artificial: uma abordagem de aprendizado de m\'{a}quina}},
year = {2011}
}
@article{Farquad2012,
abstract = {This paper deals with the application of support vector machine (SVM) to deal with the class imbalance problem. The objective of this paper is to examine the feasibility and efficiency of SVM as a preprocessor. Our study analyzes different classification algorithms that are employed to predict the customers with caravan car policy based on his/her sociodemographic data and history of product ownership. A series of experiments was conducted to test various computational intelligence techniques viz., Multilayer Perceptron (MLP), Logistic Regression (LR), and Random Forest (RF). Various standard balancing techniques such as under-sampling, over-sampling and Synthetic Minority Over-sampling TEchnique (SMOTE) are also employed. Subsequently, a strategy of data balancing for handling imbalanced distribution in data is proposed. The proposed approach first employs SVM as a preprocessor and the actual target values of training data are then replaced by the predictions of trained SVM. Later, this modified training data is used to train techniques such as MLP, LR, and RF. Based on the measure of sensitivity, it is observed that the proposed approach not only balances the data effectively but also provides more number of instances for minority class, which in turn enhances the performance of the intelligence techniques.},
author = {Farquad, M.A.H. A H and Bose, Indranil},
doi = {10.1016/j.dss.2012.01.016},
file = {::},
issn = {01679236},
journal = {Decision Support Systems},
keywords = {COIL data,Hybrid method,Preprocessor,SVM,Unbalanced data,imbalancing},
mendeley-tags = {imbalancing},
month = apr,
number = {1},
pages = {226--233},
title = {{Preprocessing unbalanced data using support vector machine}},
url = {http://www.sciencedirect.com/science/article/pii/S0167923612000425},
volume = {53},
year = {2012}
}
@article{Fawcett2006,
abstract = {Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.},
author = {Fawcett, Tom},
doi = {10.1016/j.patrec.2005.10.010},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Fawcett - 2006 - An introduction to ROC analysis(2).pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Classifier evaluation,Evaluation metrics,ROC analysis},
month = jun,
number = {8},
pages = {861--874},
title = {{An introduction to ROC analysis}},
url = {http://www.sciencedirect.com/science/article/pii/S016786550500303X},
volume = {27},
year = {2006}
}
@inproceedings{Fergus2005,
abstract = {Current approaches to object category recognition require datasets of training images to be manually prepared, with varying degrees of supervision. We present an approach that can learn an object category from just its name, by utilizing the raw output of image search engines available on the Internet. We develop a new model, TSI-pLSA, which extends pLSA (as applied to visual words) to include spatial information in a translation and scale invariant manner. Our approach can handle the high intra-class variability and large proportion of unrelated images returned by search engines. We evaluate tire models on standard test sets, showing performance competitive with existing methods trained on hand prepared datasets},
author = {Fergus, R. and Fei-Fei, L. and Perona, P. and Zisserman, A.},
booktitle = {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
doi = {10.1109/ICCV.2005.142},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Fergus et al. - 2005 - Learning object categories from Google's image search(2).pdf:pdf},
isbn = {0-7695-2334-X},
issn = {1550-5499},
keywords = {Airplanes,Computer vision,Google,Image recognition,Image segmentation,Internet,Motorcycles,Search engines,TSI-pLSA,Testing,Watches,Wrist,classification,image classification,image retrieval,image search engines,object category learning,object category recognition,search engines},
pages = {1816----1823 Vol. 2},
publisher = {IEEE},
shorttitle = {Computer Vision, 2005. ICCV 2005. Tenth IEEE Inter},
title = {{Learning object categories from Google's image search}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1544937},
volume = {2},
year = {2005}
}
@article{Fernandez-Navarro2011,
abstract = {Classification with imbalanced datasets supposes a new challenge for researches in the framework of machine learning. This problem appears when the number of patterns that represents one of the classes of the dataset (usually the concept of interest) is much lower than in the remaining classes. Thus, the learning model must be adapted to this situation, which is very common in real applications. In this paper, a dynamic over-sampling procedure is proposed for improving the classification of imbalanced datasets with more than two classes. This procedure is incorporated into a memetic algorithm (MA) that optimizes radial basis functions neural networks (RBFNNs). To handle class imbalance, the training data are resampled in two stages. In the first stage, an over-sampling procedure is applied to the minority class to balance in part the size of the classes. Then, the MA is run and the data are over-sampled in different generations of the evolution, generating new patterns of the minimum sensitivity class (the class with the worst accuracy for the best RBFNN of the population). The methodology proposed is tested using 13 imbalanced benchmark classification datasets from well-known machine learning problems and one complex problem of microbial growth. It is compared to other neural network methods specifically designed for handling imbalanced data. These methods include different over-sampling procedures in the preprocessing stage, a threshold-moving method where the output threshold is moved toward inexpensive classes and ensembles approaches combining the models obtained with these techniques. The results show that our proposal is able to improve the sensitivity in the generalization set and obtains both a high accuracy level and a good classification level for each class.},
author = {Fern\'{a}ndez-Navarro, Francisco and Herv\'{a}s-Mart\'{\i}nez, C\'{e}sar and {Antonio Guti\'{e}rrez}, Pedro},
doi = {10.1016/j.patcog.2011.02.019},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Fern\'{a}ndez-Navarro, Herv\'{a}s-Mart\'{\i}nez, Antonio Guti\'{e}rrez - 2011 - A dynamic over-sampling procedure based on sensitivity for multi-c(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Accuracy,Classification,Imbalanced datasets,Memetic algorithm,Multi-class,Over-sampling method,SMOTE,Sensitivity},
month = aug,
number = {8},
pages = {1821--1833},
title = {{A dynamic over-sampling procedure based on sensitivity for multi-class problems}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320311000823},
volume = {44},
year = {2011}
}
@article{Fischer2014,
abstract = {Restricted Boltzmann machines (RBMs) are probabilistic graphical models that can be interpreted as stochastic neural networks. They have attracted much attention as building blocks for the multi-layer learning systems called deep belief networks, and variants and extensions of RBMs have found application in a wide range of pattern recognition tasks. This tutorial introduces RBMs from the viewpoint of Markov random fields, starting with the required concepts of undirected graphical models. Different learning algorithms for RBMs, including contrastive divergence learning and parallel tempering, are discussed. As sampling from RBMs, and therefore also most of their learning algorithms, are based on Markov chain Monte Carlo (MCMC) methods, an introduction to Markov chains and MCMC techniques is provided. Experiments demonstrate relevant aspects of RBM training.},
author = {Fischer, Asja and Igel, Christian},
doi = {10.1016/j.patcog.2013.05.025},
file = {:Users/gabi/Dropbox/MESTRADO/Referencias/TRBMAI.pdf:pdf;:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Fischer, Igel - 2014 - Training restricted Boltzmann machines An introduction.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Contrastive divergence learning,Gibbs sampling,Markov chains,Markov random fields,Neural networks,Parallel tempering,Restricted Boltzmann machines},
month = jan,
number = {1},
pages = {25--39},
title = {{Training restricted Boltzmann machines: An introduction}},
volume = {47},
year = {2014}
}
@inproceedings{google09,
abstract = {The last two years have witnessed the introduction and rapid expansion of products based upon large, systematically-gathered, street-level image collections, such as Google Street View, EveryScape, and Mapjack. In the process of gathering images of public spaces, these projects also capture license plates, faces, and other information considered sensitive from a privacy standpoint. In this work, we present a system that addresses the challenge of automatically detecting and blurring faces and license plates for the purpose of privacy protection in Google Street View. Though some in the field would claim face detection is “solved”, we show that state-of-the-art face detectors alone are not sufficient to achieve the recall desired for large-scale privacy protection. In this paper we present a system that combines a standard sliding-window detector tuned for a high recall, low-precision operating point with a fast post-processing stage that is able to remove additional false positives by incorporating domain-specific information not available to the sliding-window detector. Using a completely automatic system, we are able to sufficiently blur more than 89\% of faces and 94 - 96\% of license plates in evaluation sets sampled from Google Street View imagery.},
author = {Frome, Andrea and Cheung, German and Abdulkader, Ahmad and Zennaro, Marco and Bissacco, Alessandro and Adam, Hartwig and Neven, Hartmut and Vincent, Luc},
booktitle = {2009 IEEE 12th International Conference on Computer Vision},
doi = {10.1109/ICCV.2009.5459413},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Frome et al. - 2009 - Large-scale privacy protection in Google Street View(2).pdf:pdf},
isbn = {978-1-4244-4420-5},
issn = {1550-5499},
keywords = {Automatic control,Cameras,Computer vision,Continents,Detectors,EveryScape,Face detection,Google Street View,Large-scale systems,Licenses,Mapjack,Privacy,Protection,data privacy,face blurring,face detection,face detectors,face recognition,image gathering,privacy protection,sliding-window detector},
month = sep,
pages = {2373--2380},
publisher = {IEEE},
shorttitle = {Computer Vision, 2009 IEEE 12th International Conf},
title = {{Large-scale privacy protection in Google Street View}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5459413},
year = {2009}
}
@article{Galbally2014,
author = {Galbally, Javier and Marcel, Sebastien and Fierrez, Julian},
doi = {10.1109/TIP.2013.2292332},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Galbally, Marcel, Fierrez - 2014 - Image Quality Assessment for Fake Biometric Detection Application to Iris, Fingerprint, and Face R(2).pdf:pdf},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
month = feb,
number = {2},
pages = {710--724},
title = {{Image Quality Assessment for Fake Biometric Detection: Application to Iris, Fingerprint, and Face Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6671991},
volume = {23},
year = {2014}
}
@article{Garc2009,
author = {Garc, V},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Garc - 2009 - Index of Balanced Accuracy A Performance Measure(2).pdf:pdf},
pages = {441--448},
title = {{Index of Balanced Accuracy : A Performance Measure}},
year = {2009}
}
@article{Garcia2009,
abstract = {With the continuous expansion of data availability in many large-scale, complex, and networked systems, such as surveillance, security, Internet, and finance, it becomes critical to advance the fundamental understanding of knowledge discovery and analysis from raw data to support decision-making processes. Although existing knowledge discovery and data engineering techniques have shown great success in many real-world applications, the problem of learning from imbalanced data (the imbalanced learning problem) is a relatively new challenge that has attracted growing attention from both academia and industry. The imbalanced learning problem is concerned with the performance of learning algorithms in the presence of underrepresented data and severe class distribution skews. Due to the inherent complex characteristics of imbalanced data sets, learning from such data requires new understandings, principles, algorithms, and tools to transform vast amounts of raw data efficiently into information and knowledge representation. In this paper, we provide a comprehensive review of the development of research in learning from imbalanced data. Our focus is to provide a critical review of the nature of the problem, the state-of-the-art technologies, and the current assessment metrics used to evaluate learning performance under the imbalanced learning scenario. Furthermore, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potential important research directions for learning from imbalanced data.},
author = {Garcia, E.A. A},
doi = {10.1109/TKDE.2008.239},
file = {::},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Imbalanced learning,active learning,assessment metrics.,classification,complex systems,cost-sensitive learning,data availability,data engineering,data mining,decision making,imbalanced data,kernel-based learning,knowledge discovery,large-scale systems,learning,learning (artificial intelligence),networked systems,sampling methods},
month = sep,
number = {9},
pages = {1263--1284},
shorttitle = {Knowledge and Data Engineering, IEEE Transactions},
title = {{Learning from Imbalanced Data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5128907},
volume = {21},
year = {2009}
}
@article{friedman2010,
abstract = {Experimental analysis of the performance of a proposed method is a crucial and necessary task in an investigation. In this paper, we focus on the use of nonparametric statistical inference for analyzing the results obtained in an experiment design in the field of computational intelligence. We present a case study which involves a set of techniques in classification tasks and we study a set of nonparametric procedures useful to analyze the behavior of a method with respect to a set of algorithms, such as the framework in which a new proposal is developed. Particularly, we discuss some basic and advanced nonparametric approaches which improve the results offered by the Friedman test in some circumstances. A set of post hoc procedures for multiple comparisons is presented together with the computation of adjusted p-values. We also perform an experimental analysis for comparing their power, with the objective of detecting the advantages and disadvantages of the statistical tests described. We found that some aspects such as the number of algorithms, number of data sets and differences in performance offered by the control method are very influential in the statistical tests studied. Our final goal is to offer a complete guideline for the use of nonparametric statistical procedures for performing multiple comparisons in experimental studies.},
author = {Garc\'{\i}a, Salvador and Fern\'{a}ndez, Alberto and Luengo, Juli\'{a}n and Herrera, Francisco},
doi = {10.1016/j.ins.2009.12.010},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Garc\'{\i}a et al. - 2010 - Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intellige(2).pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Computational intelligence,Data mining,Fuzzy classification systems,Genetics-based machine learning,Multiple comparisons procedures,Nonparametric statistics,Statistical analysis},
month = may,
number = {10},
pages = {2044--2064},
title = {{Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence and data mining: Experimental analysis of power}},
url = {http://www.sciencedirect.com/science/article/pii/S0020025509005404},
volume = {180},
year = {2010}
}
@article{Garcia2012,
abstract = {The present paper investigates the influence of both the imbalance ratio and the classifier on the performance of several resampling strategies to deal with imbalanced data sets. The study focuses on evaluating how learning is affected when different resampling algorithms transform the originally imbalanced data into artificially balanced class distributions. Experiments over 17 real data sets using eight different classifiers, four resampling algorithms and four performance evaluation measures show that over-sampling the minority class consistently outperforms under-sampling the majority class when data sets are strongly imbalanced, whereas there are not significant differences for databases with a low imbalance. Results also indicate that the classifier has a very poor influence on the effectiveness of the resampling strategies.},
author = {Garc\'{\i}a, V. and S\'{a}nchez, J.S. S and Mollineda, R.A. A},
doi = {10.1016/j.knosys.2011.06.013},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Garc\'{\i}a, S\'{a}nchez, Mollineda - 2012 - On the effectiveness of preprocessing methods when dealing with different levels of class imbal(2).pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Classification,Imbalance,Multi-dimensional scaling,Performance measures,Resampling},
month = feb,
number = {1},
pages = {13--21},
title = {{On the effectiveness of preprocessing methods when dealing with different levels of class imbalance}},
url = {http://www.sciencedirect.com/science/article/pii/S0950705111001286},
volume = {25},
year = {2012}
}
@phdthesis{thesisDeep,
author = {George, Dileep},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/George - 2008 - How the brain might work a hierarchical and temporal model for learning and recognition(2).pdf:pdf},
school = {Stanford University},
title = {{How the brain might work: a hierarchical and temporal model for learning and recognition}},
type = {Dissertation},
year = {2008}
}
@book{Gonzalez2007,
abstract = {THE leader in the field for more than twenty years, this introduction to basic concepts and methodologies for digital image processing continues its cutting-edge focus on contemporary developments in all mainstream areas of image processing. Completely self-contained, heavily illustrated, and mathematically accessible, it has a scope of application that is not limited to the solution of specialized problems. Digital Image Fundamentals. Image Enhancement in the Spatial Domain. Image Enhancement in the Frequency Domain. Image Restoration. Color Image Processing. Wavelets and Multiresolution Processing. Image Compression. Morphological Image Processing. Image Segmentation. Representation and Description. Object Recognition. For technicians interested in the fundamentals and contemporary applications of digital imaging processing},
author = {Gonzalez, Rafael C and Woods, Richard E},
booktitle = {3nd edition},
edition = {3},
isbn = {013168728X},
publisher = {Prentice-Hall},
title = {{Digital Image Processing}},
year = {2007}
}
@article{Gregor2015,
abstract = {This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye.},
archivePrefix = {arXiv},
arxivId = {1502.04623},
author = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and Wierstra, Daan},
eprint = {1502.04623},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Gregor et al. - 2015 - DRAW A Recurrent Neural Network For Image Generation.pdf:pdf},
month = feb,
title = {{DRAW: A Recurrent Neural Network For Image Generation}},
url = {http://arxiv.org/abs/1502.04623},
year = {2015}
}
@article{Gross2003,
author = {Gross, Ralph and Brajovic, Vladimir},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Gross, Brajovic - 2003 - An image preprocessing algorithm for illumination invariant face recognition(2).pdf:pdf},
journal = {Audio and Video-Based Biometric Person Authentication},
pages = {10--18},
title = {{An image preprocessing algorithm for illumination invariant face recognition}},
url = {http://link.springer.com/chapter/10.1007/3-540-44887-X\_2},
year = {2003}
}
@article{Hala2014,
abstract = {There is a great need for accurate and autonomous spectral classification methods in astrophysics. This thesis is about training a convolutional neural network (ConvNet) to recognize an object class (quasar, star or galaxy) from one-dimension spectra only. Author developed several scripts and C programs for datasets preparation, preprocessing and postprocessing of the data. EBLearn library (developed by Pierre Sermanet and Yann LeCun) was used to create ConvNets. Application on dataset of more than 60000 spectra yielded success rate of nearly 95\%. This thesis conclusively proved great potential of convolutional neural networks and deep learning methods in astrophysics.},
archivePrefix = {arXiv},
arxivId = {1412.8341},
author = {H\'{a}la, Pavel},
eprint = {1412.8341},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/H\'{a}la - 2014 - Spectral classification using convolutional neural networks(2).pdf:pdf},
month = dec,
pages = {71},
title = {{Spectral classification using convolutional neural networks}},
url = {http://arxiv.org/abs/1412.8341},
year = {2014}
}
@article{Hall1971,
abstract = {Feature extraction is one of the more difficult steps in image pattern recognition. Some sources of difficulty are the presence of irrelevant information and the relativity of a feature set to a particular application. Several preprocessing techniques for enhancing selected features and removing irrelevant data are described and compared. The techniques include gray level distribution linearization, digital spatial filtering, contrast enhancement, and image subtraction. Also, several feature extraction techniques are illustrated. The techniques are divided into spatial and Fourier domain operations. The spatial domain operations of directional signatures and contour tracing are first described. Then, the Fourier domain techniques of frequency signatures and template matching are illustrated. Finally, a practical image pattern recognition problem is solved using some of the described techniques.},
author = {Hall, E.L. L and Kruger, R.P. P and Dwyer, S.J. J and Hall, D.L. L and Mclaren, R.W. W and Lodwick, G.S. S},
doi = {10.1109/T-C.1971.223399},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Hall et al. - 1971 - A Survey of Preprocessing and Feature Extraction Techniques for Radiographic Images(2).pdf:pdf},
issn = {0018-9340},
journal = {IEEE Transactions on Computers},
keywords = {Data mining,Diagnostic radiography,Digital filters,Feature extraction,Filtering,Image analysis,Image processing,Matched filters,Pattern recognition,Radiology,pattern recognition,preproces,preprocessing},
mendeley-tags = {preprocessing},
month = sep,
number = {9},
pages = {1032--1044},
shorttitle = {Computers, IEEE Transactions on},
title = {{A Survey of Preprocessing and Feature Extraction Techniques for Radiographic Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1671992},
volume = {C-20},
year = {1971}
}
@article{Han2003,
abstract = {Biometrics-based authentication is a verification approach using the biological features inherent in each individual. They are processed based on the identical, portable, and arduous duplicate characteristics. In this paper, we propose a scanner-based personal authentication system by using the palm-print features. It is very suitable in many network-based applications. The authentication system consists of enrollment and verification stages. In the enrollment stage, the training samples are collected and processed by the pre-processing, feature extraction, and modeling modules to generate the matching templates. In the verification stage, a query sample is also processed by the pre-processing and feature extraction modules, and then is matched with the reference templates to decide whether it is a genuine sample or not. The region of interest (ROI) for each sample is first obtained from the pre-processing module. Then, the palm-print features are extracted from the ROI by using Sobel and morphological operations. The reference templates for a specific user are generated in the modeling module. Last, we use the template-matching and the backpropagation neural network to measure the similarity in the verification stage. Experimental results verify the validity of our proposed approaches in personal authentication.},
author = {Han, Chin-Chuan and Cheng, Hsu-Liang and Lin, Chih-Lung and Fan, Kuo-Chin},
doi = {10.1016/S0031-3203(02)00037-7},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Han et al. - 2003 - Personal authentication using palm-print features(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Backpropagation neural network,Multi-template matching,Palmprint features,Personal authentication,preprocessing},
mendeley-tags = {preprocessing},
month = feb,
number = {2},
pages = {371--381},
title = {{Personal authentication using palm-print features}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320302000377},
volume = {36},
year = {2003}
}
@article{Han2005,
abstract = {In recent years, mining with imbalanced data sets receives more and more attentions in both theoretical and practical aspects. This paper introduces the importance of imbalanced data sets and their broad application domains in data mining, and then summarizes the evaluation metrics and the existing methods to evaluate and solve the imbalance problem. Synthetic minority over-sampling technique (SMOTE) is one of the over-sampling methods addressing this problem. Based on SMOTE method, this paper presents two new minority over-sampling methods, borderline-SMOTE1 and borderline-SMOTE2, in which only the minority examples near the borderline are over-sampled. For the minority class, experiments show that our approaches achieve better TP rate and F-value than SMOTE and random over-sampling methods.},
author = {Han, Hui and Wang, Wen\-Yuan and Mao, Bing\-Huan},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Han, Wang, Mao - 2005 - Borderline-SMOTE A new over-sampling method in imbalanced data sets learning(5).pdf:pdf},
journal = {Advances in intelligent computing},
keywords = {High dimensional data,Multidimensional projection,Visual data mining,classification,imbalance,oversampling,smote},
number = {12},
pages = {878--887},
publisher = {Alvey Vision Club},
title = {{Borderline-SMOTE: A new over-sampling method in imbalanced data sets learning}},
url = {http://link.springer.com/chapter/10.1007/11538059\_91},
volume = {17},
year = {2005}
}
@article{Haralick1973,
abstract = {Texture is one of the important characteristics used in identifying objects or regions of interest in an image, whether the image be a photomicrograph, an aerial photograph, or a satellite image. This paper describes some easily computable textural features based on gray-tone spatial dependancies, and illustrates their application in category-identification tasks of three different kinds of image data: photomicrographs of five kinds of sandstones, 1:20 000 panchromatic aerial photographs of eight land-use categories, and Earth Resources Technology Satellite (ERTS) multispecial imagery containing seven land-use categories. We use two kinds of decision rules: one for which the decision regions are convex polyhedra (a piecewise linear decision rule), and one for which the decision regions are rectangular parallelpipeds (a min-max decision rule). In each experiment the data set was divided into two parts, a training set and a test set. Test set identification accuracy is 89 percent for the photomicrographs, 82 percent for the aerial photographic imagery, and 83 percent for the satellite imagery. These results indicate that the easily computable textural features probably have a general applicability for a wide variety of image-classification applications.},
author = {Haralick, Robert M. and Shanmugam, K. and Dinstein, Its'Hak},
doi = {10.1109/TSMC.1973.4309314},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Haralick, Shanmugam, Dinstein - 1973 - Textural Features for Image Classification.pdf:pdf},
issn = {0018-9472},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
keywords = {Application software,Crops,Earth,Humans,Image classification,Image resolution,Piecewise linear techniques,Satellites,Spatial resolution,Testing,features,image classification,texture},
mendeley-tags = {features,image classification,texture},
month = nov,
number = {6},
pages = {610--621},
shorttitle = {Systems, Man and Cybernetics, IEEE Transactions on},
title = {{Textural Features for Image Classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4309314},
volume = {3},
year = {1973}
}
@inproceedings{Han2005b,
author = {Harris, Chris and Stephens, Mike},
booktitle = {Proceedings of the Alvey Vision Conference},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Harris, Stephens - 1998 - A combined corner and edge detector.pdf:pdf},
keywords = {High dimensional data,Multidimensional projection,Visual data mining},
pages = {147----152},
publisher = {Alvey Vision Club},
title = {{A combined corner and edge detector}},
url = {http://www.bmva.org/bmvc/1988/avc-88-023.html},
year = {1998}
}
@article{He2009,
abstract = {Iris segmentation is an essential module in iris recognition because it defines the effective image region used for subsequent processing such as feature extraction. Traditional iris segmentation methods often involve an exhaustive search of a large parameter space, which is time consuming and sensitive to noise. To address these problems, this paper presents a novel algorithm for accurate and fast iris segmentation. After efficient reflection removal, an Adaboost-cascade iris detector is first built to extract a rough position of the iris center. Edge points of iris boundaries are then detected, and an elastic model named pulling and pushing is established. Under this model, the center and radius of the circular iris boundaries are iteratively refined in a way driven by the restoring forces of Hooke's law. Furthermore, a smoothing spline-based edge fitting scheme is presented to deal with noncircular iris boundaries. After that, eyelids are localized via edge detection followed by curve fitting. The novelty here is the adoption of a rank filter for noise elimination and a histogram filter for tackling the shape irregularity of eyelids. Finally, eyelashes and shadows are detected via a learned prediction model. This model provides an adaptive threshold for eyelash and shadow detection by analyzing the intensity distributions of different iris regions. Experimental results on three challenging iris image databases demonstrate that the proposed algorithm outperforms state-of-the-art methods in both accuracy and speed.},
author = {He, Zhaofeng and Tan, Tieniu and Sun, Zhenan and Qiu, Xianchao},
doi = {10.1109/TPAMI.2008.183},
file = {::},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Biometry,Biometry: methods,Computer-Assisted,Computer-Assisted: methods,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Iris,Iris: anatomy \& histology,Pattern Recognition,Subtraction Technique},
month = sep,
number = {9},
pages = {1670--84},
pmid = {19574626},
title = {{Toward accurate and fast iris segmentation for iris biometrics}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19574626},
volume = {31},
year = {2009}
}
@article{Heusch2006,
author = {Heusch, G. and Rodriguez, Y. and Marcel, S.},
doi = {10.1109/FGR.2006.72},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Heusch, Rodriguez, Marcel - 2006 - Local Binary Patterns as an Image Preprocessing for Face Authentication(2).pdf:pdf},
isbn = {0-7695-2503-2},
journal = {7th International Conference on Automatic Face and Gesture Recognition (FGR06)},
pages = {9--14},
publisher = {Ieee},
title = {{Local Binary Patterns as an Image Preprocessing for Face Authentication}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1612990},
year = {2006}
}
@article{Hinton2006,
author = {Hinton, G and Osindero, Simon and Teh, YW W},
file = {::},
journal = {Neural computation},
title = {{A fast learning algorithm for deep belief nets}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6796673},
year = {2006}
}
@article{Hinton2006a,
author = {Hinton, Geoffrey},
file = {::},
title = {{To Recognize Shapes , First Learn to Generate Images To Recognize Shapes , First Learn to Generate Images}},
year = {2006}
}
@article{Huang2014,
abstract = {Recent investigations on human vision discover that the retinal image is a landscape or a geometric surface, consisting of features such as ridges and summits. However, most of existing popular local image descriptors in the literature, e.g., scale invariant feature transform (SIFT), histogram of oriented gradient (HOG), DAISY, local binary Patterns (LBP), and gradient location and orientation histogram, only employ the first-order gradient information related to the slope and the elasticity, i.e., length, area, and so on of a surface, and thereby partially characterize the geometric properties of a landscape. In this paper, we introduce a novel and powerful local image descriptor that extracts the histograms of second-order gradients (HSOGs) to capture the curvature related geometric properties of the neural landscape, i.e., cliffs, ridges, summits, valleys, basins, and so on. We conduct comprehensive experiments on three different applications, including the problem of local image matching, visual object categorization, and scene classification. The experimental results clearly evidence the discriminative power of HSOG as compared with its first-order gradient-based counterparts, e.g., SIFT, HOG, DAISY, and center-symmetric LBP, and the complementarity in terms of image representation, demonstrating the effectiveness of the proposed local descriptor.},
author = {Huang, Di and Zhu, Chao and Wang, Yunhong and Chen, Liming},
doi = {10.1109/TIP.2014.2353814},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Huang et al. - 2014 - HSOG A Novel Local Image Descriptor Based on Histograms of the Second-Order Gradients(2).pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing},
month = nov,
number = {11},
pages = {4680--95},
pmid = {25203990},
title = {{HSOG: A Novel Local Image Descriptor Based on Histograms of the Second-Order Gradients.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25203990},
volume = {23},
year = {2014}
}
@inproceedings{ccv,
author = {Huang, Jing and Kumar, S Ravi and Mitra, Mandar and Zhu, Wei-Jing and Zabih, Ramin},
booktitle = {Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.1997.609412},
isbn = {0-8186-7822-4},
issn = {1063-6919},
keywords = {Cameras,Histograms,Image databases,Image retrieval,Indexing,Layout,Optical computing,Robustness,Shape,Spatial databases,camera zooms,color correlograms,content-based image retrieval,histogram refinement methods,image feature,image indexing,image retrieval,indexing,information retrieval systems,spatial correlation,viewing positions,visual databases},
language = {English},
pages = {762--768},
publisher = {IEEE},
title = {{Image indexing using color correlograms}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=609412},
year = {1997}
}
@article{Inpainting2014,
author = {Inpainting, Sparsity-based Image and Li, Fang and Zeng, Tieyong},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Inpainting, Li, Zeng - 2014 - A Universal Variational Framework for(2).pdf:pdf},
journal = {IEEE Trans},
number = {10},
pages = {4242--4254},
title = {{A Universal Variational Framework for}},
volume = {23},
year = {2014}
}
@misc{Intel2010,
abstract = {BSD license},
author = {Intel},
keywords = {Intel Corporation},
publisher = {Intel Corporation, BSD license.},
title = {{OpenCV: open source computer vision library}},
url = {http://opencv.willowgarage.com/wiki/},
year = {2010}
}
@article{Jain2014,
abstract = {In this work, we propose a novel and efficient method for articulated human pose estimation in videos using a convolutional network architecture, which incorporates both color and motion features. We propose a new human body pose dataset, FLIC-motion, that extends the FLIC dataset with additional motion features. We apply our architecture to this dataset and report significantly better performance than current state-of-the-art pose detection systems.},
archivePrefix = {arXiv},
arxivId = {1409.7963},
author = {Jain, Arjun and Tompson, Jonathan and LeCun, Yann and Bregler, Christoph},
eprint = {1409.7963},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Jain et al. - 2014 - MoDeep A Deep Learning Framework Using Motion Features for Human Pose Estimation(2).pdf:pdf},
month = sep,
title = {{MoDeep: A Deep Learning Framework Using Motion Features for Human Pose Estimation}},
url = {http://arxiv.org/abs/1409.7963},
year = {2014}
}
@article{Jaouen2014,
abstract = {In this paper, we extend the gradient vector flow field for robust variational segmentation of vector-valued images. Rather than using scalar edge information, we define a vectorial edge map derived from a weighted local structure tensor of the image that enables the diffusion of the gradient vectors in accurate directions through the 4D gradient vector flow equation. To reduce the contribution of noise in the structure tensor, image channels are weighted according to a blind estimator of contrast. The method is applied to biological volume delineation in dynamic PET imaging, and validated on realistic Monte Carlo simulations of numerical phantoms as well as on real images.},
author = {Jaouen, Vincent and Gonzalez, Paulo and Stute, Simon and Guilloteau, Denis and Chalon, Sylvie and Buvat, Irene and Tauber, Clovis},
doi = {10.1109/TIP.2014.2353854},
file = {::},
issn = {1941-0042},
journal = {IEEE transactions on image processing},
month = nov,
number = {11},
pages = {4773--85},
pmid = {25203991},
title = {{Variational segmentation of vector-valued images with gradient vector flow}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25203991},
volume = {23},
year = {2014}
}
@article{Japkowicz2003,
author = {Japkowicz, N},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Japkowicz - 2003 - Class imbalances are we focusing on the right issue.ps:ps},
journal = {Workshop on Learning from Imbalanced Data Sets II},
title = {{Class imbalances: are we focusing on the right issue}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Class+Imbalances:+Are+We+Focusing+on+the+Right+Issue?\#0},
year = {2003}
}
@misc{Japkowicz2000,
author = {Japkowicz, Nathalie},
booktitle = {AAAI Technical Report},
file = {::},
pages = {10--15},
title = {{Learning from Imbalanced Data Sets: A Comparison of Various Strategies}},
url = {http://www.aaai.org/Papers/Workshops/2000/WS-00-05/WS00-05-003.pdf},
urldate = {2014-10-13},
year = {2000}
}
@article{Japkowicz2002,
author = {Japkowicz, Nathalie and Stephen, Shaju},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Japkowicz, Stephen - 2002 - The class imbalance problem A systematic study.pdf:pdf},
journal = {Intelligent data analysis},
keywords = {0,c5,class imbalances,concept learning,misclassification costs,multi-layer perceptrons,re-sampling,support},
number = {5},
pages = {429--449},
publisher = {IOS Press},
title = {{The class imbalance problem : A systematic study}},
volume = {6},
year = {2002}
}
@article{Jia2014,
archivePrefix = {arXiv},
arxivId = {1408.5093},
author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
eprint = {1408.5093},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Jia et al. - 2014 - Caffe Convolutional Architecture for Fast Feature Embedding.pdf:pdf},
month = jun,
title = {{Caffe: Convolutional Architecture for Fast Feature Embedding}},
url = {http://arxiv.org/abs/1408.5093},
year = {2014}
}
@article{Joia2011,
abstract = {Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP's versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents.},
author = {Joia, Paulo and Paulovich, Fernando V. and Coimbra, Danilo and Cuminato, Jos\'{e} Alberto and Nonato, Luis Gustavo},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Joia et al. - 2011 - Local Affine Multidimensional Projection.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {High dimensional data,Multidimensional projection,Visual data mining},
number = {12},
pages = {2563--2571},
title = {{Local Affine Multidimensional Projection}},
volume = {17},
year = {2011}
}
@inproceedings{Kanan2010,
abstract = {Classification of images in many category datasbets has rapidly improved in recent years. However, systems that perform well on particular datasets typically have one or more limitations such as a failure to generalize across visual tasks (e.g., requiring a face detector or extensive retuning of parameters), insufficient translation invariance, inability to cope with partial views and occlusion, or significant performance degradation as the number of classes is increased. Here we attempt to overcome these challenges using a model that combines sequential visual attention using fixations with sparse coding. The model's biologically-inspired filters are acquired using unsupervised learning applied to natural image patches. Using only a single feature type, our approach achieves 78.5\% accuracy on Caltech-101 and 75.2\% on the 102 Flowers dataset when trained on 30 instances per class and it achieves 92.7\% accuracy on the AR Face database with 1 training instance per person. The same features and parameters are used across these datasets to illustrate its robust performance.},
author = {Kanan, Christopher and Cottrell, Garrison},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5539947},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Kanan, Cottrell - 2010 - Robust classification of objects, faces, and flowers using natural image statistics(2).pdf:pdf},
isbn = {978-1-4244-6984-0},
issn = {1063-6919},
keywords = {Biological system modeling,Degradation,Detectors,Face detection,Filters,Image databases,Robustness,Spatial databases,Statistics,Unsupervised learning,image classification,image coding,image statistic,object classification,preprocessing,sparse coding,translation invariance,unsupervised learning},
mendeley-tags = {preprocessing},
month = jun,
pages = {2472--2479},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Robust classification of objects, faces, and flowers using natural image statistics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5539947},
year = {2010}
}
@article{Kanan2012,
abstract = {In image recognition it is often assumed the method used to convert color images to grayscale has little impact on recognition performance. We compare thirteen different grayscale algorithms with four types of image descriptors and demonstrate that this assumption is wrong: not all color-to-grayscale algorithms work equally well, even when using descriptors that are robust to changes in illumination. These methods are tested using a modern descriptor-based image recognition framework, on face, object, and texture datasets, with relatively few training instances. We identify a simple method that generally works best for face and object recognition, and two that work well for recognizing textures.},
author = {Kanan, Christopher and Cottrell, Garrison W},
doi = {10.1371/journal.pone.0029740},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Kanan, Cottrell - 2012 - Color-to-grayscale does the method matter in image recognition(2).pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Algorithms,Animals,Automated,Automated: methods,Color,Computer-Assisted,Computer-Assisted: methods,Databases as Topic,Humans,Image Interpretation,Pattern Recognition},
month = jan,
number = {1},
pages = {e29740},
pmid = {22253768},
title = {{Color-to-grayscale: does the method matter in image recognition?}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3254613\&tool=pmcentrez\&rendertype=abstract},
volume = {7},
year = {2012}
}
@article{An1980,
author = {kanneth ivan Laws and kanneth ivan Laws},
file = {::},
number = {3119},
title = {texture image segmentation},
year = {1980}
}
@article{Knaus2014,
abstract = {Image denoising continues to be an active research topic. Although state-of-the-art denoising methods are numerically impressive and approch theoretical limits, they suffer from visible artifacts.While they produce acceptable results for natural images, human eyes are less forgiving when viewing synthetic images. At the same time, current methods are becoming more complex, making analysis, and implementation difficult. We propose image denoising as a simple physical process, which progressively reduces noise by deterministic annealing. The results of our implementation are numerically and visually excellent. We further demonstrate that our method is particularly suited for synthetic images. Finally, we offer a new perspective on image denoising using robust estimators.},
author = {Knaus, Claude and Zwicker, Matthias},
doi = {10.1109/TIP.2014.2326771},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Knaus, Zwicker - 2014 - Progressive image denoising(2).pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing},
keywords = {Annealing,Fourier transforms,Frequency-domain analysis,Image denoising,Kernel,Noise,Noise reduction,Robustness,bilateral filtering,deterministic annealing,human eyes,image denoising,natural images,noise reduction,preprocessing,progressive image denoising,robust estimation,robust estimators,short-time Fourier transform,synthetic images,visible artifacts},
mendeley-tags = {image denoising,preprocessing},
month = jul,
number = {7},
pages = {3114--3125},
pmid = {24876125},
shorttitle = {Image Processing, IEEE Transactions on},
title = {{Progressive image denoising.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24876125},
volume = {23},
year = {2014}
}
@article{Kohonen1982,
author = {Kohonen, Teuvo},
doi = {10.1007/BF00337288},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Kohonen - 1982 - Self-organized formation of topologically correct feature maps(2).pdf:pdf},
issn = {0340-1200},
journal = {Biological Cybernetics},
number = {1},
pages = {59--69},
title = {{Self-organized formation of topologically correct feature maps}},
url = {http://link.springer.com/10.1007/BF00337288},
volume = {43},
year = {1982}
}
@article{Kotsiantis2006,
author = {Kotsiantis, Sotiris},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Kotsiantis - 2006 - Handling imbalanced datasets A review.pdf:pdf},
journal = {International Transactions on Computer Science and Engineering},
title = {{Handling imbalanced datasets: A review}},
url = {http://adaptiveilp.googlecode.com/svn/trunk/imbalanced datasets survey paper gests.pdf http://adaptiveilp.googlecode.com/svn/trunk/imbalanced datasets survey paper gests.pdf},
volume = {30},
year = {2006}
}
@inproceedings{Krizhevsky,
author = {Krizhevsky, Alex and Hinton, Geoffrey E. and Sutskever, Ilya},
booktitle = {Advances in Neural Information Processing Systems},
file = {::},
pages = {1--9},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {http://papers.nips.cc/paper/4824-imagenet},
year = {2012}
}
@article{Kumar2010,
author = {Kumar, MP P and Packer, Benjamin and Koller, Daphne},
file = {::},
journal = {Advances in Neural Information \ldots},
pages = {1--9},
title = {{Self-paced learning for latent variable models}},
url = {http://papers.nips.cc/paper/3923-self-paced-learning-for-latent-variable-models},
year = {2010}
}
@book{Kuncheva2004,
author = {Kuncheva, LI},
publisher = {John Wiley \& Sons},
title = {{Combining pattern classifiers: methods and algorithms}},
year = {2004}
}
@book{Laurikkala2001,
address = {London, UK},
author = {Laurikkala, Jorma},
booktitle = {Proceedings of the 8th Conference on AI in Medicine in Europe: Artificial Intelligence Medicine},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Laurikkala - 2001 - Improving identification of difficult small classes by balancing class distribution(3).pdf:pdf},
isbn = {3-540-42294-3},
month = jul,
pages = {63--66},
publisher = {Springer-Verlag},
title = {{Improving identification of difficult small classes by balancing class distribution}},
url = {http://dl.acm.org/citation.cfm?id=648155.757340 http://link.springer.com/chapter/10.1007/3-540-48229-6\_9},
year = {2001}
}
@article{Lawrence1997,
abstract = {We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer.},
author = {Lawrence, S and Giles, C L and Tsoi, A C and Back, A D},
doi = {10.1109/72.554195},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Lawrence et al. - 1997 - Face recognition a convolutional neural-network approach(2).pdf:pdf},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
keywords = {Face recognition,Feature extraction,Humans,Image databases,Image sampling,Karhunen-Loeve transforms,Multilayer perceptrons,Neural networks,Quantization,Spatial databases,computational complexity,convolution,convolutional neural-network,dimensionality reduction,face recognition,feature extraction,image matching,invariance,local image sampling,quantisation (signal),quantization,self-organising feature maps,self-organizing map,template matching,topological space,topology},
month = jan,
number = {1},
pages = {98--113},
pmid = {18255614},
shorttitle = {Neural Networks, IEEE Transactions on},
title = {{Face recognition: a convolutional neural-network approach.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18255614},
volume = {8},
year = {1997}
}
@inproceedings{lecun1998,
author = {LeCun, Yann and Bottou, L},
booktitle = {Proceedings of the IEEE},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/LeCun, Bottou - 1998 - Gradient-based learning applied to document recognition(2).pdf:pdf},
pages = {2278----2324},
title = {{Gradient-based learning applied to document recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=726791},
volume = {86},
year = {1998}
}
@article{Lecun2006,
author = {Lecun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato, Marc Aurelio and Huang, Fu Jie},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Lecun et al. - 2006 - A Tutorial on Energy-Based Learning 1 Introduction Energy-Based Models(2).pdf:pdf},
pages = {1--59},
title = {{A Tutorial on Energy-Based Learning 1 Introduction : Energy-Based Models}},
year = {2006}
}
@inproceedings{lecun2010,
author = {LeCun, Yann and Kavukcuoglu, Koray and Farabet, Clement},
booktitle = {International Symposium on Circuits and Systems},
doi = {10.1109/ISCAS.2010.5537907},
file = {::},
isbn = {978-1-4244-5308-5},
keywords = {ConvNets,Filter bank,Learning systems,Machine learning,Mobile robots,Navigation,Object recognition,Optical character recognition software,Unsupervised learning,Video surveillance,Visual perception,biologically-inspired architecture,convolutional networks,feature pooling layers,filter bank,intelligent tasks,internal representations,labeled training samples,machine learning,mobile robots,multilevel hierarchies,object recognition,off-road mobile robots,robot vision,unsupervised learning,vision navigation,visual object recognition},
language = {English},
month = may,
pages = {253--256},
publisher = {IEEE},
title = {{Convolutional networks and applications in vision}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5537907},
year = {2010}
}
@article{Lindenbaum1994,
abstract = {Dennis Gabor is mainly known for the invention of optical holography and the introduction of the so-called Gabor functions in communications. A few people know that he was also interested in image processing. In a paper entitled “Information theory in electron microscopy” (Laboratory Investigation14(6), 801–807 (1965)), written in 1965, he examined the problem of image deblurring and was the first to suggest a method for edge enhancement based on principles widely accepted today and implemented in advanced image processing systems. In this paper his ideas are reviewed, their relation to contemporary methods is shown, and some simulations he could not do in 1965 are performed.},
author = {Lindenbaum, M and Fischer, M and Bruckstein, A},
doi = {10.1016/0031-3203(94)90013-2},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Lindenbaum, Fischer, Bruckstein - 1994 - On Gabor's contribution to image enhancement(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Anisotropic diffusion,Directional filtering,Edge detection,Image enhancement,preprocessing},
mendeley-tags = {preprocessing},
month = jan,
number = {1},
pages = {1--8},
title = {{On Gabor's contribution to image enhancement}},
url = {http://www.sciencedirect.com/science/article/pii/0031320394900132},
volume = {27},
year = {1994}
}
@article{Lippmann1987,
abstract = {Artificial neural net models have been studied for many years in the hope of achieving human-like performance in the fields of speech and image recognition. These models are composed of many nonlinear computational elements operating in parallel and arranged in patterns reminiscent of biological neural nets. Computational elements or nodes are connected via weights that are typically adapted during use to improve performance. There has been a recent resurgence in the field of artificial neural nets caused by new net topologies and algorithms, analog VLSI implementation techniques, and the belief that massive parallelism is essential for high performance speech and image recognition. This paper provides an introduction to the field of artificial neural nets by reviewing six important neural net models that can be used for pattern classification. These nets are highly parallel building blocks that illustrate neural net components and design principles and can be used to construct more complex systems. In addition to describing these nets, a major emphasis is placed on exploring how some existing classification and clustering algorithms can be performed using simple neuron-like components. Single-layer nets can implement algorithms required by Gaussian maximum-likelihood classifiers and optimum minimum-error classifiers for binary patterns corrupted by noise. More generally, the decision regions required by any classification algorithm can be generated in a straightforward manner by three-layer feed-forward nets.},
author = {Lippmann, R.},
doi = {10.1109/MASSP.1987.1165576},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Lippmann - 1987 - An introduction to computing with neural nets(2).pdf:pdf},
issn = {0740-7467},
journal = {IEEE ASSP Magazine},
keywords = {Artificial neural networks,Biological system modeling,Biology computing,Classification algorithms,Clustering algorithms,Concurrent computing,Image recognition,Neural networks},
number = {2},
pages = {4--22},
shorttitle = {ASSP Magazine, IEEE},
title = {{An introduction to computing with neural nets}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1165576},
volume = {4},
year = {1987}
}
@article{Lowe2004a,
abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance. Keywords:},
author = {Lowe, David G. DG G},
file = {::},
journal = {International Journal of Computer Vision},
keywords = {Image matching,Invariant features,Object recognition,Scale invariance,image matching,invariant features,object recognition,scale invariance},
number = {2},
pages = {91--110},
pmid = {20064111},
title = {{Distinctive image features from scale-invariant keypoints}},
url = {http://link.springer.com/article/10.1023/B:VISI.0000029664.99615.94},
volume = {60},
year = {2004}
}
@article{Lu2014,
abstract = {The count of mitotic cells is a critical factor in most cancer grading systems. Extracting the mitotic cell from the histopathological image is a very challenging task. In this paper, we propose an efficient technique for detecting and segmenting the mitotic cells in the high-resolution multispectral image. The proposed technique consists of three main modules: discriminative image generation, mitotic cell candidate detection and segmentation, and mitotic cell candidate classification. In the first module, a discriminative image is obtained by linear discriminant analysis using ten different spectral band images. A set of mitotic cell candidate regions is then detected and segmented by the Bayesian modeling and local-region threshold method. In the third module, a 226 dimension feature is extracted from the mitotic cell candidates and their surrounding regions. An imbalanced classification framework is then applied to perform the classification for the mitotic cell candidates in order to detect the real mitotic cells. The proposed technique has been evaluated on a publicly available dataset of 35 × 10 multispectral images, in which 224 mitotic cells are manually labeled by experts. The proposed technique is able to provide superior performance compared to the existing technique, 81.5\% sensitivity rate and 33.9\% precision rate in terms of detection performance, and 89.3\% sensitivity rate and 87.5\% precision rate in terms of segmentation performance.},
author = {Lu, Cheng and Mandal, Mrinal},
doi = {10.1109/JBHI.2013.2277837},
file = {::},
issn = {2168-2208},
journal = {IEEE journal of biomedical and health informatics},
keywords = {Bayes methods,Bayesian modeling,Cancer,Feature extraction,Histopathological image analysis,Image resolution,Image segmentation,Linear discriminant analysis,Microscopy,Shape,automatic mitotic cell detection,cancer,cancer grading systems,cellular biophysics,detection performance,discriminative image generation,feature extraction,high-resolution multispectral image,image classification,image generation,image resolution,image segmentation,imbalanced classification framework,linear discriminant analysis,local-region threshold method,medical image processing,mitotic cell candidate classification,mitotic cell candidate detection,mitotic cell candidate segmentation,mitotic cell extraction,multispectral histopathological image segmentation,object detection,pattern recognition,precision rate,publicly available dataset,sensitivity,sensitivity rate,spectral band images},
mendeley-tags = {image generation},
month = mar,
number = {2},
pages = {594--605},
pmid = {24608059},
shorttitle = {Biomedical and Health Informatics, IEEE Journal of},
title = {{Toward automatic mitotic cell detection and segmentation in multispectral histopathological images.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24608059},
volume = {18},
year = {2014}
}
@article{Lu2007,
author = {Lu, D. and Weng, Q.},
doi = {10.1080/01431160600746456},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Lu, Weng - 2007 - A survey of image classification methods and techniques for improving classification performance(2).pdf:pdf},
issn = {0143-1161},
journal = {International Journal of Remote Sensing},
month = mar,
number = {5},
pages = {823--870},
title = {{A survey of image classification methods and techniques for improving classification performance}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01431160600746456},
volume = {28},
year = {2007}
}
@article{Luo2014,
abstract = {Distance metric learning (DML) is a critical factor for image analysis and pattern recognition. To learn a robust distance metric for a target task, we need abundant side information (i.e., the similarity/dissimilarity pairwise constraints over the labeled data), which is usually unavailable in practice due to the high labeling cost. This paper considers the transfer learning setting by exploiting the large quantity of side information from certain related, but different source tasks to help with target metric learning (with only a little side information). The state-of-the-art metric learning algorithms usually fail in this setting because the data distributions of the source task and target task are often quite different. We address this problem by assuming that the target distance metric lies in the space spanned by the eigenvectors of the source metrics (or other randomly generated bases). The target metric is represented as a combination of the base metrics, which are computed using the decomposed components of the source metrics (or simply a set of random bases); we call the proposed method, decomposition-based transfer DML (DTDML). In particular, DTDML learns a sparse combination of the base metrics to construct the target metric by forcing the target metric to be close to an integration of the source metrics. The main advantage of the proposed method compared with existing transfer metric learning approaches is that we directly learn the base metric coefficients instead of the target metric. To this end, far fewer variables need to be learned. We therefore obtain more reliable solutions given the limited side information and the optimization tends to be faster. Experiments on the popular handwritten image (digit, letter) classification and challenge natural image annotation tasks demonstrate the effectiveness of the proposed method.},
author = {Luo, Yong and Liu, Tongliang and Tao, Dacheng and Xu, Chao},
doi = {10.1109/TIP.2014.2332398},
file = {::},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
month = sep,
number = {9},
pages = {3789--801},
pmid = {24968169},
title = {{Decomposition-based transfer distance metric learning for image classification.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24968169},
volume = {23},
year = {2014}
}
@article{Meer2012,
abstract = {This paper presents an opinion on research progress in computer vision.},
author = {Meer, Peter},
doi = {10.1016/j.imavis.2011.10.004},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Meer - 2012 - Are we making real progress in computer vision today(2).pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Computer vision,Human vision,computer vision},
mendeley-tags = {computer vision},
month = aug,
number = {8},
pages = {472--473},
title = {{Are we making real progress in computer vision today?}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885612000662},
volume = {30},
year = {2012}
}
@book{Montavon2012,
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-642-35289-8},
editor = {Montavon, Gr\'{e}goire and Orr, Genevi\`{e}ve B. and M\"{u}ller, Klaus-Robert},
isbn = {978-3-642-35288-1},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Neural Networks: Tricks of the Trade}},
url = {http://link.springer.com/10.1007/978-3-642-35289-8},
volume = {7700},
year = {2012}
}
@book{neuralNielsen,
author = {Nielsen, Michael A.},
publisher = {Determination Press},
title = {{Neural Networks and Deep Learning}},
year = {2015}
}
@article{Oliveira,
author = {Oliveira, SRM R M},
file = {::},
journal = {SLIDES},
title = {{Aprendizado com Classes Desbalanceadas}},
url = {http://www.ime.unicamp.br/~wanderson/Aulas/Aula11/MT803-Aula11-Balanceamento-Classes.pdf}
}
@article{Paiva2011,
abstract = {An alternative form to multidimensional projections for the visual analysis of data represented in multidimensional spaces is the deployment of similarity trees, such as Neighbor Joining trees. They organize data objects on the visual plane emphasizing their levels of similarity with high capability of detecting and separating groups and subgroups of objects. Besides this similarity-based hierarchical data organization, some of their advantages include the ability to decrease point clutter; high precision; and a consistent view of the data set during focusing, offering a very intuitive way to view the general structure of the data set as well as to drill down to groups and subgroups of interest. Disadvantages of similarity trees based on neighbor joining strategies include their computational cost and the presence of virtual nodes that utilize too much of the visual space. This paper presents a highly improved version of the similarity tree technique. The improvements in the technique are given by two procedures. The first is a strategy that replaces virtual nodes by promoting real leaf nodes to their place, saving large portions of space in the display and maintaining the expressiveness and precision of the technique. The second improvement is an implementation that significantly accelerates the algorithm, impacting its use for larger data sets. We also illustrate the applicability of the technique in visual data mining, showing its advantages to support visual classification of data sets, with special attention to the case of image classification. We demonstrate the capabilities of the tree for analysis and iterative manipulation and employ those capabilities to support evolving to a satisfactory data organization and classification.},
author = {Paiva, Jose Gustavo S and Florian, Laura and Pedrini, Helio and Telles, Guilherme P. and Minghim, Rosane},
file = {::},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Image Classification,Multidimensional Projections,Similarity Trees},
number = {12},
pages = {2459--2468},
publisher = {IEEE},
title = {{Improved similarity trees and their application to visual data classification}},
volume = {17},
year = {2011}
}
@article{Pal1993,
abstract = {Many image segmentation techniques are available in the literature. Some of these techniques use only the gray level histogram, some use spatial details while others use fuzzy set theoretic approaches. Most of these techniques are not suitable for noisy environments. Some works have been done using the Markov Random Field (MRF) model which is robust to noise, but is computationally involved. Neural network architectures which help to get the output in real time because of their parallel processing ability, have also been used for segmentation and they work fine even when the noise level is very high. The literature on color image segmentation is not that rich as it is for gray tone images. This paper critically reviews and summarizes some of these techniques. Attempts have been made to cover both fuzzy and non-fuzzy techniques including color image segmentation and neural network based approaches. Adequate attention is paid to segmentation of range images and magnetic resonance images. It also addresses the issue of quantitative evaluation of segmentation results.},
author = {Pal, Nikhil R and Pal, Sankar K},
doi = {10.1016/0031-3203(93)90135-J},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Pal, Pal - 1993 - A review on image segmentation techniques(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Clustering,Edge detection,Fuzzy sets,Image segmentation,Markov Random Field,Relaxation,Thresholding,preprocessing},
mendeley-tags = {preprocessing},
month = sep,
number = {9},
pages = {1277--1294},
title = {{A review on image segmentation techniques}},
url = {http://www.sciencedirect.com/science/article/pii/003132039390135J},
volume = {26},
year = {1993}
}
@article{Papari2011,
abstract = {We present an overview of various edge and line oriented approaches to contour detection that have been proposed in the last two decades. By edge and line oriented we mean methods that do not rely on segmentation. Distinction is made between edges and contours. Contour detectors are divided in local and global operators. The former are mainly based on differential analysis, statistical approaches, phase congruency, rank order filters, and combinations thereof. The latter include computation of contour saliency, perceptual grouping, relaxation labeling and active contours. Important aspects are covered, such as preprocessing aimed to suppress texture and noise, multiresolution techniques, connections between computational models and properties of the human visual system, and use of shape priors. An overview of procedures and metrics for quantitative performance evaluation is also presented. Our main conclusion is that contour detection has reached high degree of sophistication, taking into account multimodal contour definition (by luminance, color or texture changes), mechanisms for reducing the contour masking influence of noise and texture, perceptual grouping, multiscale aspects and high-level vision information.},
author = {Papari, Giuseppe and Petkov, Nicolai},
doi = {10.1016/j.imavis.2010.08.009},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Papari, Petkov - 2011 - Edge and line oriented contour detection State of the art(2).pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Closure,Contour detection,Contour salience,Gestalt grouping,Local pattern analysis,Performance evaluation,Preprocessing,Scale–space,contour detection},
mendeley-tags = {contour detection},
month = feb,
number = {2-3},
pages = {79--103},
title = {{Edge and line oriented contour detection: State of the art}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885610001253},
volume = {29},
year = {2011}
}
@inproceedings{acc,
address = {New York, USA},
author = {Pass, Greg and Zabih, Ramin and Miller, Justin},
booktitle = {Proceedings of the fourth ACM international conference on Multimedia},
doi = {10.1145/244130.244148},
isbn = {0897918711},
keywords = {color histograms,content-based image retrieval,processing},
month = feb,
pages = {65--73},
publisher = {ACM Press},
title = {{Comparing images using color coherence vectors}},
url = {http://dl.acm.org/citation.cfm?id=244130.244148},
year = {1996}
}
@article{Peng2014,
abstract = {Recent studies witness the success of Bag-of-Features (BoF) frameworks for video based human action recognition. The detection and description of local interest regions are two fundamental problems in BoF framework. In this paper, we propose a motion boundary based sampling strategy and spatial-temporal (3D) co-occurrence descriptors for action video representation and recognition. Our sampling strategy is partly inspired by the recent success of dense trajectory (DT) based features [Wang et al., 2013] for action recognition. Compared with DT, we densely sample spatial-temporal cuboids along a motion boundary which can greatly reduce the number of valid trajectories and preserve the discriminative power. Moreover, we develop a set of 3D co-occurrence descriptors which take account of the spatial-temporal context within local cuboids and deliver rich information for recognition. Furthermore, we decompose each 3D co-occurrence descriptor at pixel level and bin level and integrate the decomposed components with a multi-channel framework, which can improve the performance significantly. To evaluate the proposed methods, we conduct extensive experiments on three benchmarks including KTH, YouTube and HMDB51. The results show that our sampling strategy significantly reduces the computational cost of point tracking without degrading performance. Meanwhile, we achieve superior performance than the state-of-the-art methods. We report 95.6\% on KTH, 87.6\% on YouTube and 51.8\% on HMDB51.},
author = {Peng, Xiaojiang and Qiao, Yu and Peng, Qiang},
doi = {10.1016/j.imavis.2014.06.011},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Peng, Qiao, Peng - 2014 - Motion boundary based sampling and 3D co-occurrence descriptors for action recognition(2).pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {3D co-occurrence descriptors,Action recognition,Bag of Features,Dense trajectory,Motion boundary},
month = sep,
number = {9},
pages = {616--628},
title = {{Motion boundary based sampling and 3D co-occurrence descriptors for action recognition}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885614001103},
volume = {32},
year = {2014}
}
@article{Peng2014,
abstract = {Deep convolutional neural networks learn extremely powerful image representations, yet most of that power is hidden in the millions of deep-layer parameters. What exactly do these parameters represent? Recent work has started to analyse CNN representations, finding that, e.g., they are invariant to some 2D transformations, but are confused by particular types of image noise. In this paper, we delve deeper and ask: how invariant are CNNs to object-class variations caused by 3D shape, pose, and photorealism? These invariance properties are difficult to analyse using traditional data, so we propose an approach that renders synthetic data from freely available 3D CAD models. Using our approach we can easily generate an infinite amount of training images for almost any object. We explore the invariance of CNNs to various intra-class variations by simulating different rendering conditions, with surprising findings. Based on these results, we propose an optimal synthetic data generation strategy for training object detectors from CAD models. We show that our Virtual CNN approach significantly outperforms previous methods for learning object detectors from synthetic data on the benchmark PASCAL VOC2007 dataset.},
archivePrefix = {arXiv},
arxivId = {1412.7122},
author = {Peng, Xingchao and Sun, Baochen and Ali, Karim and Saenko, Kate},
eprint = {1412.7122},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Peng et al. - 2014 - Exploring Invariances in Deep Convolutional Neural Networks Using Synthetic Images(2).pdf:pdf},
month = dec,
title = {{Exploring Invariances in Deep Convolutional Neural Networks Using Synthetic Images}},
url = {http://arxiv.org/abs/1412.7122},
year = {2014}
}
@inproceedings{Perronnin2010,
address = {Crete, Greece},
author = {Perronnin, Florent and Dance, C},
booktitle = {European Conference on Computer Vision},
doi = {10.1007/978-3-642-15561-1\_11},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Perronnin, Dance - 2010 - Improving the Fisher Kernel for Large-Scale Image Classification.pdf:pdf},
pages = {143--156},
publisher = {Springer Berlin Heidelberg},
title = {{Improving the Fisher Kernel for Large-Scale Image Classification}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-15561-1\_11},
year = {2010}
}
@inproceedings{Perronnin2007,
address = {Minneapolis, MN},
author = {Perronnin, Florent and Dance, Christopher},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2007.383266},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Perronnin, Dance - 2007 - Fisher kernels on visual vocabularies for image categorization.pdf:pdf},
pages = {1--8},
publisher = {IEEE},
title = {{Fisher kernels on visual vocabularies for image categorization}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4270291},
year = {2007}
}
@article{Petrou2012,
abstract = {It is argued that robotic platforms are the way forward towards building intelligent systems, where multiple sensors and manipulation are used for cognitive processes. It is also argued that the cue for developing the right architecture for such a system is human language.},
author = {Petrou, Maria},
doi = {10.1016/j.imavis.2011.10.005},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Petrou - 2012 - The road to intelligence(2).pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Human language,Intelligent systems,System architecture,Tower of knowledge},
month = aug,
number = {8},
pages = {474--475},
title = {{The road to intelligence}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885612000716},
volume = {30},
year = {2012}
}
@inproceedings{Picon2011,
author = {Picon, CT T and Rossi, Isadora and Jr, MP Ponti Ponti},
booktitle = {Workshop of Undergraduate Works},
file = {::},
keywords = {-reconhecimento de padr\~{o}es,abstract,classifica\c{c}\~{a}o de ima-,descritores de cor,feature extraction and classification,gens,involves choices in,pattern recognition in images,steps of acquisition,the},
publisher = {SIBGRAPI},
title = {{An\'{a}lise da classifica\c{c}\~{a}o de imagens por descritores de cor utilizando v\'{a}rias resolu\c{c}\~{o}es}},
url = {http://www.icmc.usp.br/~moacir/papers/Picon\_WUW2011.pdf},
year = {2011}
}
@article{Polesel2000,
abstract = {This paper presents a new method for unsharp masking for contrast enhancement of images. The approach employs an adaptive filter that controls the contribution of the sharpening path in such a way that contrast enhancement occurs in high detail areas and little or no image sharpening occurs in smooth areas.},
author = {Polesel, Andrea and Ramponi, Giovanni and Mathews, V. John},
doi = {10.1109/83.826787},
file = {::},
issn = {1057-7149},
journal = {IEEE transactions on image processing},
month = jan,
number = {3},
pages = {505--10},
pmid = {18255421},
title = {{Image enhancement via adaptive unsharp masking.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18255421},
volume = {9},
year = {2000}
}
@article{Ponti2013,
abstract = {The development of low-cost remote sensing systems is important in small agriculture business, particularly in developing countries, to allow feasible use of images to gather information. However, images obtained through such systems with uncalibrated cameras have often illumination variations, shadows, and other elements that can hinder the analysis by image processing techniques. This letter investigates the combination of vegetation indices (color index of vegetation extraction, visual vegetation index, and excess green) and the mean-shift algorithm, based on the local density estimation in the color space on images acquired by a low-cost system. The objective is to detect green coverage, gaps, and degraded areas. The results showed that combining local density estimation and vegetation indices improves the segmentation accuracy when compared with the competing methods. It deals well with images in different conditions and with regions of imbalanced sizes, confirming the practical application of the low-cost system.},
author = {Ponti, Moacir P.},
doi = {10.1109/LGRS.2012.2193113},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Ponti - 2013 - Segmentation of Low-Cost Remote Sensing Images Combining Vegetation Indices and Mean Shift(2).pdf:pdf},
issn = {1545-598X},
journal = {Geoscience and Remote Sensing Letters},
keywords = {Accuracy,Agriculture,Image color analysis,Image segmentation,Indexes,Remote sensing,Vegetation mapping,precision agriculture,preprocessing,segmentation,vegetation indices},
mendeley-tags = {preprocessing,segmentation},
month = jan,
number = {1},
pages = {67--70},
publisher = {IEEE},
shorttitle = {Geoscience and Remote Sensing Letters, IEEE},
title = {{Segmentation of Low-Cost Remote Sensing Images Combining Vegetation Indices and Mean Shift}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6202674},
volume = {10},
year = {2013}
}
@inproceedings{Ponti-Jr2013,
address = {Austin, TX, Estados Unidos},
author = {Ponti, Moacir and Escobar, Luciana},
booktitle = {Global Conference on Signal and Information Processing},
doi = {10.1109/GlobalSIP.2013.6737000},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Ponti, Escobar - 2013 - Compact color features with bitwise quantization and reduced resolution for mobile processing.pdf:pdf},
pages = {751--754},
title = {{Compact color features with bitwise quantization and reduced resolution for mobile processing}},
url = {http://link.springer.com/article/10.1007/s11760-011-0216-x},
year = {2013}
}
@article{Ponti-Jr2011,
author = {Ponti, Moacir and Mascarenhas, Nelson and Ferreira, Paulo and Suazo, Claudio},
doi = {10.1007/s11760-011-0216-x},
file = {::},
issn = {1863-1703},
journal = {Signal, Image and Video Processing},
keywords = {computational optical,filtered extrapolation,image restoration,sectioning microscopy},
month = feb,
number = {1},
pages = {1--10},
title = {{Three-dimensional noisy image restoration using filtered extrapolation and deconvolution}},
url = {http://link.springer.com/10.1007/s11760-011-0216-x http://link.springer.com/article/10.1007/s11760-011-0216-x},
volume = {7},
year = {2011}
}
@article{Ponti,
author = {Ponti, Moacir and Nazar, Tiago S and Thum, Gabriela S},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Ponti, Nazar, Thum - Unknown - Image quantization as a dimensionality reduction procedure in color and texture feature extraction(2).pdf:pdf},
keywords = {br,compact features extraction,email addresses,gabithume,gabriela s,image quantization,moacir ponti,pca,ponti,usp},
title = {{Image quantization as a dimensionality reduction procedure in color and texture feature extraction}}
}
@article{Ponti2010,
author = {Ponti, MP P},
file = {::},
journal = {Nature-Inspired Computing Design, Development, and Applications},
keywords = {automatic segmentation,deconvolution,image analysis},
publisher = {IGI Global},
title = {{Microscope volume segmentation improved through non-linear restoration}},
url = {http://www.igi-global.com/article/microscope-segmentation-improved-through-non/52614},
year = {2012}
}
@incollection{Prati2004,
author = {Prati, RC R.C. C R C and Batista, G.E. GE E G E and Monard, MC M.C. C M C},
booktitle = {MICAI 2004: Advances in Artificial Intelligence},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Prati, Batista, Monard - 2004 - Class imbalances versus class overlapping an analysis of a learning system behavior(3).pdf:pdf},
pages = {312--321},
publisher = {Springer Berlin Heidelberg},
title = {{Class imbalances versus class overlapping: an analysis of a learning system behavior}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-24694-7\_32 http://download.springer.com/static/pdf/643/chp:10.1007/978-3-540-24694-7\_32.pdf?auth66=1413225006\_a0c4923c4afec687226c795df4981889\&ext=.pdf http://download.springer.com/static/pdf/643/chp\%3A10.1007\%2F978-3-540-24694-7\_32.pdf?auth66=1413225006\_a0c4923c4afec687226c795df4981889\&ext=.pdf},
year = {2004}
}
@article{Ramanath2005,
author = {Ramanath, R and Snyder, WE E},
file = {::},
journal = {IEEE SIGNAL PROCESSING MAGAZINE},
number = {January},
pages = {34--43},
title = {{Color image processing pipeline}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1407713},
year = {2005}
}
@article{Rehman2012,
author = {Rehman, Amjad and Saba, Tanzila},
doi = {10.1007/s10462-012-9337-z},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Rehman, Saba - 2012 - Neural networks for document image preprocessing state of the art(2).pdf:pdf},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
month = apr,
number = {2},
pages = {253--273},
title = {{Neural networks for document image preprocessing: state of the art}},
url = {http://link.springer.com/10.1007/s10462-012-9337-z},
volume = {42},
year = {2012}
}
@article{Rocha2010,
abstract = {Contemporary Vision and Pattern Recognition problems such as face recognition, fingerprinting identification, image categorization, and DNA sequencing often have an arbitrarily large number of classes and properties to consider. To deal with such complex problems using just one feature descriptor is a difficult task and feature fusion may become mandatory. Although normal feature fusion is quite effective for some problems, it can yield unexpected classification results when the different features are not properly normalized and preprocessed. Besides it has the drawback of increasing the dimensionality which might require more training data. To cope with these problems, this paper introduces a unified approach that can combine many features and classifiers that requires less training and is more adequate to some problems than a na\"{\i}ve method, where all features are simply concatenated and fed independently to each classification algorithm. Besides that, the presented technique is amenable to continuous learning, both when refining a learned model and also when adding new classes to be discriminated. The introduced fusion approach is validated using a multi-class fruit-and-vegetable categorization task in a semi-controlled environment, such as a distribution center or the supermarket cashier. The results show that the solution is able to reduce the classification error in up to 15 percentage points with respect to the baseline.},
author = {Rocha, Anderson and Hauagge, Daniel C. and Wainer, Jacques and Goldenstein, Siome},
doi = {10.1016/j.compag.2009.09.002},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Rocha et al. - 2010 - Automatic fruit and vegetable classification from images(2).pdf:pdf},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {Automatic produce classification,Feature and classifier fusion,Image classification,Multi-class from binary},
month = jan,
number = {1},
pages = {96--104},
title = {{Automatic fruit and vegetable classification from images}},
url = {http://www.sciencedirect.com/science/article/pii/S016816990900180X},
volume = {70},
year = {2010}
}
@article{Saliba,
author = {SALIBA, E and DIPANDA, A},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/SALIBA, DIPANDA - 2013 - An overview of Pattern Recognition.pdf:pdf},
journal = {wikiprogress. org},
keywords = {classification,feature extraction,pattern recognition,preprocessing},
pages = {1--7},
title = {{An overview of Pattern Recognition}},
url = {http://www.wikiprogress.org/images/An\_overview\_of\_Pattern\_Recognition.pdf},
year = {2013}
}
@inproceedings{Sato2014a,
abstract = {Recently, methods for the unsupervised learning of features from large data sets have been attracting much attention. These methods have been especially successful in the area of computer vision. However, there is a problem that it is difficult to determine what kind of features will result in a high classification performance. Indeed, the difficulty of determining the learning parameters is a widely known problem in the field of feature learning. To address this problem, this paper presents a feature-learning method which uses classification results to progressively learn multiple features of varied complexity. The proposed method enables the learning of both simple robust features and complex features which represents difficult patterns. In addition, we assign regularization weights that are based on the complexity of the features. This modification emphasizes simple representation and prevents over fitting. Experimental results with medical image classification show that the proposed method is superior to the conventional method, especially when classification is difficult.},
author = {Sato, Yoshikuni and Kozuka, Kazuki and Sawada, Yoshihide and Kiyono, Masaki},
booktitle = {2014 22nd International Conference on Pattern Recognition},
doi = {10.1109/ICPR.2014.580},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Sato et al. - 2014 - Learning Multiple Complex Features Based on Classification Results(2).pdf:pdf},
isbn = {978-1-4799-5209-0},
issn = {1051-4651},
keywords = {Accuracy,Complexity theory,Computed tomography,Diseases,Feature extraction,Feature learning,Machine learning,Medical imaging,Training,Vectors,classification results,computer vision,feature-learning method,large data sets,learning parameters,medical image classification,medical image processing,multiple complex features learning,pattern classification,regularization weights,unsupervised learning},
month = aug,
pages = {3369--3373},
publisher = {IEEE},
shorttitle = {Pattern Recognition (ICPR), 2014 22nd Internationa},
title = {{Learning Multiple Complex Features Based on Classification Results}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6977292},
year = {2014}
}
@article{Schmidhuber2014,
abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
archivePrefix = {arXiv},
arxivId = {1404.7828},
author = {Schmidhuber, J\"{u}rgen},
doi = {10.1016/j.neunet.2014.09.003},
eprint = {1404.7828},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Schmidhuber - 2014 - Deep learning in neural networks An overview(2).pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
month = oct,
pages = {88},
title = {{Deep learning in neural networks: An overview}},
url = {http://arxiv.org/abs/1404.7828},
year = {2014}
}
@inproceedings{Simonyan2013,
abstract = {This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [Erhan et al., 2009], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [Zeiler et al., 2013].},
archivePrefix = {arXiv},
arxivId = {1312.6034},
author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
booktitle = {ICLR Workshop},
eprint = {1312.6034},
file = {::},
month = dec,
pages = {1--8},
title = {{Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps}},
url = {http://arxiv.org/abs/1312.6034},
year = {2013}
}
@article{Simonyan2014,
abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
archivePrefix = {arXiv},
arxivId = {1409.1556},
author = {Simonyan, Karen and Zisserman, Andrew},
eprint = {1409.1556},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Simonyan, Zisserman - 2014 - Very Deep Convolutional Networks for Large-Scale Image Recognition(2).pdf:pdf},
month = sep,
title = {{Very Deep Convolutional Networks for Large-Scale Image Recognition}},
url = {http://arxiv.org/abs/1409.1556},
year = {2014}
}
@article{Sklansky1978,
abstract = {An overview of present computer techniques of partitioning continuous-tone images into meaningful segments and of characterizing these segments by sets of "features" is presented. Segmentation often consists of two methods:boundary detection and texture analysis. Both of these are discussed. The design of the segmenter and feature extractor are intimately related to the design of the rest of the image analysis system\^{A}¿particularly the preprocessor and the classifier. Toward aiding this design, a few guidelines and illustrative examples are included.},
author = {Sklansky, Jack},
doi = {10.1109/TSMC.1978.4309944},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Sklansky - 1978 - Image Segmentation and Feature Extraction(2).pdf:pdf},
issn = {0018-9472},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
keywords = {Biomedical imaging,Computer vision,Detectors,Feature extraction,Guidelines,Image analysis,Image segmentation,Image texture analysis,Labeling,Layout,feature extraction,preprocessing,segmentation},
mendeley-tags = {feature extraction,preprocessing,segmentation},
number = {4},
pages = {237--247},
shorttitle = {Systems, Man and Cybernetics, IEEE Transactions on},
title = {{Image Segmentation and Feature Extraction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4309944},
volume = {8},
year = {1978}
}
@article{Smith1997,
abstract = {This paper describes a new approach to low level image processing; in particular, edge and corner detection and structure preserving noise reduction. Non-linear ﬁltering is used to deﬁne which parts of the image are closely related to each individual pixel; each pixel has associated with it a local image region which is of similar brightness to that pixel. The new feature detectors are based on the minimization of this local image region, and the noise reduction method uses this region as the smoothing neighbourhood. The resulting methods are accurate, noise resistant and fast. Details of the new feature detectors and of the new noise reduction method are described, along with test results.},
author = {Smith, SM M and Brady, JM M},
file = {::},
journal = {International journal of computer vision},
number = {1},
pages = {45--78},
title = {{SUSAN—a new approach to low level image processing}},
url = {http://link.springer.com/article/10.1023/A:1007963824710},
volume = {23},
year = {1997}
}
@article{Soda2011,
abstract = {Class imbalance limits the performance of most learning algorithms since they cannot cope with large differences between the number of samples in each class, resulting in a low predictive accuracy over the minority class. In this respect, several papers proposed algorithms aiming at achieving more balanced performance. However, balancing the recognition accuracies for each class very often harms the global accuracy. Indeed, in these cases the accuracy over the minority class increases while the accuracy over the majority one decreases. This paper proposes an approach to overcome this limitation: for each classification act, it chooses between the output of a classifier trained on the original skewed distribution and the output of a classifier trained according to a learning method addressing the course of imbalanced data. This choice is driven by a parameter whose value maximizes, on a validation set, two objective functions, i.e. the global accuracy and the accuracies for each class. A series of experiments on ten public datasets with different proportions between the majority and minority classes show that the proposed approach provides more balanced recognition accuracies than classifiers trained according to traditional learning methods for imbalanced data as well as larger global accuracy than classifiers trained on the original skewed distribution.},
author = {Soda, Paolo},
doi = {10.1016/j.patcog.2011.01.015},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Soda - 2011 - A multi-objective optimisation approach for class imbalance learning(2).pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Class imbalance learning,Machine learning,Multi-objective optimisation,Pattern recognition},
month = aug,
number = {8},
pages = {1801--1810},
title = {{A multi-objective optimisation approach for class imbalance learning}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320311000410},
volume = {44},
year = {2011}
}
@article{Sokolova2009,
author = {Sokolova, Marina and Lapalme, Guy},
doi = {10.1016/j.ipm.2009.03.002},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Sokolova, Lapalme - 2009 - A systematic analysis of performance measures for classification tasks(2).pdf:pdf},
issn = {03064573},
journal = {Information Processing \& Management},
keywords = {performance evaluation},
month = jul,
number = {4},
pages = {427--437},
publisher = {Elsevier Ltd},
title = {{A systematic analysis of performance measures for classification tasks}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0306457309000259},
volume = {45},
year = {2009}
}
@inproceedings{Sotiropoulos2012,
abstract = {In this paper, we compare the performance of Artificial Immune System (AIS)-based classification algorithms to the performance of Gaussian kernel-based Support Vector Machines (SVM) in problems with a high degree of class imbalance. Our experimentation indicates that the AIS-based classification paradigm has the intrinsic properly of dealing more efficiently with highly skewed datasets. Specifically, our experimental results indicate that AIS-based classifiers identify instances from the minority class quite efficiently.},
author = {Sotiropoulos, Dionysios N. and Tsihrintzis, George A.},
booktitle = {Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing},
doi = {10.1109/IIH-MSP.2012.39},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Sotiropoulos, Tsihrintzis - 2012 - Artificial Immune System-based Classification in Class-Imbalanced Image Classification Problems(2).pdf:pdf},
isbn = {978-1-4673-1741-2},
keywords = {AIS-based classification algorithms,Artificial Immune Systems,Classification algorithms,Gaussian kernel-based support vector machines,Immune system,Machine learning,Machine learning algorithms,SVM,Support vector machines,Training,Vectors,artificial immune system-based classification,artificial immune systems,class imbalance,class-imbalanced image classification problems,image classification,imbalanced,minority class,support vector machines},
mendeley-tags = {imbalanced},
month = jul,
pages = {138--141},
publisher = {IEEE},
shorttitle = {Intelligent Information Hiding and Multimedia Sign},
title = {{Artificial Immune System-based Classification in Class-Imbalanced Image Classification Problems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6274632},
year = {2012}
}
@inproceedings{bic,
address = {New York, USA},
author = {Stehling, Renato O. and Nascimento, Mario A. and Falc\~{a}o, Alexandre X.},
booktitle = {Proceedings of the eleventh international conference on Information and knowledge management},
doi = {10.1145/584792.584812},
isbn = {1581134924},
keywords = {CBIR,color histogram,content-based image retrieval,distance function,image analysis},
month = nov,
pages = {102--109},
publisher = {ACM Press},
title = {{A compact and efficient image retrieval approach based on border/interior pixel classification}},
url = {http://dl.acm.org/citation.cfm?id=584792.584812},
year = {2002}
}
@article{Szegedy2014,
abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
archivePrefix = {arXiv},
arxivId = {1409.4842},
author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
eprint = {1409.4842},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Szegedy et al. - 2014 - Going Deeper with Convolutions(2).pdf:pdf},
month = sep,
pages = {1--12},
title = {{Going Deeper with Convolutions}},
url = {http://arxiv.org/abs/1409.4842v1 http://arxiv.org/abs/1409.4842},
year = {2014}
}
@article{Talebi2014,
abstract = {In this paper, we introduce a new image editing tool based on the spectrum of a global filter computed from image affinities. Recently, it has been shown that the global filter derived from a fully connected graph representing the image can be approximated using the Nystr\"{o}m extension. This filter is computed by approximating the leading eigenvectors of the filter. These orthonormal eigenfunctions are highly expressive of the coarse and fine details in the underlying image, where each eigenvector can be interpreted as one scale of a data-dependent multiscale image decomposition. In this filtering scheme, each eigenvalue can boost or suppress the corresponding signal component in each scale. Our analysis shows that the mapping of the eigenvalues by an appropriate polynomial function endows the filter with a number of important capabilities, such as edge-aware sharpening, denoising, tone manipulation, and abstraction, to name a few. Furthermore, the edits can be easily propagated across the image.},
author = {Talebi, Hossein and Milanfar, Peyman},
doi = {10.1109/TIP.2014.2348870},
file = {::},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
month = oct,
number = {10},
pages = {4460--73},
pmid = {25148666},
title = {{Nonlocal image editing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25148666},
volume = {23},
year = {2014}
}
@article{Tan2012,
abstract = {Noisy iris recognition under visible lighting has recently drawn much attention. This paper proposes an effective method for visible light iris image matching by using multiple characteristics of iris and eye images. The method consists of image preprocessing, iris data matching, eye data matching, and multi-modal fusion. Ordinal measures and color analysis are adopted for iris data matching, and texton representation and semantic information are used for eye data matching. After we obtain the four matching scores, a robust score level fusion strategy is applied to generate the dissimilarity measure of the two images under consideration. Extensive experiments on the UBIRIS.v2 database and the NICE.II training dataset demonstrate that the proposed method is effective. Our method significantly outperforms all other algorithms submitted to the Noisy Iris Challenge Evaluation-Part II (NICE.II), an open contest in noisy iris image matching.},
author = {Tan, Tieniu and Zhang, Xiaobo and Sun, Zhenan and Zhang, Hui},
doi = {10.1016/j.patrec.2011.08.009},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Tan et al. - 2012 - Noisy iris image matching by using multiple cues(2).pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Eye data matching,Iris data matching,Iris recognition,Noisy iris image matching,Robust fusion,Visible lighting,preprocessing},
mendeley-tags = {preprocessing},
month = jun,
number = {8},
pages = {970--977},
title = {{Noisy iris image matching by using multiple cues}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865511002601},
volume = {33},
year = {2012}
}
@article{Tan2010,
author = {Tan, Xiaoyang and Triggs, Bill},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Tan, Triggs - 2010 - Enhanced Local Texture Feature Sets for Face Recognition Under Difficult Lighting Conditions.pdf:pdf},
journal = {IEEE transactions on image processing},
number = {6},
pages = {1635--1650},
title = {{Enhanced Local Texture Feature Sets for Face Recognition Under Difficult Lighting Conditions}},
volume = {19},
year = {2010}
}
@article{Tanimoto1975,
abstract = {In order to speed up several picture processing operations, including edge detection, a “pyramid” (hierarchy of fine to coarse resolution versions of a picture) is produced. The low spatial frequencies preserved in coarse pictures are helpful in finding regions of interest in fine pictures at law cost. Tree structure properties of the pyramid are investigated as well as the transfer function of the compression transformation. A recursive “refining” algorithm is given for edge detection. Its computational savings are demonstrated both theoretically and in practical examples.},
author = {Tanimoto, S. and Pavlidis, T.},
doi = {10.1016/S0146-664X(75)80003-7},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Tanimoto, Pavlidis - 1975 - A hierarchical data structure for picture processing(2).pdf:pdf},
issn = {0146664X},
journal = {Computer Graphics and Image Processing},
month = jun,
number = {2},
pages = {104--119},
title = {{A hierarchical data structure for picture processing}},
url = {http://www.sciencedirect.com/science/article/pii/S0146664X75800037},
volume = {4},
year = {1975}
}
@article{Taylor2010,
author = {Taylor, GW W and Fergus, Rob and LeCun, Y and Bregler, Christoph},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Taylor et al. - 2010 - Convolutional learning of spatio-temporal features(2).pdf:pdf},
journal = {Computer Vision–ECCV 2010},
keywords = {activity recognition,con-,optical flow,restricted boltzmann machines,unsupervised learning,video analysis,volutional nets},
title = {{Convolutional learning of spatio-temporal features}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-15567-3\_11},
year = {2010}
}
@article{Tompson2014,
abstract = {Recent state-of-the-art performance on human-body pose estimation has been achieved with Deep Convolutional Networks (ConvNets). Traditional ConvNet architectures include pooling layers which reduce computational requirements, introduce invariance and prevent over-training. These benefits of pooling come at the cost of reduced localization accuracy. We introduce a novel architecture which includes an efficient 'position refinement' model that is trained to estimate the joint offset location within a small region of the image. This refinement model is jointly trained in cascade with a state-of-the-art ConvNet model to achieve improved accuracy in human joint location estimation. We show that the variance of our detector approaches the variance of human annotations on the FLIC dataset and outperforms all existing approaches on the MPII-human-pose dataset.},
archivePrefix = {arXiv},
arxivId = {1411.4280},
author = {Tompson, Jonathan and Goroshin, Ross and Jain, Arjun and LeCun, Yann and Bregler, Christopher},
eprint = {1411.4280},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Tompson et al. - 2014 - Efficient Object Localization Using Convolutional Networks(2).pdf:pdf},
month = nov,
pages = {8},
title = {{Efficient Object Localization Using Convolutional Networks}},
url = {http://arxiv.org/abs/1411.4280},
year = {2014}
}
@article{Trussell2005,
author = {Trussell, HJ J and Saber, E and Vrhel, M},
file = {::},
journal = {IEEE Signal Processing Magazine},
title = {{Color image processing: Basics and special issue overview}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:No+Title\#0 http://www.google.com/patents/US5636290 https://ritdml.rit.edu/handle/1850/9013},
year = {2005}
}
@article{Turk1991,
abstract = {We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as "eigenfaces," because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture.},
author = {Turk, M and Pentland, a},
doi = {10.1162/jocn.1991.3.1.71},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Turk, Pentland - 1991 - Eigenfaces for recognition(2).pdf:pdf},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
month = jan,
number = {1},
pages = {71--86},
pmid = {23964806},
title = {{Eigenfaces for recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23964806},
volume = {3},
year = {1991}
}
@inproceedings{VanHulse2007,
address = {New York, New York, USA},
author = {{Van Hulse}, Jason and Khoshgoftaar, Taghi M. and Napolitano, Amri},
booktitle = {Proceedings of the 24th international conference on Machine learning},
doi = {10.1145/1273496.1273614},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Van Hulse, Khoshgoftaar, Napolitano - 2007 - Experimental perspectives on learning from imbalanced data(2).pdf:pdf},
isbn = {9781595937933},
month = jun,
pages = {935--942},
publisher = {ACM Press},
title = {{Experimental perspectives on learning from imbalanced data}},
url = {http://dl.acm.org/citation.cfm?id=1273496.1273614},
year = {2007}
}
@article{Vidal2012,
abstract = {Hyperspectral Imaging is an essential technique to deep explore surfaces in which more detail than the one provided by the single point spectroscopy is needed. Many devices for acquiring hyperspectral images have been manufactured and there is an increasing interest for improving the data analysis techniques applied to such complex datasets. Regardless the instrumentation, the acquisition of the images is being constantly improved by setting faster and more robust detectors, including new cooling systems or improving the light sources. Nevertheless, there are several issues that must be handled before starting the data analysis of any sample (e.g. background removal, compression of the images, spiked points, dead pixels, etc.). Therefore, the step of image pre-processing is almost always required. The aim of this paper is to show the application of some of the most common possibilities to solve the above mentioned issues before the image processing. This is done in a practical way, providing examples of their application, pros and cons as well as their implementation. For this purpose, several real examples (pharmaceutical tablets and food stuff) have been used throughout this manuscript.},
author = {Vidal, Maider and Amigo, Jos\'{e} Manuel},
doi = {10.1016/j.chemolab.2012.05.009},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Vidal, Amigo - 2012 - Pre-processing of hyperspectral images. Essential steps before image analysis(2).pdf:pdf},
issn = {01697439},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {Background removal,Hyperspectral,Near Infrared,Pre-processing,Raman,Spikes,Wavelets,preprocessing},
mendeley-tags = {preprocessing},
month = aug,
pages = {138--148},
title = {{Pre-processing of hyperspectral images. Essential steps before image analysis}},
url = {http://www.sciencedirect.com/science/article/pii/S0169743912001220},
volume = {117},
year = {2012}
}
@inproceedings{Viola2001,
abstract = {This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the "integral image" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.},
author = {Viola, P. and Jones, M.},
booktitle = {Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},
doi = {10.1109/CVPR.2001.990517},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Viola, Jones - 2001 - Rapid object detection using a boosted cascade of simple features(2).pdf:pdf},
isbn = {0-7695-1272-0},
issn = {1063-6919},
keywords = {AdaBoost,Detectors,Face detection,Filters,Focusing,Image representation,Machine learning,Object detection,Pixel,Robustness,Skin,background regions,boosted simple feature cascade,classification,classifiers,face detection,feature extraction,image classification,image processing,image representation,integral image,learning (artificial intelligence),machine learning,object detection,object specific focus-of-attention mechanism,rapid object detection,real-time applications,statistical guarantees,visual object detection},
mendeley-tags = {classification},
pages = {I--511--I--518},
publisher = {IEEE Comput. Soc},
shorttitle = {Computer Vision and Pattern Recognition, 2001. CVP},
title = {{Rapid object detection using a boosted cascade of simple features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=990517},
volume = {1},
year = {2001}
}
@inproceedings{Wang2010,
abstract = {The traditional SPM approach based on bag-of-features (BoF) requires nonlinear classifiers to achieve good image classification performance. This paper presents a simple but effective coding scheme called Locality-constrained Linear Coding (LLC) in place of the VQ coding in traditional SPM. LLC utilizes the locality constraints to project each descriptor into its local-coordinate system, and the projected coordinates are integrated by max pooling to generate the final representation. With linear classifier, the proposed approach performs remarkably better than the traditional nonlinear SPM, achieving state-of-the-art performance on several benchmarks. Compared with the sparse coding strategy [22], the objective function used by LLC has an analytical solution. In addition, the paper proposes a fast approximated LLC method by first performing a K-nearest-neighbor search and then solving a constrained least square fitting problem, bearing computational complexity of O(M + K2). Hence even with very large codebooks, our system can still process multiple frames per second. This efficiency significantly adds to the practical values of LLC for real applications.},
author = {Wang, Jinjun and Yang, Jianchao and Yu, Kai and Lv, Fengjun and Huang, Thomas and Gong, Yihong},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5540018},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Wang et al. - 2010 - Locality-constrained Linear Coding for image classification(2).pdf:pdf},
isbn = {978-1-4244-6984-0},
issn = {1063-6919},
keywords = {Image classification,Image coding,K-nearest-neighbor search,VQ coding,bag-of-features,computational complexity,constrained least square fitting problem,image classification,image coding,image matching,learning (artificial intelligence),least squares approximations,locality-constrained linear coding,nonlinear classifiers,sparse coding strategy,spatial pyramid matching,vector quantisation},
month = jun,
pages = {3360--3367},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Locality-constrained Linear Coding for image classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5540018},
year = {2010}
}
@article{Wang2009,
abstract = {By combining Histograms of Oriented Gradients (HOG) and Local Binary Pattern (LBP) as the feature set, we propose a novel human detection approach capable of handling partial occlusion. Two kinds of detectors, i.e., global detector for whole scanning windows and part detectors for local regions, are learned from the training data using linear SVM. For each ambiguous scanning window, we construct an occlusion likelihood map by using the response of each block of the HOG feature to the global detector. The occlusion likelihood map is then segmented by Mean-shift approach. The segmented portion of the window with a majority of negative response is inferred as an occluded region. If partial occlusion is indicated with high likelihood in a certain scanning window, part detectors are applied on the unoccluded regions to achieve the final classification on the current scanning window. With the help of the augmented HOG-LBP feature and the global-part occlusion handling method, we achieve a detection rate of 91.3\% with FPPW= 10\&\#x2212;6, 94.7\% with FPPW= 10\&\#x2212;5, and 97.9\% with FPPW= 10\&\#x2212;4 on the INRIA dataset, which, to our best knowledge, is the best human detection performance on the INRIA dataset. The global-part occlusion handling method is further validated using synthesized occlusion data constructed from the INRIA and Pascal dataset.},
author = {Wang, Xiaoyu and Han, Tony X. and Yan, Shuicheng},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Wang, Han, Yan - 2009 - An HOG-LBP human detector with partial occlusion handling(2).pdf:pdf},
journal = {IEEE 12th International Conference on Computer Vision},
publisher = {IEEE},
title = {{An HOG-LBP human detector with partial occlusion handling}},
year = {2009}
}
@article{Wang2004,
abstract = {Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a Structural Similarity Index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000.},
author = {Wang, Zhou and Bovik, Alan Conrad and Sheikh, Hamid Rahim and Simoncelli, Eero P},
file = {::},
issn = {1057-7149},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
keywords = {Algorithms,Automated,Computer-Assisted,Computer-Assisted: methods,Computer-Assisted: standards,Data Interpretation,Hypermedia,Image Enhancement,Image Enhancement: methods,Image Enhancement: standards,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Information Storage and Retrieval: standards,Models,Pattern Recognition,Quality Control,Reproducibility of Results,Sensitivity and Specificity,Signal Processing,Statistical,Subtraction Technique},
month = apr,
number = {4},
pages = {600--612},
pmid = {15376593},
title = {{Image quality assessment: from error visibility to structural similarity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15376593},
volume = {13},
year = {2004}
}
@article{Will1971,
abstract = {The problem of machine vision as evidenced in the various robot projects in existence is attacked by analogy with the supposed nature of human visual processing in that edges are enhanced, texture is examined and various heuristic approaches are studied. This paper describes a non-anthropomorphically based method of decomposing a scene subjected to a special form of illumination into elementary planar areas. The method consists in coding the various planar areas as the modulation on a spatial frequency carrier grid so that the extraction of the planar areas becomes a matter of linear frequency domain filtering. The paper also addresses the application of grid coding to other problems in recording and extracting information from 3-D images.},
author = {Will, P.M. M and Pennington, K.S. S},
doi = {10.1016/0004-3702(71)90015-4},
file = {::},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {preprocessing},
mendeley-tags = {preprocessing},
month = dec,
number = {3-4},
pages = {319--329},
title = {{Grid coding: A preprocessing technique for robot and machine vision}},
url = {http://www.sciencedirect.com/science/article/pii/0004370271900154},
volume = {2},
year = {1971}
}
@article{Yang2010,
abstract = {This paper presents a new approach to single-image super-resolution, based on sparse signal representation. Research on image statistics suggests that image patches can be well-represented as a sparse linear combination of elements from an appropriately chosen over-complete dictionary. Inspired by this observation, we seek a sparse representation for each patch of the low-resolution input, and then use the coefficients of this representation to generate the high-resolution output. Theoretical results from compressed sensing suggest that under mild conditions, the sparse representation can be correctly recovered from the downsampled signals. By jointly training two dictionaries for the low- and high-resolution image patches, we can enforce the similarity of sparse representations between the low resolution and high resolution image patch pair with respect to their own dictionaries. Therefore, the sparse representation of a low resolution image patch can be applied with the high resolution image patch dictionary to generate a high resolution image patch. The learned dictionary pair is a more compact representation of the patch pairs, compared to previous approaches, which simply sample a large amount of image patch pairs, reducing the computational cost substantially. The effectiveness of such a sparsity prior is demonstrated for both general image super-resolution and the special case of face hallucination. In both cases, our algorithm generates high-resolution images that are competitive or even superior in quality to images produced by other similar SR methods. In addition, the local sparse modeling of our approach is naturally robust to noise, and therefore the proposed algorithm can handle super-resolution with noisy inputs in a more unified framework.},
author = {Yang, Jianchao and Wright, John and Huang, Thomas S and Ma, Yi},
doi = {10.1109/TIP.2010.2050625},
file = {::},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
month = nov,
number = {11},
pages = {2861--2873},
pmid = {20483687},
title = {{Image super-resolution via sparse representation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20483687},
volume = {19},
year = {2010}
}
@article{Yong2013,
author = {Yong, Yang and Chixi, Wang and Bencheng, Yu and Zhi-Hao, Yin},
doi = {10.1109/ICCIS.2013.288},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Yong et al. - 2013 - Research on the Method of Image Preprocessing in License Plate Location(2).pdf:pdf},
isbn = {978-0-7695-5004-6},
journal = {2013 International Conference on Computational and Information Sciences},
keywords = {image processing technology,key words,median value filter,preprocess},
month = jun,
pages = {1084--1087},
publisher = {Ieee},
title = {{Research on the Method of Image Preprocessing in License Plate Location}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6643205},
year = {2013}
}
@article{Yosinski2014,
author = {Yosinski, J and Clune, J},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Yosinski, Clune - 2014 - How transferable are features in deep neural networks(2).pdf:pdf},
journal = {Advances in Neural \ldots},
pages = {1--9},
title = {{How transferable are features in deep neural networks?}},
url = {http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks},
year = {2014}
}
@article{Yu2011,
abstract = {Recently, researchers are focusing more on the study of support vector machine (SVM) due to its useful applications in a number of areas, such as pattern recognition, multimedia, image processing and bioinformatics. One of the main research issues is how to improve the efficiency of the original SVM model, while preventing any deterioration of the classification performance of the model. In this paper, we propose a modified SVM based on the properties of support vectors and a pruning strategy to preserve support vectors, while eliminating redundant training vectors at the same time. The experiments on real images show that (1) our proposed approach can reduce the number of input training vectors, while preserving the support vectors, which leads to a significant reduction in the computational cost while attaining similar levels of accuracy. (2)The approach also works well when applied to image segmentation.},
author = {Yu, Zhiwen and Wong, Hau-San and Wen, Guihua},
doi = {10.1016/j.imavis.2010.08.003},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Yu, Wong, Wen - 2011 - A modified support vector machine and its application to image segmentation(2).pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Classification,Image segmentation,Support vector machine,segmentation,svm},
mendeley-tags = {segmentation,svm},
month = jan,
number = {1},
pages = {29--40},
title = {{A modified support vector machine and its application to image segmentation}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885610001113},
volume = {29},
year = {2011}
}
@article{Yuille2012,
abstract = {I argue that computer vision needs a core of techniques and foundational research to enable it to build on its current successes and achieve its enormous potential. “How do I know what papers to read in computer vision? There are so many. And they are so different.” Graduate Student. Xi'An. China. November, 2011.},
author = {Yuille, A.L. L},
doi = {10.1016/j.imavis.2011.12.013},
file = {::},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Core,Foundations,computer vision},
mendeley-tags = {computer vision},
month = aug,
number = {8},
pages = {469--471},
title = {{Computer vision needs a core and foundations}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885612000704},
volume = {30},
year = {2012}
}
@article{Zeiler2013,
abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky $\backslash$etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
archivePrefix = {arXiv},
arxivId = {1311.2901},
author = {Zeiler, Matthew D and Fergus, Rob},
edition = {2014},
eprint = {1311.2901},
file = {::},
journal = {Computer Vision--ECCV 2014},
month = nov,
pages = {818--833},
publisher = {Springer},
title = {{Visualizing and Understanding Convolutional Networks}},
url = {http://arxiv.org/abs/1311.2901},
year = {2013}
}
@inproceedings{Zeiler2010,
abstract = {Building robust low and mid-level image representations, beyond edge primitives, is a long-standing goal in vision. Many existing feature detectors spatially pool edge information which destroys cues such as edge intersections, parallelism and symmetry. We present a learning framework where features that capture these mid-level cues spontaneously emerge from image data. Our approach is based on the convolutional decomposition of images under a spar-sity constraint and is totally unsupervised. By building a hierarchy of such decompositions we can learn rich feature sets that are a robust image representation for both the analysis and synthesis of images.},
author = {Zeiler, Matthew D. and Krishnan, Dilip and Taylor, Graham W. and Fergus, Rob},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5539957},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Zeiler et al. - 2010 - Deconvolutional networks(2).pdf:pdf},
isbn = {978-1-4244-6984-0},
issn = {1063-6919},
keywords = {Computer architecture,Convolution,Decoding,Feature extraction,Filters,Image edge detection,Image representation,Image restoration,Object recognition,Robustness,deconvolution,deconvolutional networks,edge primitives,feature detectors,image representation,image representations,images synthesis,pool edge information},
month = jun,
pages = {2528--2535},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Deconvolutional networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5539957},
year = {2010}
}
@inproceedings{Zeiler2011,
abstract = {We present a hierarchical model that learns image decompositions via alternating layers of convolutional sparse coding and max pooling. When trained on natural images, the layers of our model capture image information in a variety of forms: low-level edges, mid-level edge junctions, high-level object parts and complete objects. To build our model we rely on a novel inference scheme that ensures each layer reconstructs the input, rather than just the output of the layer directly beneath, as is common with existing hierarchical approaches. This makes it possible to learn multiple layers of representation and we show models with 4 layers, trained on images from the Caltech-101 and 256 datasets. When combined with a standard classifier, features extracted from these models outperform SIFT, as well as representations from other feature learning methods.},
author = {Zeiler, Matthew D. and Taylor, Graham W. and Fergus, Rob},
booktitle = {International Conference on Computer Vision},
doi = {10.1109/ICCV.2011.6126474},
file = {::},
isbn = {978-1-4577-1102-2},
issn = {1550-5499},
keywords = {Adaptation models,Caltech-101 datasets,Caltech-256 datasets,Computational modeling,Deconvolution,Image reconstruction,Mathematical model,Switches,Training,adaptive deconvolutional networks,classifier,complete objects,convolutional sparse coding,deconvolution,feature extraction,hierarchical model,high level feature learning,high-level object parts,image classification,image decompositions,image representation,inference mechanisms,inference scheme,learning (artificial intelligence),low-level edges,max pooling,mid level feature learning,mid-level edge junctions,natural images},
month = nov,
pages = {2018--2025},
publisher = {IEEE},
shorttitle = {Computer Vision (ICCV), 2011 IEEE International Co},
title = {{Adaptive deconvolutional networks for mid and high level feature learning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6126474},
year = {2011}
}
@article{Zhang2012,
author = {Zhang, David and Zuo, Wangmeng and Yue, Feng},
doi = {10.1145/2071389.2071391},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Zhang, Zuo, Yue - 2012 - A Comparative Study of Palmprint Recognition Algorithms(2).pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
month = jan,
number = {1},
pages = {1--37},
title = {{A Comparative Study of Palmprint Recognition Algorithms}},
url = {http://dl.acm.org/citation.cfm?doid=2071389.2071391},
volume = {44},
year = {2012}
}
@article{Zhang1993,
author = {Zhang, HongJiang and Kankanhalli, Atreyi and Smoliar, Stephen W.},
doi = {10.1007/BF01210504},
issn = {0942-4962},
journal = {Multimedia Systems},
month = jan,
number = {1},
pages = {10--28},
title = {{Automatic partitioning of full-motion video}},
url = {http://link.springer.com/10.1007/BF01210504},
volume = {1},
year = {1993}
}
@article{Zhang2014,
abstract = {Traditional patch-based sparse representation modeling of natural images usually suffer from two problems. First, it has to solve a large-scale optimization problem with high computational complexity in dictionary learning. Second, each patch is considered independently in dictionary learning and sparse coding, which ignores the relationship among patches, resulting in inaccurate sparse coding coefficients. In this paper, instead of using patch as the basic unit of sparse representation, we exploit the concept of group as the basic unit of sparse representation, which is composed of nonlocal patches with similar structures, and establish a novel sparse representation modeling of natural images, called group-based sparse representation (GSR). The proposed GSR is able to sparsely represent natural images in the domain of group, which enforces the intrinsic local sparsity and nonlocal self-similarity of images simultaneously in a unified framework. In addition, an effective self-adaptive dictionary learning method for each group with low complexity is designed, rather than dictionary learning from natural images. To make GSR tractable and robust, a split Bregman-based technique is developed to solve the proposed GSR-driven ℓ0 minimization problem for image restoration efficiently. Extensive experiments on image inpainting, image deblurring and image compressive sensing recovery manifest that the proposed GSR modeling outperforms many current state-of-the-art schemes in both peak signal-to-noise ratio and visual perception.},
author = {Zhang, Jian and Zhao, Debin and Gao, Wen},
doi = {10.1109/TIP.2014.2323127},
file = {::},
issn = {1941-0042},
journal = {IEEE transactions on image processing},
month = aug,
number = {8},
pages = {3336--51},
pmid = {24835225},
title = {{Group-based sparse representation for image restoration.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24835225},
volume = {23},
year = {2014}
}
@article{Zhou2006,
author = {Zhou, Zhi-Hua and Liu, Xu-Ying},
doi = {10.1109/TKDE.2006.17},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Zhou, Liu - 2006 - Training cost-sensitive neural networks with methods addressing the class imbalance problem(2).pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Costs,Data mining,Decision trees,Index Terms- Machine learning,Learning systems,Machine learning,Neural networks,Sampling methods,Testing,Training data,Voting,class imbalance learning,cost-sensitive learning,cost-sensitive neural network training,data mining,ensemble learning,ensemble learning.,learning (artificial intelligence),machine learning,neural nets,neural networks,oversampling technique,sampling,sampling methods,threshold-moving,undersampling technique},
language = {English},
month = jan,
number = {1},
pages = {63--77},
publisher = {IEEE},
title = {{Training cost-sensitive neural networks with methods addressing the class imbalance problem}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1549828},
volume = {18},
year = {2006}
}
@article{Zhuo2014,
author = {Zhuo, Li and Cheng, Bo and Zhang, Jing},
doi = {10.1016/j.neucom.2014.03.014},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Zhuo, Cheng, Zhang - 2014 - A comparative study of dimensionality reduction methods for large-scale image retrieval.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Dimensionality reduction,HSV histogram,Large-scale image retrieval,OPTIMIZED SIFT,Vocabulary tree,dimensionality reduction,large-scale image retrieval},
month = oct,
pages = {202--210},
publisher = {Elsevier},
title = {{A comparative study of dimensionality reduction methods for large-scale image retrieval}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231214004238},
volume = {141},
year = {2014}
}
@article{Zliobaite2014,
author = {Zliobaite, Indre and Gabrys, Bogdan},
doi = {10.1109/TKDE.2012.147},
file = {:Users/gabi/Library/Application Support/Mendeley Desktop/Downloaded/Zliobaite, Gabrys - 2014 - Adaptive Preprocessing for Streaming Data.pdf:pdf},
isbn = {2011110726},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = feb,
number = {2},
pages = {309--321},
title = {{Adaptive Preprocessing for Streaming Data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6247432},
volume = {26},
year = {2014}
}
@article{Zuo2014,
abstract = {Natural image statistics plays an important role in image denoising, and various natural image priors, including gradient-based, sparse representation-based, and nonlocal self-similarity-based ones, have been widely studied and exploited for noise removal. In spite of the great success of many denoising algorithms, they tend to smooth the fine scale image textures when removing noise, degrading the image visual quality. To address this problem, in this paper, we propose a texture enhanced image denoising method by enforcing the gradient histogram of the denoised image to be close to a reference gradient histogram of the original image. Given the reference gradient histogram, a novel gradient histogram preservation (GHP) algorithm is developed to enhance the texture structures while removing noise. Two region-based variants of GHP are proposed for the denoising of images consisting of regions with different textures. An algorithm is also developed to effectively estimate the reference gradient histogram from the noisy observation of the unknown image. Our experimental results demonstrate that the proposed GHP algorithm can well preserve the texture appearance in the denoised images, making them look more natural.},
author = {Zuo, Wangmeng and Zhang, Lei and Song, Chunwei and Zhang, David and Gao, Huijun},
doi = {10.1109/TIP.2014.2316423},
file = {::},
issn = {1941-0042},
journal = {IEEE transactions on image processing},
month = jun,
number = {6},
pages = {2459--72},
pmid = {24733013},
title = {{Gradient histogram estimation and preservation for texture enhanced image denoising.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24733013},
volume = {23},
year = {2014}
}
